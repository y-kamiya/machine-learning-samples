{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TTS_jsut_vocoder_melgan_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-kamiya/machine-learning-samples/blob/feature%2Ftts-scripts/TTS_jsut_multiband_melgan_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjD0xW0cEMVT"
      },
      "source": [
        "## Hands-on example for ðŸ¸ [Coqui TTS](https://github.com/coqui-ai/TTS)\n",
        "\n",
        "This notebook trains Tacotron model on LJSpeech dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR5s0u9TdB9d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xspM7pnX7Zbj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls /gdrive\n",
        "\n",
        "!ln -s \"/gdrive/My Drive\" /mydrive\n",
        "DATAROOT='/mydrive/machine-learning/tts/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yjg-wRlPuO9"
      },
      "source": [
        "# zipã«å›ºã‚ã¦ã‚ã£ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å±•é–‹\n",
        "!cp -r \"$DATAROOT/jsut_ljspeech_structure_22050.zip\" /content/\n",
        "!unzip -q /content/jsut_ljspeech_structure_22050.zip -d /content/\n",
        "\n",
        "!cp \"$DATAROOT/jsut_ver1.1_ljspeech_structure/scale_stats.npy\" /content/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwvg3-nVDL5t"
      },
      "source": [
        "# get TTS to your local\n",
        "!git clone https://github.com/coqui-ai/TTS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tEdu7hPisWl"
      },
      "source": [
        "%cd TTS\n",
        "!git checkout v0.0.13\n",
        "!pip install -e .\n",
        "!pip install numba==0.48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7_Xao7uNOvX"
      },
      "source": [
        "# load the default config file and update with the local paths and settings.\n",
        "import json\n",
        "from TTS.utils.io import load_config\n",
        "\n",
        "DATAROOT = '/content/ljspeech_structure_22050'\n",
        "DATAROOT_DRIVE ='/mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure'\n",
        "\n",
        "CONFIG = load_config('TTS/vocoder/configs/multiband_melgan_config.json') \n",
        "\n",
        "CONFIG['data_path'] = f\"{DATAROOT}/wavs/\"\n",
        "CONFIG['audio']['stats_path'] = None\n",
        "CONFIG['output_path'] = f\"{DATAROOT_DRIVE}/output\"\n",
        "CONFIG['num_loader_workers'] = 4\n",
        "CONFIG['num_val_loader_workers'] = 1\n",
        "CONFIG['test_sentences_file'] = f\"{DATAROOT_DRIVE}/test_sentences_file\"\n",
        "CONFIG['print_step'] = 1000\n",
        "CONFIG['save_step'] = 5000\n",
        "\n",
        "CONFIG['use_l1_spec_loss'] = False\n",
        "CONFIG['diff_samples_for_G_and_D'] = False\n",
        "\n",
        "\n",
        "with open('config.json', 'w') as fp:\n",
        "    json.dump(CONFIG, fp)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1fxmcT2qGmb"
      },
      "source": [
        "%%script false --no-raise-error\n",
        "!CUDA_VISIBLE_DEVICES=\"0\" python TTS/bin/train_vocoder_gan.py --config_path config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L3JjJOBErxq",
        "outputId": "58dccfc1-d12f-4b78-a0bb-c633005f57f5"
      },
      "source": [
        "#%%script false --no-raise-error\n",
        "# å­¦ç¿’å†é–‹\n",
        "!cp config.json $DATAROOT_DRIVE/output/multiband-melgan\n",
        "!CUDA_VISIBLE_DEVICES=\"0\" python TTS/bin/train_vocoder_gan.py --continue_path $DATAROOT_DRIVE/output/multiband-melgan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã¯æœ€å¾Œã® 5000 è¡Œã«åˆ‡ã‚Šæ¨ã¦ã‚‰ã‚Œã¾ã—ãŸã€‚\u001b[0m\n",
            "     | > avg_D_mse_gan_real_loss: 0.13808\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13824\n",
            "     | > avg_D_loss: 0.44636\n",
            "     | > avg_loader_time: 0.86925\n",
            "     | > avg_step_time: 0.62491\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78846 \u001b[0m(+0.00223)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37229 \u001b[0m(+0.00812)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70276 \u001b[0m(+0.00310)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39029 \u001b[0m(+0.01677)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35986 \u001b[0m(+0.00595)\n",
            "     | > avg_G_loss:\u001b[91m 2.02654 \u001b[0m(+0.03000)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12690 \u001b[0m(+0.01511)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89964 \u001b[0m(+0.01488)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44544 \u001b[0m(+0.00003)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.17272 \u001b[0m(-0.00232)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10046 \u001b[0m(+0.00031)\n",
            "     | > avg_D_loss:\u001b[91m 0.44544 \u001b[0m(+0.00003)\n",
            "     | > avg_loader_time:\u001b[92m 0.42305 \u001b[0m(-0.01350)\n",
            "     | > avg_step_time:\u001b[91m 0.05826 \u001b[0m(+0.00613)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 327/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:45:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.95 sec -- GLOBAL_STEP: 424688\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81460\n",
            "     | > avg_G_stft_loss_sc: 0.35678\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75489\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36518\n",
            "     | > avg_G_mse_fake_loss: 0.31409\n",
            "     | > avg_G_loss: 1.93095\n",
            "     | > avg_G_gen_loss: 1.14572\n",
            "     | > avg_G_adv_loss: 0.78523\n",
            "     | > avg_D_mse_gan_loss: 0.44672\n",
            "     | > avg_D_mse_gan_real_loss: 0.13800\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13810\n",
            "     | > avg_D_loss: 0.44672\n",
            "     | > avg_loader_time: 0.86390\n",
            "     | > avg_step_time: 0.64280\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78785 \u001b[0m(-0.00061)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37244 \u001b[0m(+0.00015)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70120 \u001b[0m(-0.00156)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37558 \u001b[0m(-0.01471)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34362 \u001b[0m(-0.01624)\n",
            "     | > avg_G_loss:\u001b[92m 1.97758 \u001b[0m(-0.04896)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11853 \u001b[0m(-0.00837)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85904 \u001b[0m(-0.04060)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44341 \u001b[0m(-0.00203)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16161 \u001b[0m(-0.01111)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10783 \u001b[0m(+0.00737)\n",
            "     | > avg_D_loss:\u001b[92m 0.44341 \u001b[0m(-0.00203)\n",
            "     | > avg_loader_time:\u001b[92m 0.40216 \u001b[0m(-0.02089)\n",
            "     | > avg_step_time:\u001b[92m 0.04822 \u001b[0m(-0.01004)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 328/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:49:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.46 sec -- GLOBAL_STEP: 424809\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81730\n",
            "     | > avg_G_stft_loss_sc: 0.35944\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75655\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36807\n",
            "     | > avg_G_mse_fake_loss: 0.31697\n",
            "     | > avg_G_loss: 1.94311\n",
            "     | > avg_G_gen_loss: 1.15067\n",
            "     | > avg_G_adv_loss: 0.79243\n",
            "     | > avg_D_mse_gan_loss: 0.44646\n",
            "     | > avg_D_mse_gan_real_loss: 0.13828\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13837\n",
            "     | > avg_D_loss: 0.44646\n",
            "     | > avg_loader_time: 0.87532\n",
            "     | > avg_step_time: 0.63084\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78710 \u001b[0m(-0.00075)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36135 \u001b[0m(-0.01109)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70052 \u001b[0m(-0.00068)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37610 \u001b[0m(+0.00052)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38211 \u001b[0m(+0.03850)\n",
            "     | > avg_G_loss:\u001b[91m 2.06781 \u001b[0m(+0.09024)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11253 \u001b[0m(-0.00600)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.95528 \u001b[0m(+0.09624)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45263 \u001b[0m(+0.00922)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17857 \u001b[0m(+0.01696)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09984 \u001b[0m(-0.00800)\n",
            "     | > avg_D_loss:\u001b[91m 0.45263 \u001b[0m(+0.00922)\n",
            "     | > avg_loader_time:\u001b[91m 0.40617 \u001b[0m(+0.00401)\n",
            "     | > avg_step_time:\u001b[91m 0.05434 \u001b[0m(+0.00613)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 329/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:52:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.26 sec -- GLOBAL_STEP: 424930\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82230\n",
            "     | > avg_G_stft_loss_sc: 0.35774\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76319\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36655\n",
            "     | > avg_G_mse_fake_loss: 0.32056\n",
            "     | > avg_G_loss: 1.95629\n",
            "     | > avg_G_gen_loss: 1.15489\n",
            "     | > avg_G_adv_loss: 0.80140\n",
            "     | > avg_D_mse_gan_loss: 0.44416\n",
            "     | > avg_D_mse_gan_real_loss: 0.13773\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13783\n",
            "     | > avg_D_loss: 0.44416\n",
            "     | > avg_loader_time: 0.88407\n",
            "     | > avg_step_time: 0.62916\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78553 \u001b[0m(-0.00156)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35905 \u001b[0m(-0.00230)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69910 \u001b[0m(-0.00142)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37064 \u001b[0m(-0.00546)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38972 \u001b[0m(+0.00760)\n",
            "     | > avg_G_loss:\u001b[91m 2.08145 \u001b[0m(+0.01364)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10716 \u001b[0m(-0.00537)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.97429 \u001b[0m(+0.01901)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.45108 \u001b[0m(-0.00156)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.17229 \u001b[0m(-0.00627)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09914 \u001b[0m(-0.00069)\n",
            "     | > avg_D_loss:\u001b[92m 0.45108 \u001b[0m(-0.00156)\n",
            "     | > avg_loader_time:\u001b[92m 0.36657 \u001b[0m(-0.03960)\n",
            "     | > avg_step_time:\u001b[92m 0.05255 \u001b[0m(-0.00180)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 330/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:55:29) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 69/120 -- GLOBAL_STEP: 425000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81741  (0.80104)\n",
            "     | > G_stft_loss_sc: 0.36273  (0.36292)\n",
            "     | > G_subband_stft_loss_mg: 0.75820  (0.72700)\n",
            "     | > G_subband_stft_loss_sc: 0.36428  (0.37158)\n",
            "     | > G_mse_fake_loss: 0.33554  (0.31326)\n",
            "     | > G_loss: 1.99017  (1.91442)\n",
            "     | > G_gen_loss: 1.15131  (1.13127)\n",
            "     | > G_adv_loss: 0.83885  (0.78315)\n",
            "     | > D_mse_gan_loss: 0.44023  (0.44851)\n",
            "     | > D_mse_gan_real_loss: 0.14867  (0.13899)\n",
            "     | > D_mse_gan_fake_loss: 0.11914  (0.13820)\n",
            "     | > D_loss: 0.44023  (0.44851)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 0.0030\n",
            "     | > current_lr_G: 5.980846997657298e-06\n",
            "     | > current_lr_D: 5.980846997657298e-06\n",
            " > CHECKPOINT : /mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure/output/multiband-melgan/checkpoint_425000.pth.tar\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.39 sec -- GLOBAL_STEP: 425051\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80059\n",
            "     | > avg_G_stft_loss_sc: 0.36194\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72644\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37061\n",
            "     | > avg_G_mse_fake_loss: 0.31279\n",
            "     | > avg_G_loss: 1.91177\n",
            "     | > avg_G_gen_loss: 1.12979\n",
            "     | > avg_G_adv_loss: 0.78198\n",
            "     | > avg_D_mse_gan_loss: 0.44839\n",
            "     | > avg_D_mse_gan_real_loss: 0.13879\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13842\n",
            "     | > avg_D_loss: 0.44839\n",
            "     | > avg_loader_time: 0.80281\n",
            "     | > avg_step_time: 0.62103\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78708 \u001b[0m(+0.00155)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35718 \u001b[0m(-0.00187)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70198 \u001b[0m(+0.00288)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37489 \u001b[0m(+0.00424)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35348 \u001b[0m(-0.03624)\n",
            "     | > avg_G_loss:\u001b[92m 1.99425 \u001b[0m(-0.08720)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11056 \u001b[0m(+0.00340)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88369 \u001b[0m(-0.09060)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44563 \u001b[0m(-0.00544)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16668 \u001b[0m(-0.00561)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10412 \u001b[0m(+0.00497)\n",
            "     | > avg_D_loss:\u001b[92m 0.44563 \u001b[0m(-0.00544)\n",
            "     | > avg_loader_time:\u001b[91m 0.37634 \u001b[0m(+0.00977)\n",
            "     | > avg_step_time:\u001b[92m 0.05101 \u001b[0m(-0.00154)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 331/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:58:41) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.27 sec -- GLOBAL_STEP: 425172\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81802\n",
            "     | > avg_G_stft_loss_sc: 0.35745\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75690\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36632\n",
            "     | > avg_G_mse_fake_loss: 0.31576\n",
            "     | > avg_G_loss: 1.93874\n",
            "     | > avg_G_gen_loss: 1.14934\n",
            "     | > avg_G_adv_loss: 0.78939\n",
            "     | > avg_D_mse_gan_loss: 0.44721\n",
            "     | > avg_D_mse_gan_real_loss: 0.13868\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13791\n",
            "     | > avg_D_loss: 0.44721\n",
            "     | > avg_loader_time: 0.85863\n",
            "     | > avg_step_time: 0.60426\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78973 \u001b[0m(+0.00265)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37478 \u001b[0m(+0.01761)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70311 \u001b[0m(+0.00113)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39071 \u001b[0m(+0.01583)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33861 \u001b[0m(-0.01486)\n",
            "     | > avg_G_loss:\u001b[92m 1.97570 \u001b[0m(-0.01855)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12917 \u001b[0m(+0.01861)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84653 \u001b[0m(-0.03716)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44554 \u001b[0m(-0.00009)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15371 \u001b[0m(-0.01297)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11763 \u001b[0m(+0.01351)\n",
            "     | > avg_D_loss:\u001b[92m 0.44554 \u001b[0m(-0.00009)\n",
            "     | > avg_loader_time:\u001b[91m 0.38683 \u001b[0m(+0.01049)\n",
            "     | > avg_step_time:\u001b[91m 0.05438 \u001b[0m(+0.00337)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 332/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:01:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.37 sec -- GLOBAL_STEP: 425293\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81627\n",
            "     | > avg_G_stft_loss_sc: 0.36356\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75539\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37215\n",
            "     | > avg_G_mse_fake_loss: 0.31436\n",
            "     | > avg_G_loss: 1.93959\n",
            "     | > avg_G_gen_loss: 1.15368\n",
            "     | > avg_G_adv_loss: 0.78590\n",
            "     | > avg_D_mse_gan_loss: 0.44794\n",
            "     | > avg_D_mse_gan_real_loss: 0.13873\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13825\n",
            "     | > avg_D_loss: 0.44794\n",
            "     | > avg_loader_time: 0.86303\n",
            "     | > avg_step_time: 0.61995\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78664 \u001b[0m(-0.00310)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35612 \u001b[0m(-0.01867)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70086 \u001b[0m(-0.00225)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37154 \u001b[0m(-0.01918)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29623 \u001b[0m(-0.04238)\n",
            "     | > avg_G_loss:\u001b[92m 1.84816 \u001b[0m(-0.12754)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10757 \u001b[0m(-0.02159)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74058 \u001b[0m(-0.10595)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44152 \u001b[0m(-0.00402)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12102 \u001b[0m(-0.03269)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14527 \u001b[0m(+0.02764)\n",
            "     | > avg_D_loss:\u001b[92m 0.44152 \u001b[0m(-0.00402)\n",
            "     | > avg_loader_time:\u001b[91m 0.42525 \u001b[0m(+0.03842)\n",
            "     | > avg_step_time:\u001b[92m 0.05033 \u001b[0m(-0.00405)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 333/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:04:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.99 sec -- GLOBAL_STEP: 425414\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81213\n",
            "     | > avg_G_stft_loss_sc: 0.36017\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74920\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36860\n",
            "     | > avg_G_mse_fake_loss: 0.31395\n",
            "     | > avg_G_loss: 1.92993\n",
            "     | > avg_G_gen_loss: 1.14505\n",
            "     | > avg_G_adv_loss: 0.78488\n",
            "     | > avg_D_mse_gan_loss: 0.44732\n",
            "     | > avg_D_mse_gan_real_loss: 0.13865\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13729\n",
            "     | > avg_D_loss: 0.44732\n",
            "     | > avg_loader_time: 0.86567\n",
            "     | > avg_step_time: 0.61100\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78612 \u001b[0m(-0.00051)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36081 \u001b[0m(+0.00469)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70125 \u001b[0m(+0.00039)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37739 \u001b[0m(+0.00585)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.29767 \u001b[0m(+0.00143)\n",
            "     | > avg_G_loss:\u001b[91m 1.85695 \u001b[0m(+0.00880)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11279 \u001b[0m(+0.00521)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.74417 \u001b[0m(+0.00358)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44323 \u001b[0m(+0.00171)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.12221 \u001b[0m(+0.00119)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14717 \u001b[0m(+0.00190)\n",
            "     | > avg_D_loss:\u001b[91m 0.44323 \u001b[0m(+0.00171)\n",
            "     | > avg_loader_time:\u001b[92m 0.42073 \u001b[0m(-0.00452)\n",
            "     | > avg_step_time:\u001b[91m 0.05359 \u001b[0m(+0.00326)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 334/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:08:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.37 sec -- GLOBAL_STEP: 425535\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81619\n",
            "     | > avg_G_stft_loss_sc: 0.35787\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75605\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36629\n",
            "     | > avg_G_mse_fake_loss: 0.31257\n",
            "     | > avg_G_loss: 1.92962\n",
            "     | > avg_G_gen_loss: 1.14820\n",
            "     | > avg_G_adv_loss: 0.78142\n",
            "     | > avg_D_mse_gan_loss: 0.44804\n",
            "     | > avg_D_mse_gan_real_loss: 0.13837\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13785\n",
            "     | > avg_D_loss: 0.44804\n",
            "     | > avg_loader_time: 0.85676\n",
            "     | > avg_step_time: 0.59717\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78936 \u001b[0m(+0.00323)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37318 \u001b[0m(+0.01237)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70249 \u001b[0m(+0.00123)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38546 \u001b[0m(+0.00807)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34461 \u001b[0m(+0.04695)\n",
            "     | > avg_G_loss:\u001b[91m 1.98678 \u001b[0m(+0.12982)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12524 \u001b[0m(+0.01246)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86153 \u001b[0m(+0.11737)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44158 \u001b[0m(-0.00165)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16539 \u001b[0m(+0.04318)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10122 \u001b[0m(-0.04595)\n",
            "     | > avg_D_loss:\u001b[92m 0.44158 \u001b[0m(-0.00165)\n",
            "     | > avg_loader_time:\u001b[91m 0.43020 \u001b[0m(+0.00948)\n",
            "     | > avg_step_time:\u001b[91m 0.05378 \u001b[0m(+0.00019)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 335/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:11:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.84 sec -- GLOBAL_STEP: 425656\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81795\n",
            "     | > avg_G_stft_loss_sc: 0.35870\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75827\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36717\n",
            "     | > avg_G_mse_fake_loss: 0.31693\n",
            "     | > avg_G_loss: 1.94336\n",
            "     | > avg_G_gen_loss: 1.15104\n",
            "     | > avg_G_adv_loss: 0.79232\n",
            "     | > avg_D_mse_gan_loss: 0.44591\n",
            "     | > avg_D_mse_gan_real_loss: 0.13784\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13817\n",
            "     | > avg_D_loss: 0.44591\n",
            "     | > avg_loader_time: 0.85059\n",
            "     | > avg_step_time: 0.59271\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78770 \u001b[0m(-0.00166)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36274 \u001b[0m(-0.01044)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70101 \u001b[0m(-0.00148)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37000 \u001b[0m(-0.01546)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37166 \u001b[0m(+0.02705)\n",
            "     | > avg_G_loss:\u001b[91m 2.03988 \u001b[0m(+0.05311)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11072 \u001b[0m(-0.01452)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.92916 \u001b[0m(+0.06763)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44813 \u001b[0m(+0.00655)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16844 \u001b[0m(+0.00306)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10206 \u001b[0m(+0.00084)\n",
            "     | > avg_D_loss:\u001b[91m 0.44813 \u001b[0m(+0.00655)\n",
            "     | > avg_loader_time:\u001b[92m 0.42507 \u001b[0m(-0.00513)\n",
            "     | > avg_step_time:\u001b[91m 0.05642 \u001b[0m(+0.00264)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 336/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:14:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.69 sec -- GLOBAL_STEP: 425777\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80809\n",
            "     | > avg_G_stft_loss_sc: 0.36193\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74224\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37060\n",
            "     | > avg_G_mse_fake_loss: 0.31340\n",
            "     | > avg_G_loss: 1.92494\n",
            "     | > avg_G_gen_loss: 1.14143\n",
            "     | > avg_G_adv_loss: 0.78350\n",
            "     | > avg_D_mse_gan_loss: 0.44767\n",
            "     | > avg_D_mse_gan_real_loss: 0.13857\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13821\n",
            "     | > avg_D_loss: 0.44767\n",
            "     | > avg_loader_time: 0.84164\n",
            "     | > avg_step_time: 0.59985\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78638 \u001b[0m(-0.00133)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35826 \u001b[0m(-0.00447)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69997 \u001b[0m(-0.00104)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37245 \u001b[0m(+0.00244)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34744 \u001b[0m(-0.02422)\n",
            "     | > avg_G_loss:\u001b[92m 1.97714 \u001b[0m(-0.06275)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10853 \u001b[0m(-0.00220)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.86861 \u001b[0m(-0.06055)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44308 \u001b[0m(-0.00505)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16544 \u001b[0m(-0.00300)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10480 \u001b[0m(+0.00274)\n",
            "     | > avg_D_loss:\u001b[92m 0.44308 \u001b[0m(-0.00505)\n",
            "     | > avg_loader_time:\u001b[91m 0.48179 \u001b[0m(+0.05672)\n",
            "     | > avg_step_time:\u001b[91m 0.05875 \u001b[0m(+0.00233)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 337/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:17:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.15 sec -- GLOBAL_STEP: 425898\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81184\n",
            "     | > avg_G_stft_loss_sc: 0.35914\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75024\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36772\n",
            "     | > avg_G_mse_fake_loss: 0.31258\n",
            "     | > avg_G_loss: 1.92592\n",
            "     | > avg_G_gen_loss: 1.14447\n",
            "     | > avg_G_adv_loss: 0.78145\n",
            "     | > avg_D_mse_gan_loss: 0.44754\n",
            "     | > avg_D_mse_gan_real_loss: 0.13847\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13850\n",
            "     | > avg_D_loss: 0.44754\n",
            "     | > avg_loader_time: 0.84983\n",
            "     | > avg_step_time: 0.59536\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78794 \u001b[0m(+0.00157)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36821 \u001b[0m(+0.00994)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70140 \u001b[0m(+0.00143)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37523 \u001b[0m(+0.00278)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37430 \u001b[0m(+0.02686)\n",
            "     | > avg_G_loss:\u001b[91m 2.05215 \u001b[0m(+0.07501)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11639 \u001b[0m(+0.00786)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93575 \u001b[0m(+0.06715)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45041 \u001b[0m(+0.00733)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.19842 \u001b[0m(+0.03298)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08528 \u001b[0m(-0.01952)\n",
            "     | > avg_D_loss:\u001b[91m 0.45041 \u001b[0m(+0.00733)\n",
            "     | > avg_loader_time:\u001b[92m 0.39512 \u001b[0m(-0.08667)\n",
            "     | > avg_step_time:\u001b[92m 0.05093 \u001b[0m(-0.00781)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 338/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:20:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 101/120 -- GLOBAL_STEP: 426000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.82060  (0.81982)\n",
            "     | > G_stft_loss_sc: 0.35791  (0.36066)\n",
            "     | > G_subband_stft_loss_mg: 0.76454  (0.75928)\n",
            "     | > G_subband_stft_loss_sc: 0.37386  (0.36954)\n",
            "     | > G_mse_fake_loss: 0.32008  (0.31966)\n",
            "     | > G_loss: 1.95865  (1.95380)\n",
            "     | > G_gen_loss: 1.15845  (1.15465)\n",
            "     | > G_adv_loss: 0.80020  (0.79915)\n",
            "     | > D_mse_gan_loss: 0.44934  (0.44431)\n",
            "     | > D_mse_gan_real_loss: 0.15055  (0.13789)\n",
            "     | > D_mse_gan_fake_loss: 0.13353  (0.13741)\n",
            "     | > D_loss: 0.44934  (0.44431)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 0.0247\n",
            "     | > current_lr_G: 5.933167350882866e-06\n",
            "     | > current_lr_D: 5.933167350882866e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.31 sec -- GLOBAL_STEP: 426019\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81973\n",
            "     | > avg_G_stft_loss_sc: 0.36027\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75926\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36918\n",
            "     | > avg_G_mse_fake_loss: 0.31927\n",
            "     | > avg_G_loss: 1.95239\n",
            "     | > avg_G_gen_loss: 1.15422\n",
            "     | > avg_G_adv_loss: 0.79817\n",
            "     | > avg_D_mse_gan_loss: 0.44445\n",
            "     | > avg_D_mse_gan_real_loss: 0.13769\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13782\n",
            "     | > avg_D_loss: 0.44445\n",
            "     | > avg_loader_time: 0.86944\n",
            "     | > avg_step_time: 0.61339\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78931 \u001b[0m(+0.00136)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37463 \u001b[0m(+0.00642)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70157 \u001b[0m(+0.00017)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37875 \u001b[0m(+0.00353)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.36377 \u001b[0m(-0.01053)\n",
            "     | > avg_G_loss:\u001b[92m 2.03155 \u001b[0m(-0.02060)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12213 \u001b[0m(+0.00574)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.90942 \u001b[0m(-0.02633)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44946 \u001b[0m(-0.00095)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16388 \u001b[0m(-0.03454)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10838 \u001b[0m(+0.02311)\n",
            "     | > avg_D_loss:\u001b[92m 0.44946 \u001b[0m(-0.00095)\n",
            "     | > avg_loader_time:\u001b[92m 0.37215 \u001b[0m(-0.02297)\n",
            "     | > avg_step_time:\u001b[92m 0.04565 \u001b[0m(-0.00528)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 339/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:23:34) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.63 sec -- GLOBAL_STEP: 426140\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81423\n",
            "     | > avg_G_stft_loss_sc: 0.35989\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75501\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36845\n",
            "     | > avg_G_mse_fake_loss: 0.31294\n",
            "     | > avg_G_loss: 1.93114\n",
            "     | > avg_G_gen_loss: 1.14879\n",
            "     | > avg_G_adv_loss: 0.78235\n",
            "     | > avg_D_mse_gan_loss: 0.44763\n",
            "     | > avg_D_mse_gan_real_loss: 0.13818\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13772\n",
            "     | > avg_D_loss: 0.44763\n",
            "     | > avg_loader_time: 0.85696\n",
            "     | > avg_step_time: 0.61600\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78712 \u001b[0m(-0.00218)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36275 \u001b[0m(-0.01188)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70109 \u001b[0m(-0.00048)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38098 \u001b[0m(+0.00222)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32510 \u001b[0m(-0.03867)\n",
            "     | > avg_G_loss:\u001b[92m 1.92872 \u001b[0m(-0.10283)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11597 \u001b[0m(-0.00616)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81275 \u001b[0m(-0.09667)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44166 \u001b[0m(-0.00780)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16064 \u001b[0m(-0.00324)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10765 \u001b[0m(-0.00073)\n",
            "     | > avg_D_loss:\u001b[92m 0.44166 \u001b[0m(-0.00780)\n",
            "     | > avg_loader_time:\u001b[91m 0.42494 \u001b[0m(+0.05278)\n",
            "     | > avg_step_time:\u001b[91m 0.05334 \u001b[0m(+0.00769)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 340/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:26:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.50 sec -- GLOBAL_STEP: 426261\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80285\n",
            "     | > avg_G_stft_loss_sc: 0.35779\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72786\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36685\n",
            "     | > avg_G_mse_fake_loss: 0.31820\n",
            "     | > avg_G_loss: 1.92317\n",
            "     | > avg_G_gen_loss: 1.12767\n",
            "     | > avg_G_adv_loss: 0.79549\n",
            "     | > avg_D_mse_gan_loss: 0.44688\n",
            "     | > avg_D_mse_gan_real_loss: 0.13814\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13830\n",
            "     | > avg_D_loss: 0.44688\n",
            "     | > avg_loader_time: 0.85789\n",
            "     | > avg_step_time: 0.61485\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78601 \u001b[0m(-0.00111)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36570 \u001b[0m(+0.00295)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70017 \u001b[0m(-0.00093)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37841 \u001b[0m(-0.00257)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37452 \u001b[0m(+0.04942)\n",
            "     | > avg_G_loss:\u001b[91m 2.05143 \u001b[0m(+0.12272)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11514 \u001b[0m(-0.00083)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93629 \u001b[0m(+0.12354)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45144 \u001b[0m(+0.00978)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.19254 \u001b[0m(+0.03190)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08995 \u001b[0m(-0.01770)\n",
            "     | > avg_D_loss:\u001b[91m 0.45144 \u001b[0m(+0.00978)\n",
            "     | > avg_loader_time:\u001b[92m 0.39795 \u001b[0m(-0.02699)\n",
            "     | > avg_step_time:\u001b[92m 0.05188 \u001b[0m(-0.00146)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 341/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:29:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.09 sec -- GLOBAL_STEP: 426382\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81589\n",
            "     | > avg_G_stft_loss_sc: 0.35891\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75352\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36775\n",
            "     | > avg_G_mse_fake_loss: 0.31848\n",
            "     | > avg_G_loss: 1.94423\n",
            "     | > avg_G_gen_loss: 1.14803\n",
            "     | > avg_G_adv_loss: 0.79620\n",
            "     | > avg_D_mse_gan_loss: 0.44655\n",
            "     | > avg_D_mse_gan_real_loss: 0.13904\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13842\n",
            "     | > avg_D_loss: 0.44655\n",
            "     | > avg_loader_time: 0.84581\n",
            "     | > avg_step_time: 0.61922\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78701 \u001b[0m(+0.00099)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35967 \u001b[0m(-0.00603)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70039 \u001b[0m(+0.00022)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37589 \u001b[0m(-0.00252)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34815 \u001b[0m(-0.02637)\n",
            "     | > avg_G_loss:\u001b[92m 1.98185 \u001b[0m(-0.06958)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11147 \u001b[0m(-0.00367)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.87037 \u001b[0m(-0.06592)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44876 \u001b[0m(-0.00268)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15981 \u001b[0m(-0.03273)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11417 \u001b[0m(+0.02422)\n",
            "     | > avg_D_loss:\u001b[92m 0.44876 \u001b[0m(-0.00268)\n",
            "     | > avg_loader_time:\u001b[91m 0.41815 \u001b[0m(+0.02020)\n",
            "     | > avg_step_time:\u001b[91m 0.05329 \u001b[0m(+0.00141)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 342/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:32:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.82 sec -- GLOBAL_STEP: 426503\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81164\n",
            "     | > avg_G_stft_loss_sc: 0.36295\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74697\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37138\n",
            "     | > avg_G_mse_fake_loss: 0.31204\n",
            "     | > avg_G_loss: 1.92657\n",
            "     | > avg_G_gen_loss: 1.14647\n",
            "     | > avg_G_adv_loss: 0.78010\n",
            "     | > avg_D_mse_gan_loss: 0.44844\n",
            "     | > avg_D_mse_gan_real_loss: 0.13882\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13794\n",
            "     | > avg_D_loss: 0.44844\n",
            "     | > avg_loader_time: 0.83674\n",
            "     | > avg_step_time: 0.60105\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78583 \u001b[0m(-0.00117)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36435 \u001b[0m(+0.00469)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70061 \u001b[0m(+0.00023)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37851 \u001b[0m(+0.00262)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31335 \u001b[0m(-0.03480)\n",
            "     | > avg_G_loss:\u001b[92m 1.89804 \u001b[0m(-0.08381)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11465 \u001b[0m(+0.00318)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.78338 \u001b[0m(-0.08699)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44502 \u001b[0m(-0.00374)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13616 \u001b[0m(-0.02365)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13148 \u001b[0m(+0.01731)\n",
            "     | > avg_D_loss:\u001b[92m 0.44502 \u001b[0m(-0.00374)\n",
            "     | > avg_loader_time:\u001b[91m 0.44866 \u001b[0m(+0.03051)\n",
            "     | > avg_step_time:\u001b[91m 0.05475 \u001b[0m(+0.00147)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 343/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:36:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.17 sec -- GLOBAL_STEP: 426624\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81957\n",
            "     | > avg_G_stft_loss_sc: 0.35994\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75882\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36914\n",
            "     | > avg_G_mse_fake_loss: 0.31981\n",
            "     | > avg_G_loss: 1.95327\n",
            "     | > avg_G_gen_loss: 1.15374\n",
            "     | > avg_G_adv_loss: 0.79952\n",
            "     | > avg_D_mse_gan_loss: 0.44668\n",
            "     | > avg_D_mse_gan_real_loss: 0.13899\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13816\n",
            "     | > avg_D_loss: 0.44668\n",
            "     | > avg_loader_time: 0.86638\n",
            "     | > avg_step_time: 0.62025\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78846 \u001b[0m(+0.00263)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36104 \u001b[0m(-0.00331)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70223 \u001b[0m(+0.00162)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37630 \u001b[0m(-0.00221)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32265 \u001b[0m(+0.00930)\n",
            "     | > avg_G_loss:\u001b[91m 1.92065 \u001b[0m(+0.02261)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11402 \u001b[0m(-0.00064)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.80663 \u001b[0m(+0.02325)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44598 \u001b[0m(+0.00096)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.13791 \u001b[0m(+0.00174)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13400 \u001b[0m(+0.00252)\n",
            "     | > avg_D_loss:\u001b[91m 0.44598 \u001b[0m(+0.00096)\n",
            "     | > avg_loader_time:\u001b[91m 0.45070 \u001b[0m(+0.00204)\n",
            "     | > avg_step_time:\u001b[92m 0.05265 \u001b[0m(-0.00211)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 344/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:39:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.39 sec -- GLOBAL_STEP: 426745\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81273\n",
            "     | > avg_G_stft_loss_sc: 0.35991\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75143\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36834\n",
            "     | > avg_G_mse_fake_loss: 0.31276\n",
            "     | > avg_G_loss: 1.92812\n",
            "     | > avg_G_gen_loss: 1.14621\n",
            "     | > avg_G_adv_loss: 0.78191\n",
            "     | > avg_D_mse_gan_loss: 0.44747\n",
            "     | > avg_D_mse_gan_real_loss: 0.13825\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13798\n",
            "     | > avg_D_loss: 0.44747\n",
            "     | > avg_loader_time: 0.85475\n",
            "     | > avg_step_time: 0.61392\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79097 \u001b[0m(+0.00251)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36253 \u001b[0m(+0.00149)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70286 \u001b[0m(+0.00063)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37227 \u001b[0m(-0.00403)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34185 \u001b[0m(+0.01919)\n",
            "     | > avg_G_loss:\u001b[91m 1.96893 \u001b[0m(+0.04828)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11432 \u001b[0m(+0.00030)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85461 \u001b[0m(+0.04798)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44261 \u001b[0m(-0.00337)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16337 \u001b[0m(+0.02546)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10390 \u001b[0m(-0.03010)\n",
            "     | > avg_D_loss:\u001b[92m 0.44261 \u001b[0m(-0.00337)\n",
            "     | > avg_loader_time:\u001b[92m 0.41999 \u001b[0m(-0.03071)\n",
            "     | > avg_step_time:\u001b[92m 0.05260 \u001b[0m(-0.00005)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 345/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:42:19) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.47 sec -- GLOBAL_STEP: 426866\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82002\n",
            "     | > avg_G_stft_loss_sc: 0.35871\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75935\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36746\n",
            "     | > avg_G_mse_fake_loss: 0.31742\n",
            "     | > avg_G_loss: 1.94633\n",
            "     | > avg_G_gen_loss: 1.15277\n",
            "     | > avg_G_adv_loss: 0.79355\n",
            "     | > avg_D_mse_gan_loss: 0.44591\n",
            "     | > avg_D_mse_gan_real_loss: 0.13797\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13782\n",
            "     | > avg_D_loss: 0.44591\n",
            "     | > avg_loader_time: 0.85071\n",
            "     | > avg_step_time: 0.61406\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79115 \u001b[0m(+0.00018)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37662 \u001b[0m(+0.01409)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70611 \u001b[0m(+0.00325)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39718 \u001b[0m(+0.02491)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32542 \u001b[0m(-0.01642)\n",
            "     | > avg_G_loss:\u001b[92m 1.94909 \u001b[0m(-0.01984)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13553 \u001b[0m(+0.02122)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81356 \u001b[0m(-0.04105)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44115 \u001b[0m(-0.00145)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14217 \u001b[0m(-0.02120)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12570 \u001b[0m(+0.02180)\n",
            "     | > avg_D_loss:\u001b[92m 0.44115 \u001b[0m(-0.00145)\n",
            "     | > avg_loader_time:\u001b[92m 0.40780 \u001b[0m(-0.01219)\n",
            "     | > avg_step_time:\u001b[92m 0.05033 \u001b[0m(-0.00227)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 346/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:45:27) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.34 sec -- GLOBAL_STEP: 426987\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81878\n",
            "     | > avg_G_stft_loss_sc: 0.35989\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76139\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36836\n",
            "     | > avg_G_mse_fake_loss: 0.31527\n",
            "     | > avg_G_loss: 1.94239\n",
            "     | > avg_G_gen_loss: 1.15421\n",
            "     | > avg_G_adv_loss: 0.78818\n",
            "     | > avg_D_mse_gan_loss: 0.44716\n",
            "     | > avg_D_mse_gan_real_loss: 0.13867\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13798\n",
            "     | > avg_D_loss: 0.44716\n",
            "     | > avg_loader_time: 0.84629\n",
            "     | > avg_step_time: 0.60492\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78844 \u001b[0m(-0.00271)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35943 \u001b[0m(-0.01719)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70001 \u001b[0m(-0.00610)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36735 \u001b[0m(-0.02983)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36058 \u001b[0m(+0.03515)\n",
            "     | > avg_G_loss:\u001b[91m 2.00906 \u001b[0m(+0.05997)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10762 \u001b[0m(-0.02792)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90144 \u001b[0m(+0.08788)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44447 \u001b[0m(+0.00331)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16344 \u001b[0m(+0.02127)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10655 \u001b[0m(-0.01915)\n",
            "     | > avg_D_loss:\u001b[91m 0.44447 \u001b[0m(+0.00331)\n",
            "     | > avg_loader_time:\u001b[92m 0.39941 \u001b[0m(-0.00838)\n",
            "     | > avg_step_time:\u001b[91m 0.05255 \u001b[0m(+0.00222)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 347/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:48:32) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 12/120 -- GLOBAL_STEP: 427000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80527  (0.81582)\n",
            "     | > G_stft_loss_sc: 0.36205  (0.36028)\n",
            "     | > G_subband_stft_loss_mg: 0.74203  (0.75547)\n",
            "     | > G_subband_stft_loss_sc: 0.35833  (0.36867)\n",
            "     | > G_mse_fake_loss: 0.32380  (0.31734)\n",
            "     | > G_loss: 1.94335  (1.94348)\n",
            "     | > G_gen_loss: 1.13384  (1.15012)\n",
            "     | > G_adv_loss: 0.80951  (0.79336)\n",
            "     | > D_mse_gan_loss: 0.45558  (0.44426)\n",
            "     | > D_mse_gan_real_loss: 0.15603  (0.13868)\n",
            "     | > D_mse_gan_fake_loss: 0.13112  (0.13664)\n",
            "     | > D_loss: 0.45558  (0.44426)\n",
            "     | > step_time: 0.61\n",
            "     | > loader_time: 3.7690\n",
            "     | > current_lr_G: 5.879981941110327e-06\n",
            "     | > current_lr_D: 5.879981941110327e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.74 sec -- GLOBAL_STEP: 427108\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81521\n",
            "     | > avg_G_stft_loss_sc: 0.35869\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75470\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36742\n",
            "     | > avg_G_mse_fake_loss: 0.31594\n",
            "     | > avg_G_loss: 1.93786\n",
            "     | > avg_G_gen_loss: 1.14801\n",
            "     | > avg_G_adv_loss: 0.78985\n",
            "     | > avg_D_mse_gan_loss: 0.44536\n",
            "     | > avg_D_mse_gan_real_loss: 0.13762\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13765\n",
            "     | > avg_D_loss: 0.44536\n",
            "     | > avg_loader_time: 0.84690\n",
            "     | > avg_step_time: 0.62440\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79089 \u001b[0m(+0.00245)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37818 \u001b[0m(+0.01875)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70338 \u001b[0m(+0.00337)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38999 \u001b[0m(+0.02264)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35090 \u001b[0m(-0.00968)\n",
            "     | > avg_G_loss:\u001b[92m 2.00847 \u001b[0m(-0.00059)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13122 \u001b[0m(+0.02361)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.87724 \u001b[0m(-0.02420)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44726 \u001b[0m(+0.00279)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15953 \u001b[0m(-0.00391)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11144 \u001b[0m(+0.00490)\n",
            "     | > avg_D_loss:\u001b[91m 0.44726 \u001b[0m(+0.00279)\n",
            "     | > avg_loader_time:\u001b[91m 0.40120 \u001b[0m(+0.00179)\n",
            "     | > avg_step_time:\u001b[91m 0.05263 \u001b[0m(+0.00008)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 348/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:51:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.99 sec -- GLOBAL_STEP: 427229\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80737\n",
            "     | > avg_G_stft_loss_sc: 0.35845\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73804\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36733\n",
            "     | > avg_G_mse_fake_loss: 0.31505\n",
            "     | > avg_G_loss: 1.92321\n",
            "     | > avg_G_gen_loss: 1.13560\n",
            "     | > avg_G_adv_loss: 0.78761\n",
            "     | > avg_D_mse_gan_loss: 0.44773\n",
            "     | > avg_D_mse_gan_real_loss: 0.13894\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13842\n",
            "     | > avg_D_loss: 0.44773\n",
            "     | > avg_loader_time: 0.86966\n",
            "     | > avg_step_time: 0.61950\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.79013 \u001b[0m(-0.00076)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.37551 \u001b[0m(-0.00267)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70196 \u001b[0m(-0.00142)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37849 \u001b[0m(-0.01150)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35441 \u001b[0m(+0.00352)\n",
            "     | > avg_G_loss:\u001b[91m 2.00908 \u001b[0m(+0.00061)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.12305 \u001b[0m(-0.00818)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88603 \u001b[0m(+0.00879)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45252 \u001b[0m(+0.00526)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16421 \u001b[0m(+0.00469)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11222 \u001b[0m(+0.00078)\n",
            "     | > avg_D_loss:\u001b[91m 0.45252 \u001b[0m(+0.00526)\n",
            "     | > avg_loader_time:\u001b[91m 0.42109 \u001b[0m(+0.01989)\n",
            "     | > avg_step_time:\u001b[92m 0.05246 \u001b[0m(-0.00017)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 349/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:54:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.43 sec -- GLOBAL_STEP: 427350\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80482\n",
            "     | > avg_G_stft_loss_sc: 0.35953\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73284\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36855\n",
            "     | > avg_G_mse_fake_loss: 0.31806\n",
            "     | > avg_G_loss: 1.92801\n",
            "     | > avg_G_gen_loss: 1.13287\n",
            "     | > avg_G_adv_loss: 0.79514\n",
            "     | > avg_D_mse_gan_loss: 0.44692\n",
            "     | > avg_D_mse_gan_real_loss: 0.13863\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13778\n",
            "     | > avg_D_loss: 0.44692\n",
            "     | > avg_loader_time: 0.84571\n",
            "     | > avg_step_time: 0.58909\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78665 \u001b[0m(-0.00348)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36888 \u001b[0m(-0.00664)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70202 \u001b[0m(+0.00006)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38744 \u001b[0m(+0.00895)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33384 \u001b[0m(-0.02057)\n",
            "     | > avg_G_loss:\u001b[92m 1.95710 \u001b[0m(-0.05198)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.12250 \u001b[0m(-0.00055)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.83461 \u001b[0m(-0.05143)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44956 \u001b[0m(-0.00295)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16517 \u001b[0m(+0.00096)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11308 \u001b[0m(+0.00086)\n",
            "     | > avg_D_loss:\u001b[92m 0.44956 \u001b[0m(-0.00295)\n",
            "     | > avg_loader_time:\u001b[92m 0.40457 \u001b[0m(-0.01652)\n",
            "     | > avg_step_time:\u001b[92m 0.05035 \u001b[0m(-0.00211)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 350/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:57:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.84 sec -- GLOBAL_STEP: 427471\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81635\n",
            "     | > avg_G_stft_loss_sc: 0.35977\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75586\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36806\n",
            "     | > avg_G_mse_fake_loss: 0.31586\n",
            "     | > avg_G_loss: 1.93968\n",
            "     | > avg_G_gen_loss: 1.15002\n",
            "     | > avg_G_adv_loss: 0.78966\n",
            "     | > avg_D_mse_gan_loss: 0.44617\n",
            "     | > avg_D_mse_gan_real_loss: 0.13803\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13796\n",
            "     | > avg_D_loss: 0.44617\n",
            "     | > avg_loader_time: 0.84860\n",
            "     | > avg_step_time: 0.59973\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79001 \u001b[0m(+0.00336)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37293 \u001b[0m(+0.00405)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70133 \u001b[0m(-0.00070)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36828 \u001b[0m(-0.01916)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34373 \u001b[0m(+0.00988)\n",
            "     | > avg_G_loss:\u001b[91m 1.97558 \u001b[0m(+0.01848)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11627 \u001b[0m(-0.00623)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85931 \u001b[0m(+0.02471)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44692 \u001b[0m(-0.00264)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14369 \u001b[0m(-0.02148)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12407 \u001b[0m(+0.01099)\n",
            "     | > avg_D_loss:\u001b[92m 0.44692 \u001b[0m(-0.00264)\n",
            "     | > avg_loader_time:\u001b[92m 0.40241 \u001b[0m(-0.00216)\n",
            "     | > avg_step_time:\u001b[91m 0.05418 \u001b[0m(+0.00383)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 351/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:01:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.98 sec -- GLOBAL_STEP: 427592\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80621\n",
            "     | > avg_G_stft_loss_sc: 0.35892\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73653\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36785\n",
            "     | > avg_G_mse_fake_loss: 0.31596\n",
            "     | > avg_G_loss: 1.92465\n",
            "     | > avg_G_gen_loss: 1.13475\n",
            "     | > avg_G_adv_loss: 0.78990\n",
            "     | > avg_D_mse_gan_loss: 0.44688\n",
            "     | > avg_D_mse_gan_real_loss: 0.13882\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13802\n",
            "     | > avg_D_loss: 0.44688\n",
            "     | > avg_loader_time: 0.83835\n",
            "     | > avg_step_time: 0.60232\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78593 \u001b[0m(-0.00408)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36097 \u001b[0m(-0.01196)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70098 \u001b[0m(-0.00035)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37859 \u001b[0m(+0.01031)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33781 \u001b[0m(-0.00591)\n",
            "     | > avg_G_loss:\u001b[92m 1.95776 \u001b[0m(-0.01782)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11323 \u001b[0m(-0.00304)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84453 \u001b[0m(-0.01479)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44238 \u001b[0m(-0.00454)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15427 \u001b[0m(+0.01058)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11570 \u001b[0m(-0.00837)\n",
            "     | > avg_D_loss:\u001b[92m 0.44238 \u001b[0m(-0.00454)\n",
            "     | > avg_loader_time:\u001b[91m 0.48486 \u001b[0m(+0.08245)\n",
            "     | > avg_step_time:\u001b[91m 0.05426 \u001b[0m(+0.00008)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 352/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:04:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.47 sec -- GLOBAL_STEP: 427713\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81416\n",
            "     | > avg_G_stft_loss_sc: 0.35758\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75177\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36604\n",
            "     | > avg_G_mse_fake_loss: 0.31698\n",
            "     | > avg_G_loss: 1.93721\n",
            "     | > avg_G_gen_loss: 1.14477\n",
            "     | > avg_G_adv_loss: 0.79244\n",
            "     | > avg_D_mse_gan_loss: 0.44628\n",
            "     | > avg_D_mse_gan_real_loss: 0.13890\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13805\n",
            "     | > avg_D_loss: 0.44628\n",
            "     | > avg_loader_time: 0.84344\n",
            "     | > avg_step_time: 0.59784\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78677 \u001b[0m(+0.00084)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35860 \u001b[0m(-0.00237)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69994 \u001b[0m(-0.00104)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37083 \u001b[0m(-0.00776)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31042 \u001b[0m(-0.02739)\n",
            "     | > avg_G_loss:\u001b[92m 1.88413 \u001b[0m(-0.07363)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10807 \u001b[0m(-0.00516)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.77605 \u001b[0m(-0.06847)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44378 \u001b[0m(+0.00140)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14010 \u001b[0m(-0.01417)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12475 \u001b[0m(+0.00904)\n",
            "     | > avg_D_loss:\u001b[91m 0.44378 \u001b[0m(+0.00140)\n",
            "     | > avg_loader_time:\u001b[92m 0.40931 \u001b[0m(-0.07554)\n",
            "     | > avg_step_time:\u001b[92m 0.04949 \u001b[0m(-0.00477)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 353/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:07:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.98 sec -- GLOBAL_STEP: 427834\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81475\n",
            "     | > avg_G_stft_loss_sc: 0.35935\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75413\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36803\n",
            "     | > avg_G_mse_fake_loss: 0.31648\n",
            "     | > avg_G_loss: 1.93933\n",
            "     | > avg_G_gen_loss: 1.14813\n",
            "     | > avg_G_adv_loss: 0.79120\n",
            "     | > avg_D_mse_gan_loss: 0.44539\n",
            "     | > avg_D_mse_gan_real_loss: 0.13796\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13773\n",
            "     | > avg_D_loss: 0.44539\n",
            "     | > avg_loader_time: 0.84780\n",
            "     | > avg_step_time: 0.60216\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78628 \u001b[0m(-0.00049)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36007 \u001b[0m(+0.00147)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70017 \u001b[0m(+0.00023)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37172 \u001b[0m(+0.00088)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38926 \u001b[0m(+0.07884)\n",
            "     | > avg_G_loss:\u001b[91m 2.08227 \u001b[0m(+0.19814)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10912 \u001b[0m(+0.00104)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.97315 \u001b[0m(+0.19710)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44750 \u001b[0m(+0.00371)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17404 \u001b[0m(+0.03394)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09887 \u001b[0m(-0.02588)\n",
            "     | > avg_D_loss:\u001b[91m 0.44750 \u001b[0m(+0.00371)\n",
            "     | > avg_loader_time:\u001b[92m 0.37445 \u001b[0m(-0.03486)\n",
            "     | > avg_step_time:\u001b[91m 0.05046 \u001b[0m(+0.00097)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 354/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:10:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.52 sec -- GLOBAL_STEP: 427955\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81674\n",
            "     | > avg_G_stft_loss_sc: 0.35925\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75800\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36765\n",
            "     | > avg_G_mse_fake_loss: 0.31571\n",
            "     | > avg_G_loss: 1.94010\n",
            "     | > avg_G_gen_loss: 1.15082\n",
            "     | > avg_G_adv_loss: 0.78928\n",
            "     | > avg_D_mse_gan_loss: 0.44634\n",
            "     | > avg_D_mse_gan_real_loss: 0.13790\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13784\n",
            "     | > avg_D_loss: 0.44634\n",
            "     | > avg_loader_time: 0.83954\n",
            "     | > avg_step_time: 0.59006\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78980 \u001b[0m(+0.00352)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37111 \u001b[0m(+0.01103)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70387 \u001b[0m(+0.00370)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39195 \u001b[0m(+0.02024)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34073 \u001b[0m(-0.04853)\n",
            "     | > avg_G_loss:\u001b[92m 1.98018 \u001b[0m(-0.10209)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12836 \u001b[0m(+0.01924)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85182 \u001b[0m(-0.12133)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44421 \u001b[0m(-0.00329)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16919 \u001b[0m(-0.00485)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10349 \u001b[0m(+0.00462)\n",
            "     | > avg_D_loss:\u001b[92m 0.44421 \u001b[0m(-0.00329)\n",
            "     | > avg_loader_time:\u001b[91m 0.44341 \u001b[0m(+0.06896)\n",
            "     | > avg_step_time:\u001b[91m 0.05123 \u001b[0m(+0.00076)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 355/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:13:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 44/120 -- GLOBAL_STEP: 428000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81467  (0.81443)\n",
            "     | > G_stft_loss_sc: 0.35674  (0.35842)\n",
            "     | > G_subband_stft_loss_mg: 0.75448  (0.75438)\n",
            "     | > G_subband_stft_loss_sc: 0.36266  (0.36662)\n",
            "     | > G_mse_fake_loss: 0.31317  (0.31268)\n",
            "     | > G_loss: 1.92721  (1.92862)\n",
            "     | > G_gen_loss: 1.14428  (1.14693)\n",
            "     | > G_adv_loss: 0.78293  (0.78169)\n",
            "     | > D_mse_gan_loss: 0.45161  (0.44831)\n",
            "     | > D_mse_gan_real_loss: 0.14360  (0.13936)\n",
            "     | > D_mse_gan_fake_loss: 0.14314  (0.13956)\n",
            "     | > D_loss: 0.45161  (0.44831)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 1.9389\n",
            "     | > current_lr_G: 5.833106396208075e-06\n",
            "     | > current_lr_D: 5.833106396208075e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.50 sec -- GLOBAL_STEP: 428076\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81432\n",
            "     | > avg_G_stft_loss_sc: 0.35902\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75453\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36726\n",
            "     | > avg_G_mse_fake_loss: 0.31282\n",
            "     | > avg_G_loss: 1.92960\n",
            "     | > avg_G_gen_loss: 1.14756\n",
            "     | > avg_G_adv_loss: 0.78204\n",
            "     | > avg_D_mse_gan_loss: 0.44793\n",
            "     | > avg_D_mse_gan_real_loss: 0.13878\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13870\n",
            "     | > avg_D_loss: 0.44793\n",
            "     | > avg_loader_time: 0.83960\n",
            "     | > avg_step_time: 0.59847\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78847 \u001b[0m(-0.00133)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35800 \u001b[0m(-0.01311)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70220 \u001b[0m(-0.00166)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37356 \u001b[0m(-0.01840)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35963 \u001b[0m(+0.01890)\n",
            "     | > avg_G_loss:\u001b[91m 2.01018 \u001b[0m(+0.03000)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11112 \u001b[0m(-0.01725)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89906 \u001b[0m(+0.04724)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44707 \u001b[0m(+0.00286)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15185 \u001b[0m(-0.01735)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11841 \u001b[0m(+0.01492)\n",
            "     | > avg_D_loss:\u001b[91m 0.44707 \u001b[0m(+0.00286)\n",
            "     | > avg_loader_time:\u001b[91m 0.46068 \u001b[0m(+0.01727)\n",
            "     | > avg_step_time:\u001b[92m 0.04941 \u001b[0m(-0.00182)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 356/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:16:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.94 sec -- GLOBAL_STEP: 428197\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81415\n",
            "     | > avg_G_stft_loss_sc: 0.35932\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75157\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36820\n",
            "     | > avg_G_mse_fake_loss: 0.31597\n",
            "     | > avg_G_loss: 1.93655\n",
            "     | > avg_G_gen_loss: 1.14663\n",
            "     | > avg_G_adv_loss: 0.78993\n",
            "     | > avg_D_mse_gan_loss: 0.44636\n",
            "     | > avg_D_mse_gan_real_loss: 0.13874\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13792\n",
            "     | > avg_D_loss: 0.44636\n",
            "     | > avg_loader_time: 0.83955\n",
            "     | > avg_step_time: 0.61823\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79020 \u001b[0m(+0.00173)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36963 \u001b[0m(+0.01164)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70195 \u001b[0m(-0.00025)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37856 \u001b[0m(+0.00501)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36455 \u001b[0m(+0.00492)\n",
            "     | > avg_G_loss:\u001b[91m 2.03155 \u001b[0m(+0.02137)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12018 \u001b[0m(+0.00906)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91138 \u001b[0m(+0.01231)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44557 \u001b[0m(-0.00150)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16362 \u001b[0m(+0.01178)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10843 \u001b[0m(-0.00998)\n",
            "     | > avg_D_loss:\u001b[92m 0.44557 \u001b[0m(-0.00150)\n",
            "     | > avg_loader_time:\u001b[92m 0.39335 \u001b[0m(-0.06734)\n",
            "     | > avg_step_time:\u001b[91m 0.04963 \u001b[0m(+0.00022)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 357/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:19:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.53 sec -- GLOBAL_STEP: 428318\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81022\n",
            "     | > avg_G_stft_loss_sc: 0.35830\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74625\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36653\n",
            "     | > avg_G_mse_fake_loss: 0.31286\n",
            "     | > avg_G_loss: 1.92279\n",
            "     | > avg_G_gen_loss: 1.14065\n",
            "     | > avg_G_adv_loss: 0.78214\n",
            "     | > avg_D_mse_gan_loss: 0.44706\n",
            "     | > avg_D_mse_gan_real_loss: 0.13818\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13802\n",
            "     | > avg_D_loss: 0.44706\n",
            "     | > avg_loader_time: 0.84675\n",
            "     | > avg_step_time: 0.61534\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78741 \u001b[0m(-0.00279)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36172 \u001b[0m(-0.00791)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69987 \u001b[0m(-0.00208)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37576 \u001b[0m(-0.00281)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35253 \u001b[0m(-0.01202)\n",
            "     | > avg_G_loss:\u001b[92m 1.99369 \u001b[0m(-0.03786)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11238 \u001b[0m(-0.00780)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88131 \u001b[0m(-0.03006)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44787 \u001b[0m(+0.00230)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18005 \u001b[0m(+0.01643)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09453 \u001b[0m(-0.01390)\n",
            "     | > avg_D_loss:\u001b[91m 0.44787 \u001b[0m(+0.00230)\n",
            "     | > avg_loader_time:\u001b[91m 0.44976 \u001b[0m(+0.05641)\n",
            "     | > avg_step_time:\u001b[91m 0.05167 \u001b[0m(+0.00204)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 358/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:22:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.84 sec -- GLOBAL_STEP: 428439\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81490\n",
            "     | > avg_G_stft_loss_sc: 0.35730\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75638\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36581\n",
            "     | > avg_G_mse_fake_loss: 0.31334\n",
            "     | > avg_G_loss: 1.93054\n",
            "     | > avg_G_gen_loss: 1.14720\n",
            "     | > avg_G_adv_loss: 0.78335\n",
            "     | > avg_D_mse_gan_loss: 0.44752\n",
            "     | > avg_D_mse_gan_real_loss: 0.13826\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13864\n",
            "     | > avg_D_loss: 0.44752\n",
            "     | > avg_loader_time: 0.86960\n",
            "     | > avg_step_time: 0.61617\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78899 \u001b[0m(+0.00158)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36399 \u001b[0m(+0.00227)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70112 \u001b[0m(+0.00124)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37343 \u001b[0m(-0.00232)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36314 \u001b[0m(+0.01062)\n",
            "     | > avg_G_loss:\u001b[91m 2.02162 \u001b[0m(+0.02793)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11377 \u001b[0m(+0.00139)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90785 \u001b[0m(+0.02654)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45032 \u001b[0m(+0.00244)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16111 \u001b[0m(-0.01895)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11144 \u001b[0m(+0.01691)\n",
            "     | > avg_D_loss:\u001b[91m 0.45032 \u001b[0m(+0.00244)\n",
            "     | > avg_loader_time:\u001b[92m 0.38583 \u001b[0m(-0.06392)\n",
            "     | > avg_step_time:\u001b[92m 0.05083 \u001b[0m(-0.00084)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 359/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:25:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.12 sec -- GLOBAL_STEP: 428560\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80296\n",
            "     | > avg_G_stft_loss_sc: 0.35773\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72798\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36698\n",
            "     | > avg_G_mse_fake_loss: 0.31967\n",
            "     | > avg_G_loss: 1.92701\n",
            "     | > avg_G_gen_loss: 1.12783\n",
            "     | > avg_G_adv_loss: 0.79919\n",
            "     | > avg_D_mse_gan_loss: 0.44710\n",
            "     | > avg_D_mse_gan_real_loss: 0.13907\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13803\n",
            "     | > avg_D_loss: 0.44710\n",
            "     | > avg_loader_time: 0.87793\n",
            "     | > avg_step_time: 0.61043\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78843 \u001b[0m(-0.00056)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36631 \u001b[0m(+0.00231)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70234 \u001b[0m(+0.00123)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38397 \u001b[0m(+0.01054)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33025 \u001b[0m(-0.03290)\n",
            "     | > avg_G_loss:\u001b[92m 1.94614 \u001b[0m(-0.07548)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12053 \u001b[0m(+0.00676)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82561 \u001b[0m(-0.08224)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44925 \u001b[0m(-0.00107)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15788 \u001b[0m(-0.00322)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11980 \u001b[0m(+0.00835)\n",
            "     | > avg_D_loss:\u001b[92m 0.44925 \u001b[0m(-0.00107)\n",
            "     | > avg_loader_time:\u001b[91m 0.39357 \u001b[0m(+0.00773)\n",
            "     | > avg_step_time:\u001b[91m 0.05179 \u001b[0m(+0.00095)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 360/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:28:53) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.52 sec -- GLOBAL_STEP: 428681\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81735\n",
            "     | > avg_G_stft_loss_sc: 0.36014\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75747\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36899\n",
            "     | > avg_G_mse_fake_loss: 0.31571\n",
            "     | > avg_G_loss: 1.94124\n",
            "     | > avg_G_gen_loss: 1.15198\n",
            "     | > avg_G_adv_loss: 0.78926\n",
            "     | > avg_D_mse_gan_loss: 0.44725\n",
            "     | > avg_D_mse_gan_real_loss: 0.13919\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13861\n",
            "     | > avg_D_loss: 0.44725\n",
            "     | > avg_loader_time: 0.85075\n",
            "     | > avg_step_time: 0.60726\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78707 \u001b[0m(-0.00136)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36760 \u001b[0m(+0.00130)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70106 \u001b[0m(-0.00128)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38548 \u001b[0m(+0.00151)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31832 \u001b[0m(-0.01192)\n",
            "     | > avg_G_loss:\u001b[92m 1.91641 \u001b[0m(-0.02973)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12061 \u001b[0m(+0.00008)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.79581 \u001b[0m(-0.02981)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44229 \u001b[0m(-0.00696)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13626 \u001b[0m(-0.02163)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13242 \u001b[0m(+0.01263)\n",
            "     | > avg_D_loss:\u001b[92m 0.44229 \u001b[0m(-0.00696)\n",
            "     | > avg_loader_time:\u001b[91m 0.41067 \u001b[0m(+0.01710)\n",
            "     | > avg_step_time:\u001b[91m 0.05591 \u001b[0m(+0.00412)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 361/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:32:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.91 sec -- GLOBAL_STEP: 428802\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81329\n",
            "     | > avg_G_stft_loss_sc: 0.36042\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74986\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36952\n",
            "     | > avg_G_mse_fake_loss: 0.31739\n",
            "     | > avg_G_loss: 1.94001\n",
            "     | > avg_G_gen_loss: 1.14654\n",
            "     | > avg_G_adv_loss: 0.79346\n",
            "     | > avg_D_mse_gan_loss: 0.44642\n",
            "     | > avg_D_mse_gan_real_loss: 0.13843\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13761\n",
            "     | > avg_D_loss: 0.44642\n",
            "     | > avg_loader_time: 0.86443\n",
            "     | > avg_step_time: 0.61791\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78794 \u001b[0m(+0.00088)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35996 \u001b[0m(-0.00764)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70174 \u001b[0m(+0.00068)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37495 \u001b[0m(-0.01053)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34421 \u001b[0m(+0.02589)\n",
            "     | > avg_G_loss:\u001b[91m 1.97284 \u001b[0m(+0.05642)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11230 \u001b[0m(-0.00831)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86054 \u001b[0m(+0.06473)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44317 \u001b[0m(+0.00088)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15070 \u001b[0m(+0.01444)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11704 \u001b[0m(-0.01538)\n",
            "     | > avg_D_loss:\u001b[91m 0.44317 \u001b[0m(+0.00088)\n",
            "     | > avg_loader_time:\u001b[91m 0.42369 \u001b[0m(+0.01303)\n",
            "     | > avg_step_time:\u001b[92m 0.05393 \u001b[0m(-0.00198)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 362/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:35:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.31 sec -- GLOBAL_STEP: 428923\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82044\n",
            "     | > avg_G_stft_loss_sc: 0.35965\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76160\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36864\n",
            "     | > avg_G_mse_fake_loss: 0.31910\n",
            "     | > avg_G_loss: 1.95292\n",
            "     | > avg_G_gen_loss: 1.15517\n",
            "     | > avg_G_adv_loss: 0.79776\n",
            "     | > avg_D_mse_gan_loss: 0.44598\n",
            "     | > avg_D_mse_gan_real_loss: 0.13859\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13841\n",
            "     | > avg_D_loss: 0.44598\n",
            "     | > avg_loader_time: 0.85808\n",
            "     | > avg_step_time: 0.62154\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79013 \u001b[0m(+0.00218)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37119 \u001b[0m(+0.01123)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70176 \u001b[0m(+0.00001)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37357 \u001b[0m(-0.00137)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37592 \u001b[0m(+0.03170)\n",
            "     | > avg_G_loss:\u001b[91m 2.05811 \u001b[0m(+0.08528)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11832 \u001b[0m(+0.00603)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93979 \u001b[0m(+0.07925)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45154 \u001b[0m(+0.00837)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18180 \u001b[0m(+0.03110)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09623 \u001b[0m(-0.02080)\n",
            "     | > avg_D_loss:\u001b[91m 0.45154 \u001b[0m(+0.00837)\n",
            "     | > avg_loader_time:\u001b[91m 0.46452 \u001b[0m(+0.04083)\n",
            "     | > avg_step_time:\u001b[91m 0.05650 \u001b[0m(+0.00258)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 363/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:38:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 76/120 -- GLOBAL_STEP: 429000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80426  (0.80788)\n",
            "     | > G_stft_loss_sc: 0.37307  (0.35913)\n",
            "     | > G_subband_stft_loss_mg: 0.73431  (0.73743)\n",
            "     | > G_subband_stft_loss_sc: 0.38147  (0.36843)\n",
            "     | > G_mse_fake_loss: 0.34040  (0.31841)\n",
            "     | > G_loss: 1.99755  (1.93245)\n",
            "     | > G_gen_loss: 1.14655  (1.13644)\n",
            "     | > G_adv_loss: 0.85100  (0.79602)\n",
            "     | > D_mse_gan_loss: 0.45379  (0.44689)\n",
            "     | > D_mse_gan_real_loss: 0.15649  (0.13911)\n",
            "     | > D_mse_gan_fake_loss: 0.12641  (0.13823)\n",
            "     | > D_loss: 0.45379  (0.44689)\n",
            "     | > step_time: 0.65\n",
            "     | > loader_time: 0.8720\n",
            "     | > current_lr_G: 5.786604545771537e-06\n",
            "     | > current_lr_D: 5.786604545771537e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.00 sec -- GLOBAL_STEP: 429044\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80798\n",
            "     | > avg_G_stft_loss_sc: 0.35893\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73732\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36799\n",
            "     | > avg_G_mse_fake_loss: 0.31830\n",
            "     | > avg_G_loss: 1.93185\n",
            "     | > avg_G_gen_loss: 1.13611\n",
            "     | > avg_G_adv_loss: 0.79574\n",
            "     | > avg_D_mse_gan_loss: 0.44681\n",
            "     | > avg_D_mse_gan_real_loss: 0.13901\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13819\n",
            "     | > avg_D_loss: 0.44681\n",
            "     | > avg_loader_time: 0.88976\n",
            "     | > avg_step_time: 0.63549\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78557 \u001b[0m(-0.00456)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36745 \u001b[0m(-0.00374)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70008 \u001b[0m(-0.00167)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38350 \u001b[0m(+0.00993)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33684 \u001b[0m(-0.03908)\n",
            "     | > avg_G_loss:\u001b[92m 1.96040 \u001b[0m(-0.09771)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11830 \u001b[0m(-0.00002)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84210 \u001b[0m(-0.09769)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44474 \u001b[0m(-0.00680)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15927 \u001b[0m(-0.02253)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11069 \u001b[0m(+0.01445)\n",
            "     | > avg_D_loss:\u001b[92m 0.44474 \u001b[0m(-0.00680)\n",
            "     | > avg_loader_time:\u001b[92m 0.43315 \u001b[0m(-0.03137)\n",
            "     | > avg_step_time:\u001b[92m 0.05364 \u001b[0m(-0.00287)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 364/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:41:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.65 sec -- GLOBAL_STEP: 429165\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80547\n",
            "     | > avg_G_stft_loss_sc: 0.36070\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73505\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36944\n",
            "     | > avg_G_mse_fake_loss: 0.31581\n",
            "     | > avg_G_loss: 1.92485\n",
            "     | > avg_G_gen_loss: 1.13533\n",
            "     | > avg_G_adv_loss: 0.78952\n",
            "     | > avg_D_mse_gan_loss: 0.44825\n",
            "     | > avg_D_mse_gan_real_loss: 0.13942\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13849\n",
            "     | > avg_D_loss: 0.44825\n",
            "     | > avg_loader_time: 0.86018\n",
            "     | > avg_step_time: 0.62182\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78795 \u001b[0m(+0.00238)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37390 \u001b[0m(+0.00645)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70366 \u001b[0m(+0.00358)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39615 \u001b[0m(+0.01264)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.30654 \u001b[0m(-0.03030)\n",
            "     | > avg_G_loss:\u001b[92m 1.89719 \u001b[0m(-0.06321)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13083 \u001b[0m(+0.01252)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.76636 \u001b[0m(-0.07574)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44551 \u001b[0m(+0.00077)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15195 \u001b[0m(-0.00732)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11893 \u001b[0m(+0.00824)\n",
            "     | > avg_D_loss:\u001b[91m 0.44551 \u001b[0m(+0.00077)\n",
            "     | > avg_loader_time:\u001b[92m 0.42972 \u001b[0m(-0.00343)\n",
            "     | > avg_step_time:\u001b[91m 0.05523 \u001b[0m(+0.00159)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 365/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:44:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.83 sec -- GLOBAL_STEP: 429286\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81462\n",
            "     | > avg_G_stft_loss_sc: 0.35756\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75360\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36602\n",
            "     | > avg_G_mse_fake_loss: 0.31402\n",
            "     | > avg_G_loss: 1.93094\n",
            "     | > avg_G_gen_loss: 1.14590\n",
            "     | > avg_G_adv_loss: 0.78504\n",
            "     | > avg_D_mse_gan_loss: 0.44744\n",
            "     | > avg_D_mse_gan_real_loss: 0.13910\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13891\n",
            "     | > avg_D_loss: 0.44744\n",
            "     | > avg_loader_time: 0.85002\n",
            "     | > avg_step_time: 0.60104\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78572 \u001b[0m(-0.00223)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36105 \u001b[0m(-0.01285)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69933 \u001b[0m(-0.00433)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36962 \u001b[0m(-0.02653)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36064 \u001b[0m(+0.05409)\n",
            "     | > avg_G_loss:\u001b[91m 2.00945 \u001b[0m(+0.11226)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10786 \u001b[0m(-0.02297)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90159 \u001b[0m(+0.13523)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44480 \u001b[0m(-0.00072)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17920 \u001b[0m(+0.02725)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09373 \u001b[0m(-0.02520)\n",
            "     | > avg_D_loss:\u001b[92m 0.44480 \u001b[0m(-0.00072)\n",
            "     | > avg_loader_time:\u001b[92m 0.40285 \u001b[0m(-0.02687)\n",
            "     | > avg_step_time:\u001b[92m 0.05058 \u001b[0m(-0.00466)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 366/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:47:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.81 sec -- GLOBAL_STEP: 429407\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81510\n",
            "     | > avg_G_stft_loss_sc: 0.35671\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75555\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36543\n",
            "     | > avg_G_mse_fake_loss: 0.31435\n",
            "     | > avg_G_loss: 1.93226\n",
            "     | > avg_G_gen_loss: 1.14639\n",
            "     | > avg_G_adv_loss: 0.78586\n",
            "     | > avg_D_mse_gan_loss: 0.44717\n",
            "     | > avg_D_mse_gan_real_loss: 0.13839\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13890\n",
            "     | > avg_D_loss: 0.44717\n",
            "     | > avg_loader_time: 0.85933\n",
            "     | > avg_step_time: 0.61666\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78848 \u001b[0m(+0.00276)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36660 \u001b[0m(+0.00556)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70168 \u001b[0m(+0.00235)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37949 \u001b[0m(+0.00987)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37410 \u001b[0m(+0.01347)\n",
            "     | > avg_G_loss:\u001b[91m 2.05339 \u001b[0m(+0.04394)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11813 \u001b[0m(+0.01027)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93526 \u001b[0m(+0.03367)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44977 \u001b[0m(+0.00498)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16692 \u001b[0m(-0.01228)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10602 \u001b[0m(+0.01229)\n",
            "     | > avg_D_loss:\u001b[91m 0.44977 \u001b[0m(+0.00498)\n",
            "     | > avg_loader_time:\u001b[92m 0.38783 \u001b[0m(-0.01502)\n",
            "     | > avg_step_time:\u001b[91m 0.05077 \u001b[0m(+0.00020)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 367/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:50:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.64 sec -- GLOBAL_STEP: 429528\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81248\n",
            "     | > avg_G_stft_loss_sc: 0.35563\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74779\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36462\n",
            "     | > avg_G_mse_fake_loss: 0.31798\n",
            "     | > avg_G_loss: 1.93520\n",
            "     | > avg_G_gen_loss: 1.14026\n",
            "     | > avg_G_adv_loss: 0.79494\n",
            "     | > avg_D_mse_gan_loss: 0.44523\n",
            "     | > avg_D_mse_gan_real_loss: 0.13800\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13746\n",
            "     | > avg_D_loss: 0.44523\n",
            "     | > avg_loader_time: 0.84937\n",
            "     | > avg_step_time: 0.59938\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78600 \u001b[0m(-0.00248)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37195 \u001b[0m(+0.00534)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70009 \u001b[0m(-0.00159)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38772 \u001b[0m(+0.00823)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34488 \u001b[0m(-0.02922)\n",
            "     | > avg_G_loss:\u001b[92m 1.98509 \u001b[0m(-0.06829)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12288 \u001b[0m(+0.00475)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.86221 \u001b[0m(-0.07305)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44333 \u001b[0m(-0.00644)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15239 \u001b[0m(-0.01453)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11350 \u001b[0m(+0.00748)\n",
            "     | > avg_D_loss:\u001b[92m 0.44333 \u001b[0m(-0.00644)\n",
            "     | > avg_loader_time:\u001b[91m 0.41683 \u001b[0m(+0.02899)\n",
            "     | > avg_step_time:\u001b[91m 0.05411 \u001b[0m(+0.00334)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 368/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:54:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.91 sec -- GLOBAL_STEP: 429649\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81376\n",
            "     | > avg_G_stft_loss_sc: 0.35850\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75097\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36711\n",
            "     | > avg_G_mse_fake_loss: 0.31652\n",
            "     | > avg_G_loss: 1.93647\n",
            "     | > avg_G_gen_loss: 1.14517\n",
            "     | > avg_G_adv_loss: 0.79130\n",
            "     | > avg_D_mse_gan_loss: 0.44733\n",
            "     | > avg_D_mse_gan_real_loss: 0.13902\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13829\n",
            "     | > avg_D_loss: 0.44733\n",
            "     | > avg_loader_time: 0.87856\n",
            "     | > avg_step_time: 0.61817\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78606 \u001b[0m(+0.00006)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36458 \u001b[0m(-0.00737)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69973 \u001b[0m(-0.00036)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37205 \u001b[0m(-0.01567)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31469 \u001b[0m(-0.03019)\n",
            "     | > avg_G_loss:\u001b[92m 1.89795 \u001b[0m(-0.08715)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11121 \u001b[0m(-0.01167)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.78673 \u001b[0m(-0.07548)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44173 \u001b[0m(-0.00160)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13762 \u001b[0m(-0.01477)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12959 \u001b[0m(+0.01609)\n",
            "     | > avg_D_loss:\u001b[92m 0.44173 \u001b[0m(-0.00160)\n",
            "     | > avg_loader_time:\u001b[92m 0.40939 \u001b[0m(-0.00744)\n",
            "     | > avg_step_time:\u001b[92m 0.05288 \u001b[0m(-0.00123)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 369/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:57:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.51 sec -- GLOBAL_STEP: 429770\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81602\n",
            "     | > avg_G_stft_loss_sc: 0.35890\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75413\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36749\n",
            "     | > avg_G_mse_fake_loss: 0.31800\n",
            "     | > avg_G_loss: 1.94328\n",
            "     | > avg_G_gen_loss: 1.14827\n",
            "     | > avg_G_adv_loss: 0.79501\n",
            "     | > avg_D_mse_gan_loss: 0.44563\n",
            "     | > avg_D_mse_gan_real_loss: 0.13806\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13751\n",
            "     | > avg_D_loss: 0.44563\n",
            "     | > avg_loader_time: 0.88204\n",
            "     | > avg_step_time: 0.62324\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78576 \u001b[0m(-0.00030)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36130 \u001b[0m(-0.00328)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70003 \u001b[0m(+0.00030)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37506 \u001b[0m(+0.00301)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.31705 \u001b[0m(+0.00236)\n",
            "     | > avg_G_loss:\u001b[91m 1.90370 \u001b[0m(+0.00576)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11108 \u001b[0m(-0.00014)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.79263 \u001b[0m(+0.00589)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44534 \u001b[0m(+0.00361)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.13937 \u001b[0m(+0.00175)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13022 \u001b[0m(+0.00063)\n",
            "     | > avg_D_loss:\u001b[91m 0.44534 \u001b[0m(+0.00361)\n",
            "     | > avg_loader_time:\u001b[92m 0.40899 \u001b[0m(-0.00040)\n",
            "     | > avg_step_time:\u001b[91m 0.05731 \u001b[0m(+0.00443)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 370/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:00:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.21 sec -- GLOBAL_STEP: 429891\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81318\n",
            "     | > avg_G_stft_loss_sc: 0.36154\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75111\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36963\n",
            "     | > avg_G_mse_fake_loss: 0.31450\n",
            "     | > avg_G_loss: 1.93399\n",
            "     | > avg_G_gen_loss: 1.14773\n",
            "     | > avg_G_adv_loss: 0.78626\n",
            "     | > avg_D_mse_gan_loss: 0.44718\n",
            "     | > avg_D_mse_gan_real_loss: 0.13880\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13814\n",
            "     | > avg_D_loss: 0.44718\n",
            "     | > avg_loader_time: 0.89035\n",
            "     | > avg_step_time: 0.63736\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78642 \u001b[0m(+0.00066)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36757 \u001b[0m(+0.00627)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70081 \u001b[0m(+0.00078)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38038 \u001b[0m(+0.00532)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32233 \u001b[0m(+0.00528)\n",
            "     | > avg_G_loss:\u001b[91m 1.92340 \u001b[0m(+0.01970)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11759 \u001b[0m(+0.00651)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.80582 \u001b[0m(+0.01319)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44540 \u001b[0m(+0.00006)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.14175 \u001b[0m(+0.00238)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12998 \u001b[0m(-0.00024)\n",
            "     | > avg_D_loss:\u001b[91m 0.44540 \u001b[0m(+0.00006)\n",
            "     | > avg_loader_time:\u001b[92m 0.40452 \u001b[0m(-0.00447)\n",
            "     | > avg_step_time:\u001b[92m 0.05219 \u001b[0m(-0.00512)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 371/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:03:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 108/120 -- GLOBAL_STEP: 430000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80969  (0.81671)\n",
            "     | > G_stft_loss_sc: 0.36923  (0.35842)\n",
            "     | > G_subband_stft_loss_mg: 0.74269  (0.75651)\n",
            "     | > G_subband_stft_loss_sc: 0.37496  (0.36682)\n",
            "     | > G_mse_fake_loss: 0.31860  (0.31557)\n",
            "     | > G_loss: 1.94479  (1.93814)\n",
            "     | > G_gen_loss: 1.14829  (1.14922)\n",
            "     | > G_adv_loss: 0.79650  (0.78892)\n",
            "     | > D_mse_gan_loss: 0.45221  (0.44616)\n",
            "     | > D_mse_gan_real_loss: 0.14008  (0.13854)\n",
            "     | > D_mse_gan_fake_loss: 0.13865  (0.13770)\n",
            "     | > D_loss: 0.45221  (0.44616)\n",
            "     | > step_time: 0.56\n",
            "     | > loader_time: 1.0965\n",
            "     | > current_lr_G: 5.74047341068753e-06\n",
            "     | > current_lr_D: 5.74047341068753e-06\n",
            " > CHECKPOINT : /mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure/output/multiband-melgan/checkpoint_430000.pth.tar\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.12 sec -- GLOBAL_STEP: 430012\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81638\n",
            "     | > avg_G_stft_loss_sc: 0.35833\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75603\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36685\n",
            "     | > avg_G_mse_fake_loss: 0.31544\n",
            "     | > avg_G_loss: 1.93738\n",
            "     | > avg_G_gen_loss: 1.14879\n",
            "     | > avg_G_adv_loss: 0.78859\n",
            "     | > avg_D_mse_gan_loss: 0.44608\n",
            "     | > avg_D_mse_gan_real_loss: 0.13849\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13778\n",
            "     | > avg_D_loss: 0.44608\n",
            "     | > avg_loader_time: 0.81315\n",
            "     | > avg_step_time: 0.62019\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78745 \u001b[0m(+0.00103)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36621 \u001b[0m(-0.00136)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70086 \u001b[0m(+0.00005)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37384 \u001b[0m(-0.00654)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37463 \u001b[0m(+0.05230)\n",
            "     | > avg_G_loss:\u001b[91m 2.05074 \u001b[0m(+0.12734)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11418 \u001b[0m(-0.00341)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93656 \u001b[0m(+0.13075)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45036 \u001b[0m(+0.00497)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15664 \u001b[0m(+0.01489)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11651 \u001b[0m(-0.01347)\n",
            "     | > avg_D_loss:\u001b[91m 0.45036 \u001b[0m(+0.00497)\n",
            "     | > avg_loader_time:\u001b[92m 0.37473 \u001b[0m(-0.02979)\n",
            "     | > avg_step_time:\u001b[92m 0.04950 \u001b[0m(-0.00269)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 372/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:06:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.80 sec -- GLOBAL_STEP: 430133\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81370\n",
            "     | > avg_G_stft_loss_sc: 0.36117\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75002\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36977\n",
            "     | > avg_G_mse_fake_loss: 0.31627\n",
            "     | > avg_G_loss: 1.93801\n",
            "     | > avg_G_gen_loss: 1.14733\n",
            "     | > avg_G_adv_loss: 0.79068\n",
            "     | > avg_D_mse_gan_loss: 0.44619\n",
            "     | > avg_D_mse_gan_real_loss: 0.13856\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13799\n",
            "     | > avg_D_loss: 0.44619\n",
            "     | > avg_loader_time: 0.84947\n",
            "     | > avg_step_time: 0.60053\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79015 \u001b[0m(+0.00270)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37933 \u001b[0m(+0.01312)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70236 \u001b[0m(+0.00150)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37574 \u001b[0m(+0.00190)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31207 \u001b[0m(-0.06255)\n",
            "     | > avg_G_loss:\u001b[92m 1.90397 \u001b[0m(-0.14677)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12380 \u001b[0m(+0.00962)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.78018 \u001b[0m(-0.15639)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44800 \u001b[0m(-0.00236)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13693 \u001b[0m(-0.01972)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13682 \u001b[0m(+0.02031)\n",
            "     | > avg_D_loss:\u001b[92m 0.44800 \u001b[0m(-0.00236)\n",
            "     | > avg_loader_time:\u001b[91m 0.39587 \u001b[0m(+0.02114)\n",
            "     | > avg_step_time:\u001b[91m 0.05222 \u001b[0m(+0.00272)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 373/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:09:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.33 sec -- GLOBAL_STEP: 430254\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81756\n",
            "     | > avg_G_stft_loss_sc: 0.35644\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75808\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36529\n",
            "     | > avg_G_mse_fake_loss: 0.31523\n",
            "     | > avg_G_loss: 1.93677\n",
            "     | > avg_G_gen_loss: 1.14868\n",
            "     | > avg_G_adv_loss: 0.78808\n",
            "     | > avg_D_mse_gan_loss: 0.44692\n",
            "     | > avg_D_mse_gan_real_loss: 0.13871\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13837\n",
            "     | > avg_D_loss: 0.44692\n",
            "     | > avg_loader_time: 0.85985\n",
            "     | > avg_step_time: 0.60561\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78933 \u001b[0m(-0.00082)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.37172 \u001b[0m(-0.00762)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70219 \u001b[0m(-0.00017)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37668 \u001b[0m(+0.00094)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36450 \u001b[0m(+0.05243)\n",
            "     | > avg_G_loss:\u001b[91m 2.03122 \u001b[0m(+0.12725)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11996 \u001b[0m(-0.00384)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91126 \u001b[0m(+0.13108)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44815 \u001b[0m(+0.00015)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15086 \u001b[0m(+0.01393)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12089 \u001b[0m(-0.01593)\n",
            "     | > avg_D_loss:\u001b[91m 0.44815 \u001b[0m(+0.00015)\n",
            "     | > avg_loader_time:\u001b[91m 0.40015 \u001b[0m(+0.00428)\n",
            "     | > avg_step_time:\u001b[92m 0.05130 \u001b[0m(-0.00091)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 374/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:13:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.21 sec -- GLOBAL_STEP: 430375\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81589\n",
            "     | > avg_G_stft_loss_sc: 0.35880\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75424\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36755\n",
            "     | > avg_G_mse_fake_loss: 0.31578\n",
            "     | > avg_G_loss: 1.93769\n",
            "     | > avg_G_gen_loss: 1.14824\n",
            "     | > avg_G_adv_loss: 0.78945\n",
            "     | > avg_D_mse_gan_loss: 0.44612\n",
            "     | > avg_D_mse_gan_real_loss: 0.13824\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13780\n",
            "     | > avg_D_loss: 0.44612\n",
            "     | > avg_loader_time: 0.85157\n",
            "     | > avg_step_time: 0.59535\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79016 \u001b[0m(+0.00083)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35971 \u001b[0m(-0.01200)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70206 \u001b[0m(-0.00013)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37052 \u001b[0m(-0.00616)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33123 \u001b[0m(-0.03328)\n",
            "     | > avg_G_loss:\u001b[92m 1.93929 \u001b[0m(-0.09193)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11122 \u001b[0m(-0.00873)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82806 \u001b[0m(-0.08320)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.43994 \u001b[0m(-0.00820)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14439 \u001b[0m(-0.00647)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12092 \u001b[0m(+0.00004)\n",
            "     | > avg_D_loss:\u001b[92m 0.43994 \u001b[0m(-0.00820)\n",
            "     | > avg_loader_time:\u001b[91m 0.43435 \u001b[0m(+0.03420)\n",
            "     | > avg_step_time:\u001b[91m 0.05413 \u001b[0m(+0.00282)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 375/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:16:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.60 sec -- GLOBAL_STEP: 430496\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80731\n",
            "     | > avg_G_stft_loss_sc: 0.36312\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74306\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37124\n",
            "     | > avg_G_mse_fake_loss: 0.31122\n",
            "     | > avg_G_loss: 1.92041\n",
            "     | > avg_G_gen_loss: 1.14237\n",
            "     | > avg_G_adv_loss: 0.77804\n",
            "     | > avg_D_mse_gan_loss: 0.44841\n",
            "     | > avg_D_mse_gan_real_loss: 0.13801\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13833\n",
            "     | > avg_D_loss: 0.44841\n",
            "     | > avg_loader_time: 0.85208\n",
            "     | > avg_step_time: 0.59878\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78912 \u001b[0m(-0.00103)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35879 \u001b[0m(-0.00092)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70194 \u001b[0m(-0.00011)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37131 \u001b[0m(+0.00079)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36761 \u001b[0m(+0.03639)\n",
            "     | > avg_G_loss:\u001b[91m 2.02961 \u001b[0m(+0.09032)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11058 \u001b[0m(-0.00064)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91903 \u001b[0m(+0.09096)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44277 \u001b[0m(+0.00282)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18300 \u001b[0m(+0.03861)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08761 \u001b[0m(-0.03332)\n",
            "     | > avg_D_loss:\u001b[91m 0.44277 \u001b[0m(+0.00282)\n",
            "     | > avg_loader_time:\u001b[92m 0.40105 \u001b[0m(-0.03331)\n",
            "     | > avg_step_time:\u001b[92m 0.05113 \u001b[0m(-0.00300)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 376/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:19:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.80 sec -- GLOBAL_STEP: 430617\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81359\n",
            "     | > avg_G_stft_loss_sc: 0.35768\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74913\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36681\n",
            "     | > avg_G_mse_fake_loss: 0.31863\n",
            "     | > avg_G_loss: 1.94018\n",
            "     | > avg_G_gen_loss: 1.14360\n",
            "     | > avg_G_adv_loss: 0.79657\n",
            "     | > avg_D_mse_gan_loss: 0.44610\n",
            "     | > avg_D_mse_gan_real_loss: 0.13844\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13821\n",
            "     | > avg_D_loss: 0.44610\n",
            "     | > avg_loader_time: 0.84834\n",
            "     | > avg_step_time: 0.60932\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78973 \u001b[0m(+0.00061)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36900 \u001b[0m(+0.01021)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70462 \u001b[0m(+0.00268)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38598 \u001b[0m(+0.01467)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32516 \u001b[0m(-0.04245)\n",
            "     | > avg_G_loss:\u001b[92m 1.93756 \u001b[0m(-0.09205)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12466 \u001b[0m(+0.01408)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81290 \u001b[0m(-0.10613)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44483 \u001b[0m(+0.00206)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15577 \u001b[0m(-0.02723)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11974 \u001b[0m(+0.03213)\n",
            "     | > avg_D_loss:\u001b[91m 0.44483 \u001b[0m(+0.00206)\n",
            "     | > avg_loader_time:\u001b[92m 0.39874 \u001b[0m(-0.00231)\n",
            "     | > avg_step_time:\u001b[92m 0.04989 \u001b[0m(-0.00124)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 377/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:22:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.78 sec -- GLOBAL_STEP: 430738\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82093\n",
            "     | > avg_G_stft_loss_sc: 0.36066\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76253\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36935\n",
            "     | > avg_G_mse_fake_loss: 0.31885\n",
            "     | > avg_G_loss: 1.95386\n",
            "     | > avg_G_gen_loss: 1.15673\n",
            "     | > avg_G_adv_loss: 0.79713\n",
            "     | > avg_D_mse_gan_loss: 0.44445\n",
            "     | > avg_D_mse_gan_real_loss: 0.13764\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13761\n",
            "     | > avg_D_loss: 0.44445\n",
            "     | > avg_loader_time: 0.87037\n",
            "     | > avg_step_time: 0.62561\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78520 \u001b[0m(-0.00453)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36235 \u001b[0m(-0.00665)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69879 \u001b[0m(-0.00583)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36989 \u001b[0m(-0.01609)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.40854 \u001b[0m(+0.08338)\n",
            "     | > avg_G_loss:\u001b[91m 2.12947 \u001b[0m(+0.19191)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10811 \u001b[0m(-0.01655)\n",
            "     | > avg_G_adv_loss:\u001b[91m 1.02136 \u001b[0m(+0.20845)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45834 \u001b[0m(+0.01351)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17527 \u001b[0m(+0.01950)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10080 \u001b[0m(-0.01894)\n",
            "     | > avg_D_loss:\u001b[91m 0.45834 \u001b[0m(+0.01351)\n",
            "     | > avg_loader_time:\u001b[91m 0.47715 \u001b[0m(+0.07841)\n",
            "     | > avg_step_time:\u001b[91m 0.05874 \u001b[0m(+0.00885)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 378/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:25:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.65 sec -- GLOBAL_STEP: 430859\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81478\n",
            "     | > avg_G_stft_loss_sc: 0.35809\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75462\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36681\n",
            "     | > avg_G_mse_fake_loss: 0.31515\n",
            "     | > avg_G_loss: 1.93501\n",
            "     | > avg_G_gen_loss: 1.14715\n",
            "     | > avg_G_adv_loss: 0.78786\n",
            "     | > avg_D_mse_gan_loss: 0.44634\n",
            "     | > avg_D_mse_gan_real_loss: 0.13843\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13791\n",
            "     | > avg_D_loss: 0.44634\n",
            "     | > avg_loader_time: 0.87883\n",
            "     | > avg_step_time: 0.63206\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78540 \u001b[0m(+0.00020)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36088 \u001b[0m(-0.00147)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.69956 \u001b[0m(+0.00077)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37626 \u001b[0m(+0.00637)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34582 \u001b[0m(-0.06272)\n",
            "     | > avg_G_loss:\u001b[92m 1.97561 \u001b[0m(-0.15386)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11105 \u001b[0m(+0.00293)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.86456 \u001b[0m(-0.15680)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44315 \u001b[0m(-0.01519)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15829 \u001b[0m(-0.01698)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10825 \u001b[0m(+0.00745)\n",
            "     | > avg_D_loss:\u001b[92m 0.44315 \u001b[0m(-0.01519)\n",
            "     | > avg_loader_time:\u001b[92m 0.42347 \u001b[0m(-0.05368)\n",
            "     | > avg_step_time:\u001b[92m 0.05053 \u001b[0m(-0.00821)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 379/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:28:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.54 sec -- GLOBAL_STEP: 430980\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81700\n",
            "     | > avg_G_stft_loss_sc: 0.35672\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75872\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36504\n",
            "     | > avg_G_mse_fake_loss: 0.31446\n",
            "     | > avg_G_loss: 1.93490\n",
            "     | > avg_G_gen_loss: 1.14874\n",
            "     | > avg_G_adv_loss: 0.78616\n",
            "     | > avg_D_mse_gan_loss: 0.44697\n",
            "     | > avg_D_mse_gan_real_loss: 0.13844\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13829\n",
            "     | > avg_D_loss: 0.44697\n",
            "     | > avg_loader_time: 0.84999\n",
            "     | > avg_step_time: 0.59815\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78698 \u001b[0m(+0.00158)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36669 \u001b[0m(+0.00581)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70100 \u001b[0m(+0.00144)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38253 \u001b[0m(+0.00627)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32441 \u001b[0m(-0.02142)\n",
            "     | > avg_G_loss:\u001b[92m 1.92962 \u001b[0m(-0.04599)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11860 \u001b[0m(+0.00755)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81102 \u001b[0m(-0.05354)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.43994 \u001b[0m(-0.00321)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13016 \u001b[0m(-0.02813)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13474 \u001b[0m(+0.02649)\n",
            "     | > avg_D_loss:\u001b[92m 0.43994 \u001b[0m(-0.00321)\n",
            "     | > avg_loader_time:\u001b[92m 0.40707 \u001b[0m(-0.01640)\n",
            "     | > avg_step_time:\u001b[91m 0.05308 \u001b[0m(+0.00254)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 380/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:31:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 19/120 -- GLOBAL_STEP: 431000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81968  (0.81504)\n",
            "     | > G_stft_loss_sc: 0.35347  (0.36048)\n",
            "     | > G_subband_stft_loss_mg: 0.76395  (0.75335)\n",
            "     | > G_subband_stft_loss_sc: 0.36663  (0.36940)\n",
            "     | > G_mse_fake_loss: 0.29518  (0.31530)\n",
            "     | > G_loss: 1.88981  (1.93739)\n",
            "     | > G_gen_loss: 1.15187  (1.14914)\n",
            "     | > G_adv_loss: 0.73794  (0.78825)\n",
            "     | > D_mse_gan_loss: 0.44384  (0.44748)\n",
            "     | > D_mse_gan_real_loss: 0.10896  (0.13772)\n",
            "     | > D_mse_gan_fake_loss: 0.16742  (0.13908)\n",
            "     | > D_loss: 0.44384  (0.44748)\n",
            "     | > step_time: 0.75\n",
            "     | > loader_time: 0.0070\n",
            "     | > current_lr_G: 5.689015325556938e-06\n",
            "     | > current_lr_D: 5.689015325556938e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.27 sec -- GLOBAL_STEP: 431101\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81455\n",
            "     | > avg_G_stft_loss_sc: 0.35897\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75297\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36785\n",
            "     | > avg_G_mse_fake_loss: 0.31533\n",
            "     | > avg_G_loss: 1.93549\n",
            "     | > avg_G_gen_loss: 1.14717\n",
            "     | > avg_G_adv_loss: 0.78833\n",
            "     | > avg_D_mse_gan_loss: 0.44727\n",
            "     | > avg_D_mse_gan_real_loss: 0.13894\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13820\n",
            "     | > avg_D_loss: 0.44727\n",
            "     | > avg_loader_time: 0.85084\n",
            "     | > avg_step_time: 0.59658\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78858 \u001b[0m(+0.00159)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37644 \u001b[0m(+0.00976)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70404 \u001b[0m(+0.00304)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38937 \u001b[0m(+0.00685)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32687 \u001b[0m(+0.00247)\n",
            "     | > avg_G_loss:\u001b[91m 1.94640 \u001b[0m(+0.01678)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12922 \u001b[0m(+0.01062)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.81718 \u001b[0m(+0.00617)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44387 \u001b[0m(+0.00393)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.13763 \u001b[0m(+0.00747)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.13100 \u001b[0m(-0.00373)\n",
            "     | > avg_D_loss:\u001b[91m 0.44387 \u001b[0m(+0.00393)\n",
            "     | > avg_loader_time:\u001b[91m 0.47072 \u001b[0m(+0.06364)\n",
            "     | > avg_step_time:\u001b[91m 0.05622 \u001b[0m(+0.00315)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 381/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:34:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.67 sec -- GLOBAL_STEP: 431222\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81690\n",
            "     | > avg_G_stft_loss_sc: 0.35937\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75704\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36789\n",
            "     | > avg_G_mse_fake_loss: 0.31538\n",
            "     | > avg_G_loss: 1.93905\n",
            "     | > avg_G_gen_loss: 1.15060\n",
            "     | > avg_G_adv_loss: 0.78845\n",
            "     | > avg_D_mse_gan_loss: 0.44630\n",
            "     | > avg_D_mse_gan_real_loss: 0.13844\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13776\n",
            "     | > avg_D_loss: 0.44630\n",
            "     | > avg_loader_time: 0.82709\n",
            "     | > avg_step_time: 0.58296\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78844 \u001b[0m(-0.00014)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36154 \u001b[0m(-0.01490)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70061 \u001b[0m(-0.00343)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37268 \u001b[0m(-0.01669)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32787 \u001b[0m(+0.00099)\n",
            "     | > avg_G_loss:\u001b[92m 1.93130 \u001b[0m(-0.01510)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11164 \u001b[0m(-0.01758)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.81967 \u001b[0m(+0.00248)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44449 \u001b[0m(+0.00062)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13089 \u001b[0m(-0.00674)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13386 \u001b[0m(+0.00285)\n",
            "     | > avg_D_loss:\u001b[91m 0.44449 \u001b[0m(+0.00062)\n",
            "     | > avg_loader_time:\u001b[92m 0.42609 \u001b[0m(-0.04463)\n",
            "     | > avg_step_time:\u001b[92m 0.05287 \u001b[0m(-0.00335)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 382/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:37:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.32 sec -- GLOBAL_STEP: 431343\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82127\n",
            "     | > avg_G_stft_loss_sc: 0.35810\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76231\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36688\n",
            "     | > avg_G_mse_fake_loss: 0.31989\n",
            "     | > avg_G_loss: 1.95400\n",
            "     | > avg_G_gen_loss: 1.15428\n",
            "     | > avg_G_adv_loss: 0.79971\n",
            "     | > avg_D_mse_gan_loss: 0.44461\n",
            "     | > avg_D_mse_gan_real_loss: 0.13779\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13733\n",
            "     | > avg_D_loss: 0.44461\n",
            "     | > avg_loader_time: 0.84549\n",
            "     | > avg_step_time: 0.59666\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78748 \u001b[0m(-0.00096)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35913 \u001b[0m(-0.00241)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70050 \u001b[0m(-0.00011)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37263 \u001b[0m(-0.00005)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38932 \u001b[0m(+0.06145)\n",
            "     | > avg_G_loss:\u001b[91m 2.08316 \u001b[0m(+0.15186)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10987 \u001b[0m(-0.00176)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.97329 \u001b[0m(+0.15363)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44808 \u001b[0m(+0.00359)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17001 \u001b[0m(+0.03912)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09998 \u001b[0m(-0.03387)\n",
            "     | > avg_D_loss:\u001b[91m 0.44808 \u001b[0m(+0.00359)\n",
            "     | > avg_loader_time:\u001b[91m 0.42891 \u001b[0m(+0.00282)\n",
            "     | > avg_step_time:\u001b[92m 0.04920 \u001b[0m(-0.00367)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 383/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:41:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.04 sec -- GLOBAL_STEP: 431464\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81916\n",
            "     | > avg_G_stft_loss_sc: 0.35819\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76020\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36687\n",
            "     | > avg_G_mse_fake_loss: 0.31759\n",
            "     | > avg_G_loss: 1.94617\n",
            "     | > avg_G_gen_loss: 1.15221\n",
            "     | > avg_G_adv_loss: 0.79396\n",
            "     | > avg_D_mse_gan_loss: 0.44563\n",
            "     | > avg_D_mse_gan_real_loss: 0.13804\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13745\n",
            "     | > avg_D_loss: 0.44563\n",
            "     | > avg_loader_time: 0.83863\n",
            "     | > avg_step_time: 0.58649\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78533 \u001b[0m(-0.00215)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35746 \u001b[0m(-0.00167)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69865 \u001b[0m(-0.00185)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36840 \u001b[0m(-0.00423)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29711 \u001b[0m(-0.09221)\n",
            "     | > avg_G_loss:\u001b[92m 1.84770 \u001b[0m(-0.23546)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10492 \u001b[0m(-0.00495)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74278 \u001b[0m(-0.23051)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44282 \u001b[0m(-0.00526)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12335 \u001b[0m(-0.04667)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14447 \u001b[0m(+0.04448)\n",
            "     | > avg_D_loss:\u001b[92m 0.44282 \u001b[0m(-0.00526)\n",
            "     | > avg_loader_time:\u001b[92m 0.39752 \u001b[0m(-0.03139)\n",
            "     | > avg_step_time:\u001b[92m 0.04854 \u001b[0m(-0.00066)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 384/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:44:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.86 sec -- GLOBAL_STEP: 431585\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81372\n",
            "     | > avg_G_stft_loss_sc: 0.35953\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75166\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36843\n",
            "     | > avg_G_mse_fake_loss: 0.31563\n",
            "     | > avg_G_loss: 1.93576\n",
            "     | > avg_G_gen_loss: 1.14667\n",
            "     | > avg_G_adv_loss: 0.78909\n",
            "     | > avg_D_mse_gan_loss: 0.44608\n",
            "     | > avg_D_mse_gan_real_loss: 0.13823\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13769\n",
            "     | > avg_D_loss: 0.44608\n",
            "     | > avg_loader_time: 0.82425\n",
            "     | > avg_step_time: 0.58500\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78610 \u001b[0m(+0.00077)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36147 \u001b[0m(+0.00401)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70010 \u001b[0m(+0.00144)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37698 \u001b[0m(+0.00858)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35960 \u001b[0m(+0.06249)\n",
            "     | > avg_G_loss:\u001b[91m 2.01133 \u001b[0m(+0.16363)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11232 \u001b[0m(+0.00740)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89900 \u001b[0m(+0.15622)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44112 \u001b[0m(-0.00170)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18135 \u001b[0m(+0.05800)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09003 \u001b[0m(-0.05444)\n",
            "     | > avg_D_loss:\u001b[92m 0.44112 \u001b[0m(-0.00170)\n",
            "     | > avg_loader_time:\u001b[91m 0.43432 \u001b[0m(+0.03680)\n",
            "     | > avg_step_time:\u001b[91m 0.05517 \u001b[0m(+0.00663)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 385/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:47:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.97 sec -- GLOBAL_STEP: 431706\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81522\n",
            "     | > avg_G_stft_loss_sc: 0.36128\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75453\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36962\n",
            "     | > avg_G_mse_fake_loss: 0.31481\n",
            "     | > avg_G_loss: 1.93734\n",
            "     | > avg_G_gen_loss: 1.15033\n",
            "     | > avg_G_adv_loss: 0.78702\n",
            "     | > avg_D_mse_gan_loss: 0.44679\n",
            "     | > avg_D_mse_gan_real_loss: 0.13812\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13758\n",
            "     | > avg_D_loss: 0.44679\n",
            "     | > avg_loader_time: 0.82513\n",
            "     | > avg_step_time: 0.57751\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78916 \u001b[0m(+0.00306)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36242 \u001b[0m(+0.00095)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70203 \u001b[0m(+0.00193)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37203 \u001b[0m(-0.00496)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35938 \u001b[0m(-0.00022)\n",
            "     | > avg_G_loss:\u001b[92m 2.01127 \u001b[0m(-0.00005)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11282 \u001b[0m(+0.00049)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.89846 \u001b[0m(-0.00055)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44168 \u001b[0m(+0.00056)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15666 \u001b[0m(-0.02469)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10785 \u001b[0m(+0.01782)\n",
            "     | > avg_D_loss:\u001b[91m 0.44168 \u001b[0m(+0.00056)\n",
            "     | > avg_loader_time:\u001b[92m 0.38427 \u001b[0m(-0.05005)\n",
            "     | > avg_step_time:\u001b[92m 0.04937 \u001b[0m(-0.00581)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 386/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:50:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.88 sec -- GLOBAL_STEP: 431827\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81992\n",
            "     | > avg_G_stft_loss_sc: 0.35777\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76182\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36631\n",
            "     | > avg_G_mse_fake_loss: 0.31723\n",
            "     | > avg_G_loss: 1.94599\n",
            "     | > avg_G_gen_loss: 1.15291\n",
            "     | > avg_G_adv_loss: 0.79307\n",
            "     | > avg_D_mse_gan_loss: 0.44519\n",
            "     | > avg_D_mse_gan_real_loss: 0.13758\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13751\n",
            "     | > avg_D_loss: 0.44519\n",
            "     | > avg_loader_time: 0.81651\n",
            "     | > avg_step_time: 0.58549\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78794 \u001b[0m(-0.00123)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35940 \u001b[0m(-0.00301)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70174 \u001b[0m(-0.00029)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36801 \u001b[0m(-0.00401)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35369 \u001b[0m(-0.00569)\n",
            "     | > avg_G_loss:\u001b[92m 1.99277 \u001b[0m(-0.01850)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10855 \u001b[0m(-0.00427)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88423 \u001b[0m(-0.01423)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44282 \u001b[0m(+0.00114)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15584 \u001b[0m(-0.00082)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10918 \u001b[0m(+0.00133)\n",
            "     | > avg_D_loss:\u001b[91m 0.44282 \u001b[0m(+0.00114)\n",
            "     | > avg_loader_time:\u001b[91m 0.45814 \u001b[0m(+0.07388)\n",
            "     | > avg_step_time:\u001b[91m 0.05164 \u001b[0m(+0.00227)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 387/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:53:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.61 sec -- GLOBAL_STEP: 431948\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81670\n",
            "     | > avg_G_stft_loss_sc: 0.35699\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75677\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36561\n",
            "     | > avg_G_mse_fake_loss: 0.31559\n",
            "     | > avg_G_loss: 1.93701\n",
            "     | > avg_G_gen_loss: 1.14803\n",
            "     | > avg_G_adv_loss: 0.78897\n",
            "     | > avg_D_mse_gan_loss: 0.44621\n",
            "     | > avg_D_mse_gan_real_loss: 0.13839\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13785\n",
            "     | > avg_D_loss: 0.44621\n",
            "     | > avg_loader_time: 0.82723\n",
            "     | > avg_step_time: 0.58258\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78835 \u001b[0m(+0.00041)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36850 \u001b[0m(+0.00910)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70138 \u001b[0m(-0.00036)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38501 \u001b[0m(+0.01700)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33119 \u001b[0m(-0.02250)\n",
            "     | > avg_G_loss:\u001b[92m 1.94959 \u001b[0m(-0.04318)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12162 \u001b[0m(+0.01308)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82797 \u001b[0m(-0.05626)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44397 \u001b[0m(+0.00115)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13743 \u001b[0m(-0.01842)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13112 \u001b[0m(+0.02194)\n",
            "     | > avg_D_loss:\u001b[91m 0.44397 \u001b[0m(+0.00115)\n",
            "     | > avg_loader_time:\u001b[92m 0.37526 \u001b[0m(-0.08288)\n",
            "     | > avg_step_time:\u001b[92m 0.04826 \u001b[0m(-0.00338)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 388/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:56:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 51/120 -- GLOBAL_STEP: 432000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81073  (0.81376)\n",
            "     | > G_stft_loss_sc: 0.35727  (0.35914)\n",
            "     | > G_subband_stft_loss_mg: 0.75047  (0.75257)\n",
            "     | > G_subband_stft_loss_sc: 0.36331  (0.36753)\n",
            "     | > G_mse_fake_loss: 0.31016  (0.31553)\n",
            "     | > G_loss: 1.91630  (1.93531)\n",
            "     | > G_gen_loss: 1.14089  (1.14650)\n",
            "     | > G_adv_loss: 0.77541  (0.78881)\n",
            "     | > D_mse_gan_loss: 0.44749  (0.44615)\n",
            "     | > D_mse_gan_real_loss: 0.13770  (0.13840)\n",
            "     | > D_mse_gan_fake_loss: 0.14037  (0.13763)\n",
            "     | > D_loss: 0.44749  (0.44615)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 0.0073\n",
            "     | > current_lr_G: 5.643662177194653e-06\n",
            "     | > current_lr_D: 5.643662177194653e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.59 sec -- GLOBAL_STEP: 432069\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81445\n",
            "     | > avg_G_stft_loss_sc: 0.35871\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75366\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36726\n",
            "     | > avg_G_mse_fake_loss: 0.31559\n",
            "     | > avg_G_loss: 1.93603\n",
            "     | > avg_G_gen_loss: 1.14704\n",
            "     | > avg_G_adv_loss: 0.78899\n",
            "     | > avg_D_mse_gan_loss: 0.44602\n",
            "     | > avg_D_mse_gan_real_loss: 0.13825\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13780\n",
            "     | > avg_D_loss: 0.44602\n",
            "     | > avg_loader_time: 0.82775\n",
            "     | > avg_step_time: 0.57418\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78570 \u001b[0m(-0.00265)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35819 \u001b[0m(-0.01031)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69935 \u001b[0m(-0.00203)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36870 \u001b[0m(-0.01631)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35306 \u001b[0m(+0.02187)\n",
            "     | > avg_G_loss:\u001b[91m 1.98863 \u001b[0m(+0.03903)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10597 \u001b[0m(-0.01565)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88265 \u001b[0m(+0.05468)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44505 \u001b[0m(+0.00108)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15492 \u001b[0m(+0.01749)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11602 \u001b[0m(-0.01510)\n",
            "     | > avg_D_loss:\u001b[91m 0.44505 \u001b[0m(+0.00108)\n",
            "     | > avg_loader_time:\u001b[91m 0.40262 \u001b[0m(+0.02736)\n",
            "     | > avg_step_time:\u001b[91m 0.04897 \u001b[0m(+0.00071)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 389/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:59:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.55 sec -- GLOBAL_STEP: 432190\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80823\n",
            "     | > avg_G_stft_loss_sc: 0.35920\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73795\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36865\n",
            "     | > avg_G_mse_fake_loss: 0.32015\n",
            "     | > avg_G_loss: 1.93739\n",
            "     | > avg_G_gen_loss: 1.13702\n",
            "     | > avg_G_adv_loss: 0.80037\n",
            "     | > avg_D_mse_gan_loss: 0.44537\n",
            "     | > avg_D_mse_gan_real_loss: 0.13780\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13738\n",
            "     | > avg_D_loss: 0.44537\n",
            "     | > avg_loader_time: 0.81576\n",
            "     | > avg_step_time: 0.56551\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78639 \u001b[0m(+0.00069)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36192 \u001b[0m(+0.00373)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.69947 \u001b[0m(+0.00012)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.36927 \u001b[0m(+0.00057)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36997 \u001b[0m(+0.01691)\n",
            "     | > avg_G_loss:\u001b[91m 2.03345 \u001b[0m(+0.04482)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10853 \u001b[0m(+0.00256)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.92492 \u001b[0m(+0.04227)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44580 \u001b[0m(+0.00074)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16945 \u001b[0m(+0.01453)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10224 \u001b[0m(-0.01378)\n",
            "     | > avg_D_loss:\u001b[91m 0.44580 \u001b[0m(+0.00074)\n",
            "     | > avg_loader_time:\u001b[91m 0.41684 \u001b[0m(+0.01421)\n",
            "     | > avg_step_time:\u001b[91m 0.04981 \u001b[0m(+0.00083)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 390/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:01:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.71 sec -- GLOBAL_STEP: 432311\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81779\n",
            "     | > avg_G_stft_loss_sc: 0.36194\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75752\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37078\n",
            "     | > avg_G_mse_fake_loss: 0.31820\n",
            "     | > avg_G_loss: 1.94952\n",
            "     | > avg_G_gen_loss: 1.15402\n",
            "     | > avg_G_adv_loss: 0.79550\n",
            "     | > avg_D_mse_gan_loss: 0.44510\n",
            "     | > avg_D_mse_gan_real_loss: 0.13836\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13738\n",
            "     | > avg_D_loss: 0.44510\n",
            "     | > avg_loader_time: 0.82430\n",
            "     | > avg_step_time: 0.58339\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78883 \u001b[0m(+0.00244)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37596 \u001b[0m(+0.01404)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70172 \u001b[0m(+0.00225)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37547 \u001b[0m(+0.00619)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33659 \u001b[0m(-0.03337)\n",
            "     | > avg_G_loss:\u001b[92m 1.96247 \u001b[0m(-0.07097)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12099 \u001b[0m(+0.01246)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84149 \u001b[0m(-0.08343)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44757 \u001b[0m(+0.00177)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14459 \u001b[0m(-0.02485)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12599 \u001b[0m(+0.02374)\n",
            "     | > avg_D_loss:\u001b[91m 0.44757 \u001b[0m(+0.00177)\n",
            "     | > avg_loader_time:\u001b[92m 0.38880 \u001b[0m(-0.02803)\n",
            "     | > avg_step_time:\u001b[92m 0.04683 \u001b[0m(-0.00298)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 391/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:04:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.91 sec -- GLOBAL_STEP: 432432\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82269\n",
            "     | > avg_G_stft_loss_sc: 0.35735\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76392\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36658\n",
            "     | > avg_G_mse_fake_loss: 0.32159\n",
            "     | > avg_G_loss: 1.95926\n",
            "     | > avg_G_gen_loss: 1.15527\n",
            "     | > avg_G_adv_loss: 0.80399\n",
            "     | > avg_D_mse_gan_loss: 0.44374\n",
            "     | > avg_D_mse_gan_real_loss: 0.13793\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13756\n",
            "     | > avg_D_loss: 0.44374\n",
            "     | > avg_loader_time: 0.81684\n",
            "     | > avg_step_time: 0.56860\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78899 \u001b[0m(+0.00016)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37850 \u001b[0m(+0.00253)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70301 \u001b[0m(+0.00129)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39537 \u001b[0m(+0.01991)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36280 \u001b[0m(+0.02621)\n",
            "     | > avg_G_loss:\u001b[91m 2.03993 \u001b[0m(+0.07746)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13293 \u001b[0m(+0.01195)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90700 \u001b[0m(+0.06551)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44550 \u001b[0m(-0.00207)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15932 \u001b[0m(+0.01473)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11140 \u001b[0m(-0.01459)\n",
            "     | > avg_D_loss:\u001b[92m 0.44550 \u001b[0m(-0.00207)\n",
            "     | > avg_loader_time:\u001b[91m 0.42939 \u001b[0m(+0.04059)\n",
            "     | > avg_step_time:\u001b[91m 0.04949 \u001b[0m(+0.00266)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 392/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:07:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.08 sec -- GLOBAL_STEP: 432553\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80869\n",
            "     | > avg_G_stft_loss_sc: 0.35987\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73923\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36851\n",
            "     | > avg_G_mse_fake_loss: 0.31743\n",
            "     | > avg_G_loss: 1.93173\n",
            "     | > avg_G_gen_loss: 1.13815\n",
            "     | > avg_G_adv_loss: 0.79358\n",
            "     | > avg_D_mse_gan_loss: 0.44693\n",
            "     | > avg_D_mse_gan_real_loss: 0.13867\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13867\n",
            "     | > avg_D_loss: 0.44693\n",
            "     | > avg_loader_time: 0.85067\n",
            "     | > avg_step_time: 0.61003\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78765 \u001b[0m(-0.00134)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.37396 \u001b[0m(-0.00454)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70291 \u001b[0m(-0.00010)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.39263 \u001b[0m(-0.00274)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.39213 \u001b[0m(+0.02932)\n",
            "     | > avg_G_loss:\u001b[91m 2.10889 \u001b[0m(+0.06895)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.12857 \u001b[0m(-0.00436)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.98031 \u001b[0m(+0.07331)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45300 \u001b[0m(+0.00750)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.19134 \u001b[0m(+0.03202)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08890 \u001b[0m(-0.02250)\n",
            "     | > avg_D_loss:\u001b[91m 0.45300 \u001b[0m(+0.00750)\n",
            "     | > avg_loader_time:\u001b[92m 0.42938 \u001b[0m(-0.00001)\n",
            "     | > avg_step_time:\u001b[91m 0.05217 \u001b[0m(+0.00268)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 393/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:11:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.35 sec -- GLOBAL_STEP: 432674\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80992\n",
            "     | > avg_G_stft_loss_sc: 0.36231\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74723\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37037\n",
            "     | > avg_G_mse_fake_loss: 0.31225\n",
            "     | > avg_G_loss: 1.92553\n",
            "     | > avg_G_gen_loss: 1.14492\n",
            "     | > avg_G_adv_loss: 0.78062\n",
            "     | > avg_D_mse_gan_loss: 0.44844\n",
            "     | > avg_D_mse_gan_real_loss: 0.13907\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13838\n",
            "     | > avg_D_loss: 0.44844\n",
            "     | > avg_loader_time: 0.87032\n",
            "     | > avg_step_time: 0.62192\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78470 \u001b[0m(-0.00296)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36035 \u001b[0m(-0.01361)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69923 \u001b[0m(-0.00367)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37474 \u001b[0m(-0.01790)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32937 \u001b[0m(-0.06275)\n",
            "     | > avg_G_loss:\u001b[92m 1.93294 \u001b[0m(-0.17595)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10951 \u001b[0m(-0.01907)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82343 \u001b[0m(-0.15688)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44069 \u001b[0m(-0.01230)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13749 \u001b[0m(-0.05385)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12770 \u001b[0m(+0.03880)\n",
            "     | > avg_D_loss:\u001b[92m 0.44069 \u001b[0m(-0.01230)\n",
            "     | > avg_loader_time:\u001b[92m 0.40956 \u001b[0m(-0.01981)\n",
            "     | > avg_step_time:\u001b[92m 0.05142 \u001b[0m(-0.00075)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 394/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:14:11) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.76 sec -- GLOBAL_STEP: 432795\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81806\n",
            "     | > avg_G_stft_loss_sc: 0.36003\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75749\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36882\n",
            "     | > avg_G_mse_fake_loss: 0.31917\n",
            "     | > avg_G_loss: 1.95011\n",
            "     | > avg_G_gen_loss: 1.15219\n",
            "     | > avg_G_adv_loss: 0.79792\n",
            "     | > avg_D_mse_gan_loss: 0.44525\n",
            "     | > avg_D_mse_gan_real_loss: 0.13831\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13744\n",
            "     | > avg_D_loss: 0.44525\n",
            "     | > avg_loader_time: 0.88179\n",
            "     | > avg_step_time: 0.64266\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78851 \u001b[0m(+0.00381)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35809 \u001b[0m(-0.00226)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70254 \u001b[0m(+0.00330)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37478 \u001b[0m(+0.00004)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32795 \u001b[0m(-0.00142)\n",
            "     | > avg_G_loss:\u001b[92m 1.93183 \u001b[0m(-0.00111)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11196 \u001b[0m(+0.00245)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81987 \u001b[0m(-0.00356)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44223 \u001b[0m(+0.00153)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15993 \u001b[0m(+0.02243)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10827 \u001b[0m(-0.01943)\n",
            "     | > avg_D_loss:\u001b[91m 0.44223 \u001b[0m(+0.00153)\n",
            "     | > avg_loader_time:\u001b[91m 0.41775 \u001b[0m(+0.00819)\n",
            "     | > avg_step_time:\u001b[91m 0.05291 \u001b[0m(+0.00149)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 395/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:17:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.15 sec -- GLOBAL_STEP: 432916\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80572\n",
            "     | > avg_G_stft_loss_sc: 0.36122\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73987\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36976\n",
            "     | > avg_G_mse_fake_loss: 0.31191\n",
            "     | > avg_G_loss: 1.91806\n",
            "     | > avg_G_gen_loss: 1.13829\n",
            "     | > avg_G_adv_loss: 0.77977\n",
            "     | > avg_D_mse_gan_loss: 0.44796\n",
            "     | > avg_D_mse_gan_real_loss: 0.13870\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13807\n",
            "     | > avg_D_loss: 0.44796\n",
            "     | > avg_loader_time: 0.86810\n",
            "     | > avg_step_time: 0.61994\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78807 \u001b[0m(-0.00043)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36064 \u001b[0m(+0.00255)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70094 \u001b[0m(-0.00160)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36419 \u001b[0m(-0.01059)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34831 \u001b[0m(+0.02036)\n",
            "     | > avg_G_loss:\u001b[91m 1.97770 \u001b[0m(+0.04587)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10692 \u001b[0m(-0.00504)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.87078 \u001b[0m(+0.05091)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44222 \u001b[0m(-0.00001)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16387 \u001b[0m(+0.00395)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10601 \u001b[0m(-0.00226)\n",
            "     | > avg_D_loss:\u001b[92m 0.44222 \u001b[0m(-0.00001)\n",
            "     | > avg_loader_time:\u001b[92m 0.40931 \u001b[0m(-0.00844)\n",
            "     | > avg_step_time:\u001b[91m 0.05448 \u001b[0m(+0.00157)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 396/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:20:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 83/120 -- GLOBAL_STEP: 433000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.82059  (0.81471)\n",
            "     | > G_stft_loss_sc: 0.34925  (0.35812)\n",
            "     | > G_subband_stft_loss_mg: 0.75859  (0.75310)\n",
            "     | > G_subband_stft_loss_sc: 0.35999  (0.36686)\n",
            "     | > G_mse_fake_loss: 0.30995  (0.31724)\n",
            "     | > G_loss: 1.91909  (1.93950)\n",
            "     | > G_gen_loss: 1.14421  (1.14640)\n",
            "     | > G_adv_loss: 0.77488  (0.79311)\n",
            "     | > D_mse_gan_loss: 0.44190  (0.44599)\n",
            "     | > D_mse_gan_real_loss: 0.13020  (0.13805)\n",
            "     | > D_mse_gan_fake_loss: 0.14510  (0.13753)\n",
            "     | > D_loss: 0.44190  (0.44599)\n",
            "     | > step_time: 0.65\n",
            "     | > loader_time: 0.0064\n",
            "     | > current_lr_G: 5.598670586667716e-06\n",
            "     | > current_lr_D: 5.598670586667716e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.55 sec -- GLOBAL_STEP: 433037\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81438\n",
            "     | > avg_G_stft_loss_sc: 0.35781\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75296\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36672\n",
            "     | > avg_G_mse_fake_loss: 0.31680\n",
            "     | > avg_G_loss: 1.93794\n",
            "     | > avg_G_gen_loss: 1.14593\n",
            "     | > avg_G_adv_loss: 0.79201\n",
            "     | > avg_D_mse_gan_loss: 0.44635\n",
            "     | > avg_D_mse_gan_real_loss: 0.13838\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13753\n",
            "     | > avg_D_loss: 0.44635\n",
            "     | > avg_loader_time: 0.84510\n",
            "     | > avg_step_time: 0.60717\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78891 \u001b[0m(+0.00084)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36410 \u001b[0m(+0.00346)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70148 \u001b[0m(+0.00055)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37654 \u001b[0m(+0.01236)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33915 \u001b[0m(-0.00916)\n",
            "     | > avg_G_loss:\u001b[92m 1.96340 \u001b[0m(-0.01430)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11552 \u001b[0m(+0.00860)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84788 \u001b[0m(-0.02290)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44584 \u001b[0m(+0.00362)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13638 \u001b[0m(-0.02749)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13149 \u001b[0m(+0.02548)\n",
            "     | > avg_D_loss:\u001b[91m 0.44584 \u001b[0m(+0.00362)\n",
            "     | > avg_loader_time:\u001b[92m 0.40311 \u001b[0m(-0.00620)\n",
            "     | > avg_step_time:\u001b[92m 0.05305 \u001b[0m(-0.00142)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 397/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:23:41) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 78.02 sec -- GLOBAL_STEP: 433158\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81658\n",
            "     | > avg_G_stft_loss_sc: 0.35927\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75709\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36781\n",
            "     | > avg_G_mse_fake_loss: 0.31474\n",
            "     | > avg_G_loss: 1.93723\n",
            "     | > avg_G_gen_loss: 1.15038\n",
            "     | > avg_G_adv_loss: 0.78686\n",
            "     | > avg_D_mse_gan_loss: 0.44694\n",
            "     | > avg_D_mse_gan_real_loss: 0.13865\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13813\n",
            "     | > avg_D_loss: 0.44694\n",
            "     | > avg_loader_time: 0.91029\n",
            "     | > avg_step_time: 0.64351\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78813 \u001b[0m(-0.00078)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36550 \u001b[0m(+0.00140)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70065 \u001b[0m(-0.00083)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37258 \u001b[0m(-0.00396)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33678 \u001b[0m(-0.00237)\n",
            "     | > avg_G_loss:\u001b[92m 1.95538 \u001b[0m(-0.00801)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11343 \u001b[0m(-0.00209)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84195 \u001b[0m(-0.00593)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44517 \u001b[0m(-0.00066)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.14763 \u001b[0m(+0.01124)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12390 \u001b[0m(-0.00759)\n",
            "     | > avg_D_loss:\u001b[92m 0.44517 \u001b[0m(-0.00066)\n",
            "     | > avg_loader_time:\u001b[91m 0.44251 \u001b[0m(+0.03940)\n",
            "     | > avg_step_time:\u001b[91m 0.05592 \u001b[0m(+0.00287)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 398/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:27:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.35 sec -- GLOBAL_STEP: 433279\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81747\n",
            "     | > avg_G_stft_loss_sc: 0.35814\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75807\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36685\n",
            "     | > avg_G_mse_fake_loss: 0.31750\n",
            "     | > avg_G_loss: 1.94400\n",
            "     | > avg_G_gen_loss: 1.15026\n",
            "     | > avg_G_adv_loss: 0.79374\n",
            "     | > avg_D_mse_gan_loss: 0.44556\n",
            "     | > avg_D_mse_gan_real_loss: 0.13787\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13766\n",
            "     | > avg_D_loss: 0.44556\n",
            "     | > avg_loader_time: 0.88394\n",
            "     | > avg_step_time: 0.62957\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78493 \u001b[0m(-0.00320)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36305 \u001b[0m(-0.00244)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69887 \u001b[0m(-0.00178)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37057 \u001b[0m(-0.00202)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34499 \u001b[0m(+0.00821)\n",
            "     | > avg_G_loss:\u001b[91m 1.97119 \u001b[0m(+0.01581)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10871 \u001b[0m(-0.00472)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86248 \u001b[0m(+0.02053)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44494 \u001b[0m(-0.00024)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15277 \u001b[0m(+0.00515)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11609 \u001b[0m(-0.00781)\n",
            "     | > avg_D_loss:\u001b[92m 0.44494 \u001b[0m(-0.00024)\n",
            "     | > avg_loader_time:\u001b[92m 0.39398 \u001b[0m(-0.04852)\n",
            "     | > avg_step_time:\u001b[92m 0.05176 \u001b[0m(-0.00416)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 399/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:30:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.74 sec -- GLOBAL_STEP: 433400\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81743\n",
            "     | > avg_G_stft_loss_sc: 0.35782\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75818\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36620\n",
            "     | > avg_G_mse_fake_loss: 0.31549\n",
            "     | > avg_G_loss: 1.93855\n",
            "     | > avg_G_gen_loss: 1.14981\n",
            "     | > avg_G_adv_loss: 0.78874\n",
            "     | > avg_D_mse_gan_loss: 0.44636\n",
            "     | > avg_D_mse_gan_real_loss: 0.13803\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13774\n",
            "     | > avg_D_loss: 0.44636\n",
            "     | > avg_loader_time: 0.88456\n",
            "     | > avg_step_time: 0.63985\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79029 \u001b[0m(+0.00537)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36925 \u001b[0m(+0.00619)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70241 \u001b[0m(+0.00353)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37345 \u001b[0m(+0.00289)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35925 \u001b[0m(+0.01426)\n",
            "     | > avg_G_loss:\u001b[91m 2.01582 \u001b[0m(+0.04463)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11770 \u001b[0m(+0.00899)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89812 \u001b[0m(+0.03564)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44742 \u001b[0m(+0.00248)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16565 \u001b[0m(+0.01287)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10628 \u001b[0m(-0.00981)\n",
            "     | > avg_D_loss:\u001b[91m 0.44742 \u001b[0m(+0.00248)\n",
            "     | > avg_loader_time:\u001b[91m 0.40886 \u001b[0m(+0.01488)\n",
            "     | > avg_step_time:\u001b[92m 0.05093 \u001b[0m(-0.00083)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 400/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:33:29) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.52 sec -- GLOBAL_STEP: 433521\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81494\n",
            "     | > avg_G_stft_loss_sc: 0.35610\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75312\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36495\n",
            "     | > avg_G_mse_fake_loss: 0.31802\n",
            "     | > avg_G_loss: 1.93961\n",
            "     | > avg_G_gen_loss: 1.14455\n",
            "     | > avg_G_adv_loss: 0.79506\n",
            "     | > avg_D_mse_gan_loss: 0.44506\n",
            "     | > avg_D_mse_gan_real_loss: 0.13832\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13714\n",
            "     | > avg_D_loss: 0.44506\n",
            "     | > avg_loader_time: 0.85447\n",
            "     | > avg_step_time: 0.62269\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78588 \u001b[0m(-0.00442)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35546 \u001b[0m(-0.01379)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69932 \u001b[0m(-0.00308)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37051 \u001b[0m(-0.00295)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29788 \u001b[0m(-0.06137)\n",
            "     | > avg_G_loss:\u001b[92m 1.85028 \u001b[0m(-0.16554)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10558 \u001b[0m(-0.01212)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74470 \u001b[0m(-0.15342)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44186 \u001b[0m(-0.00556)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12553 \u001b[0m(-0.04012)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13892 \u001b[0m(+0.03264)\n",
            "     | > avg_D_loss:\u001b[92m 0.44186 \u001b[0m(-0.00556)\n",
            "     | > avg_loader_time:\u001b[91m 0.43313 \u001b[0m(+0.02427)\n",
            "     | > avg_step_time:\u001b[91m 0.05558 \u001b[0m(+0.00465)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 401/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:36:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.03 sec -- GLOBAL_STEP: 433642\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81845\n",
            "     | > avg_G_stft_loss_sc: 0.35963\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75694\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36838\n",
            "     | > avg_G_mse_fake_loss: 0.32049\n",
            "     | > avg_G_loss: 1.95293\n",
            "     | > avg_G_gen_loss: 1.15170\n",
            "     | > avg_G_adv_loss: 0.80123\n",
            "     | > avg_D_mse_gan_loss: 0.44365\n",
            "     | > avg_D_mse_gan_real_loss: 0.13795\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13660\n",
            "     | > avg_D_loss: 0.44365\n",
            "     | > avg_loader_time: 0.88618\n",
            "     | > avg_step_time: 0.62782\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78757 \u001b[0m(+0.00170)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36510 \u001b[0m(+0.00964)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70066 \u001b[0m(+0.00134)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36881 \u001b[0m(-0.00169)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.30028 \u001b[0m(+0.00240)\n",
            "     | > avg_G_loss:\u001b[91m 1.86178 \u001b[0m(+0.01150)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11108 \u001b[0m(+0.00549)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.75071 \u001b[0m(+0.00601)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44192 \u001b[0m(+0.00007)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12536 \u001b[0m(-0.00017)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14163 \u001b[0m(+0.00271)\n",
            "     | > avg_D_loss:\u001b[91m 0.44192 \u001b[0m(+0.00007)\n",
            "     | > avg_loader_time:\u001b[91m 0.44137 \u001b[0m(+0.00825)\n",
            "     | > avg_step_time:\u001b[91m 0.05606 \u001b[0m(+0.00048)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 402/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:39:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 80.45 sec -- GLOBAL_STEP: 433763\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81258\n",
            "     | > avg_G_stft_loss_sc: 0.36160\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75000\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37006\n",
            "     | > avg_G_mse_fake_loss: 0.31450\n",
            "     | > avg_G_loss: 1.93337\n",
            "     | > avg_G_gen_loss: 1.14712\n",
            "     | > avg_G_adv_loss: 0.78625\n",
            "     | > avg_D_mse_gan_loss: 0.44706\n",
            "     | > avg_D_mse_gan_real_loss: 0.13836\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13834\n",
            "     | > avg_D_loss: 0.44706\n",
            "     | > avg_loader_time: 0.91099\n",
            "     | > avg_step_time: 0.66336\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78686 \u001b[0m(-0.00072)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36106 \u001b[0m(-0.00405)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70054 \u001b[0m(-0.00013)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37473 \u001b[0m(+0.00592)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34995 \u001b[0m(+0.04967)\n",
            "     | > avg_G_loss:\u001b[91m 1.98647 \u001b[0m(+0.12469)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11159 \u001b[0m(+0.00052)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.87488 \u001b[0m(+0.12417)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44634 \u001b[0m(+0.00441)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17777 \u001b[0m(+0.05241)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09651 \u001b[0m(-0.04512)\n",
            "     | > avg_D_loss:\u001b[91m 0.44634 \u001b[0m(+0.00441)\n",
            "     | > avg_loader_time:\u001b[92m 0.40725 \u001b[0m(-0.03413)\n",
            "     | > avg_step_time:\u001b[92m 0.05023 \u001b[0m(-0.00583)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 403/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:43:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 82.80 sec -- GLOBAL_STEP: 433884\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81075\n",
            "     | > avg_G_stft_loss_sc: 0.36209\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74693\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37077\n",
            "     | > avg_G_mse_fake_loss: 0.31457\n",
            "     | > avg_G_loss: 1.93169\n",
            "     | > avg_G_gen_loss: 1.14527\n",
            "     | > avg_G_adv_loss: 0.78642\n",
            "     | > avg_D_mse_gan_loss: 0.44668\n",
            "     | > avg_D_mse_gan_real_loss: 0.13833\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13790\n",
            "     | > avg_D_loss: 0.44668\n",
            "     | > avg_loader_time: 0.90612\n",
            "     | > avg_step_time: 0.68355\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78685 \u001b[0m(-0.00000)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36034 \u001b[0m(-0.00072)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70052 \u001b[0m(-0.00002)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37279 \u001b[0m(-0.00194)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35739 \u001b[0m(+0.00744)\n",
            "     | > avg_G_loss:\u001b[91m 2.00372 \u001b[0m(+0.01725)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11025 \u001b[0m(-0.00134)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89347 \u001b[0m(+0.01859)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44865 \u001b[0m(+0.00231)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16130 \u001b[0m(-0.01647)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11312 \u001b[0m(+0.01662)\n",
            "     | > avg_D_loss:\u001b[91m 0.44865 \u001b[0m(+0.00231)\n",
            "     | > avg_loader_time:\u001b[91m 0.43684 \u001b[0m(+0.02959)\n",
            "     | > avg_step_time:\u001b[91m 0.05471 \u001b[0m(+0.00448)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 404/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:46:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 115/120 -- GLOBAL_STEP: 434000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80399  (0.81041)\n",
            "     | > G_stft_loss_sc: 0.36673  (0.36029)\n",
            "     | > G_subband_stft_loss_mg: 0.73263  (0.74769)\n",
            "     | > G_subband_stft_loss_sc: 0.37549  (0.36864)\n",
            "     | > G_mse_fake_loss: 0.29846  (0.31258)\n",
            "     | > G_loss: 1.88556  (1.92496)\n",
            "     | > G_gen_loss: 1.13942  (1.14351)\n",
            "     | > G_adv_loss: 0.74614  (0.78145)\n",
            "     | > D_mse_gan_loss: 0.44587  (0.44765)\n",
            "     | > D_mse_gan_real_loss: 0.12354  (0.13848)\n",
            "     | > D_mse_gan_fake_loss: 0.15396  (0.13784)\n",
            "     | > D_loss: 0.44587  (0.44765)\n",
            "     | > step_time: 0.49\n",
            "     | > loader_time: 0.0059\n",
            "     | > current_lr_G: 5.554037671616842e-06\n",
            "     | > current_lr_D: 5.554037671616842e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.05 sec -- GLOBAL_STEP: 434005\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81054\n",
            "     | > avg_G_stft_loss_sc: 0.36004\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74790\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36834\n",
            "     | > avg_G_mse_fake_loss: 0.31260\n",
            "     | > avg_G_loss: 1.92490\n",
            "     | > avg_G_gen_loss: 1.14341\n",
            "     | > avg_G_adv_loss: 0.78149\n",
            "     | > avg_D_mse_gan_loss: 0.44763\n",
            "     | > avg_D_mse_gan_real_loss: 0.13838\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13801\n",
            "     | > avg_D_loss: 0.44763\n",
            "     | > avg_loader_time: 0.85881\n",
            "     | > avg_step_time: 0.61890\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78650 \u001b[0m(-0.00035)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36507 \u001b[0m(+0.00474)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70011 \u001b[0m(-0.00041)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37633 \u001b[0m(+0.00354)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34227 \u001b[0m(-0.01512)\n",
            "     | > avg_G_loss:\u001b[92m 1.96967 \u001b[0m(-0.03405)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11401 \u001b[0m(+0.00376)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85566 \u001b[0m(-0.03781)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44644 \u001b[0m(-0.00221)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16294 \u001b[0m(+0.00164)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11040 \u001b[0m(-0.00273)\n",
            "     | > avg_D_loss:\u001b[92m 0.44644 \u001b[0m(-0.00221)\n",
            "     | > avg_loader_time:\u001b[92m 0.40251 \u001b[0m(-0.03432)\n",
            "     | > avg_step_time:\u001b[91m 0.05519 \u001b[0m(+0.00047)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 405/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:49:45) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.55 sec -- GLOBAL_STEP: 434126\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80905\n",
            "     | > avg_G_stft_loss_sc: 0.35817\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74292\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36718\n",
            "     | > avg_G_mse_fake_loss: 0.31500\n",
            "     | > avg_G_loss: 1.92617\n",
            "     | > avg_G_gen_loss: 1.13866\n",
            "     | > avg_G_adv_loss: 0.78751\n",
            "     | > avg_D_mse_gan_loss: 0.44725\n",
            "     | > avg_D_mse_gan_real_loss: 0.13791\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13796\n",
            "     | > avg_D_loss: 0.44725\n",
            "     | > avg_loader_time: 0.82642\n",
            "     | > avg_step_time: 0.57418\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79112 \u001b[0m(+0.00461)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.38639 \u001b[0m(+0.02132)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70317 \u001b[0m(+0.00306)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38466 \u001b[0m(+0.00834)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34228 \u001b[0m(+0.00001)\n",
            "     | > avg_G_loss:\u001b[91m 1.98836 \u001b[0m(+0.01869)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13267 \u001b[0m(+0.01866)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85569 \u001b[0m(+0.00003)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44974 \u001b[0m(+0.00330)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16850 \u001b[0m(+0.00556)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10528 \u001b[0m(-0.00512)\n",
            "     | > avg_D_loss:\u001b[91m 0.44974 \u001b[0m(+0.00330)\n",
            "     | > avg_loader_time:\u001b[91m 0.43560 \u001b[0m(+0.03308)\n",
            "     | > avg_step_time:\u001b[92m 0.05047 \u001b[0m(-0.00472)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 406/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:52:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.20 sec -- GLOBAL_STEP: 434247\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80907\n",
            "     | > avg_G_stft_loss_sc: 0.36082\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74564\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36907\n",
            "     | > avg_G_mse_fake_loss: 0.31227\n",
            "     | > avg_G_loss: 1.92296\n",
            "     | > avg_G_gen_loss: 1.14230\n",
            "     | > avg_G_adv_loss: 0.78066\n",
            "     | > avg_D_mse_gan_loss: 0.44802\n",
            "     | > avg_D_mse_gan_real_loss: 0.13855\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13771\n",
            "     | > avg_D_loss: 0.44802\n",
            "     | > avg_loader_time: 0.81352\n",
            "     | > avg_step_time: 0.55456\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78624 \u001b[0m(-0.00488)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36534 \u001b[0m(-0.02105)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70103 \u001b[0m(-0.00213)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.38224 \u001b[0m(-0.00242)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32226 \u001b[0m(-0.02002)\n",
            "     | > avg_G_loss:\u001b[92m 1.92308 \u001b[0m(-0.06528)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11743 \u001b[0m(-0.01524)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.80565 \u001b[0m(-0.05004)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44222 \u001b[0m(-0.00753)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14203 \u001b[0m(-0.02647)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12661 \u001b[0m(+0.02133)\n",
            "     | > avg_D_loss:\u001b[92m 0.44222 \u001b[0m(-0.00753)\n",
            "     | > avg_loader_time:\u001b[92m 0.38623 \u001b[0m(-0.04937)\n",
            "     | > avg_step_time:\u001b[91m 0.05213 \u001b[0m(+0.00166)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 407/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:55:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.06 sec -- GLOBAL_STEP: 434368\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81846\n",
            "     | > avg_G_stft_loss_sc: 0.35829\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75923\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36713\n",
            "     | > avg_G_mse_fake_loss: 0.31860\n",
            "     | > avg_G_loss: 1.94805\n",
            "     | > avg_G_gen_loss: 1.15156\n",
            "     | > avg_G_adv_loss: 0.79649\n",
            "     | > avg_D_mse_gan_loss: 0.44463\n",
            "     | > avg_D_mse_gan_real_loss: 0.13699\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13674\n",
            "     | > avg_D_loss: 0.44463\n",
            "     | > avg_loader_time: 0.82023\n",
            "     | > avg_step_time: 0.58691\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78615 \u001b[0m(-0.00009)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37347 \u001b[0m(+0.00812)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70070 \u001b[0m(-0.00034)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38896 \u001b[0m(+0.00671)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38651 \u001b[0m(+0.06425)\n",
            "     | > avg_G_loss:\u001b[91m 2.09090 \u001b[0m(+0.16782)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12463 \u001b[0m(+0.00721)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.96627 \u001b[0m(+0.16062)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44747 \u001b[0m(+0.00526)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17604 \u001b[0m(+0.03401)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09741 \u001b[0m(-0.02920)\n",
            "     | > avg_D_loss:\u001b[91m 0.44747 \u001b[0m(+0.00526)\n",
            "     | > avg_loader_time:\u001b[91m 0.43519 \u001b[0m(+0.04896)\n",
            "     | > avg_step_time:\u001b[91m 0.05493 \u001b[0m(+0.00280)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 408/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:58:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.50 sec -- GLOBAL_STEP: 434489\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81622\n",
            "     | > avg_G_stft_loss_sc: 0.35738\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75678\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36604\n",
            "     | > avg_G_mse_fake_loss: 0.31562\n",
            "     | > avg_G_loss: 1.93725\n",
            "     | > avg_G_gen_loss: 1.14821\n",
            "     | > avg_G_adv_loss: 0.78904\n",
            "     | > avg_D_mse_gan_loss: 0.44596\n",
            "     | > avg_D_mse_gan_real_loss: 0.13781\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13754\n",
            "     | > avg_D_loss: 0.44596\n",
            "     | > avg_loader_time: 0.80816\n",
            "     | > avg_step_time: 0.56599\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78591 \u001b[0m(-0.00024)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35918 \u001b[0m(-0.01429)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69966 \u001b[0m(-0.00104)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37670 \u001b[0m(-0.01226)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32421 \u001b[0m(-0.06230)\n",
            "     | > avg_G_loss:\u001b[92m 1.92124 \u001b[0m(-0.16966)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11072 \u001b[0m(-0.01391)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81052 \u001b[0m(-0.15575)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44261 \u001b[0m(-0.00486)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15617 \u001b[0m(-0.01987)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11331 \u001b[0m(+0.01590)\n",
            "     | > avg_D_loss:\u001b[92m 0.44261 \u001b[0m(-0.00486)\n",
            "     | > avg_loader_time:\u001b[92m 0.39876 \u001b[0m(-0.03642)\n",
            "     | > avg_step_time:\u001b[92m 0.05100 \u001b[0m(-0.00393)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 409/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:01:34) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.30 sec -- GLOBAL_STEP: 434610\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81162\n",
            "     | > avg_G_stft_loss_sc: 0.35878\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74862\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36739\n",
            "     | > avg_G_mse_fake_loss: 0.31560\n",
            "     | > avg_G_loss: 1.93221\n",
            "     | > avg_G_gen_loss: 1.14320\n",
            "     | > avg_G_adv_loss: 0.78901\n",
            "     | > avg_D_mse_gan_loss: 0.44665\n",
            "     | > avg_D_mse_gan_real_loss: 0.13850\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13831\n",
            "     | > avg_D_loss: 0.44665\n",
            "     | > avg_loader_time: 0.81737\n",
            "     | > avg_step_time: 0.57989\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78651 \u001b[0m(+0.00060)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35780 \u001b[0m(-0.00138)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.69978 \u001b[0m(+0.00013)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37174 \u001b[0m(-0.00496)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34563 \u001b[0m(+0.02143)\n",
            "     | > avg_G_loss:\u001b[91m 1.97200 \u001b[0m(+0.05076)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10791 \u001b[0m(-0.00281)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86409 \u001b[0m(+0.05356)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44285 \u001b[0m(+0.00024)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14660 \u001b[0m(-0.00956)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12240 \u001b[0m(+0.00909)\n",
            "     | > avg_D_loss:\u001b[91m 0.44285 \u001b[0m(+0.00024)\n",
            "     | > avg_loader_time:\u001b[92m 0.38515 \u001b[0m(-0.01361)\n",
            "     | > avg_step_time:\u001b[92m 0.05004 \u001b[0m(-0.00096)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 410/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:04:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.20 sec -- GLOBAL_STEP: 434731\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80039\n",
            "     | > avg_G_stft_loss_sc: 0.35623\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72487\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36520\n",
            "     | > avg_G_mse_fake_loss: 0.31613\n",
            "     | > avg_G_loss: 1.91368\n",
            "     | > avg_G_gen_loss: 1.12335\n",
            "     | > avg_G_adv_loss: 0.79033\n",
            "     | > avg_D_mse_gan_loss: 0.44688\n",
            "     | > avg_D_mse_gan_real_loss: 0.13821\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13762\n",
            "     | > avg_D_loss: 0.44688\n",
            "     | > avg_loader_time: 0.80576\n",
            "     | > avg_step_time: 0.56267\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78829 \u001b[0m(+0.00177)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.35793 \u001b[0m(+0.00013)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70062 \u001b[0m(+0.00084)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36954 \u001b[0m(-0.00220)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36658 \u001b[0m(+0.02095)\n",
            "     | > avg_G_loss:\u001b[91m 2.02463 \u001b[0m(+0.05263)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10818 \u001b[0m(+0.00027)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91645 \u001b[0m(+0.05236)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44016 \u001b[0m(-0.00269)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14545 \u001b[0m(-0.00116)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11306 \u001b[0m(-0.00935)\n",
            "     | > avg_D_loss:\u001b[92m 0.44016 \u001b[0m(-0.00269)\n",
            "     | > avg_loader_time:\u001b[91m 0.38790 \u001b[0m(+0.00275)\n",
            "     | > avg_step_time:\u001b[91m 0.05063 \u001b[0m(+0.00059)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 411/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:07:28) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.62 sec -- GLOBAL_STEP: 434852\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81851\n",
            "     | > avg_G_stft_loss_sc: 0.35828\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75983\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36740\n",
            "     | > avg_G_mse_fake_loss: 0.31972\n",
            "     | > avg_G_loss: 1.95130\n",
            "     | > avg_G_gen_loss: 1.15201\n",
            "     | > avg_G_adv_loss: 0.79930\n",
            "     | > avg_D_mse_gan_loss: 0.44399\n",
            "     | > avg_D_mse_gan_real_loss: 0.13744\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13650\n",
            "     | > avg_D_loss: 0.44399\n",
            "     | > avg_loader_time: 0.81261\n",
            "     | > avg_step_time: 0.56622\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78739 \u001b[0m(-0.00090)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37095 \u001b[0m(+0.01302)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70212 \u001b[0m(+0.00150)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39358 \u001b[0m(+0.02404)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33692 \u001b[0m(-0.02966)\n",
            "     | > avg_G_loss:\u001b[92m 1.96933 \u001b[0m(-0.05530)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12702 \u001b[0m(+0.01884)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84231 \u001b[0m(-0.07414)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.43967 \u001b[0m(-0.00049)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14339 \u001b[0m(-0.00205)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12006 \u001b[0m(+0.00701)\n",
            "     | > avg_D_loss:\u001b[92m 0.43967 \u001b[0m(-0.00049)\n",
            "     | > avg_loader_time:\u001b[91m 0.43594 \u001b[0m(+0.04804)\n",
            "     | > avg_step_time:\u001b[91m 0.05087 \u001b[0m(+0.00024)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 412/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:10:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.08 sec -- GLOBAL_STEP: 434973\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81381\n",
            "     | > avg_G_stft_loss_sc: 0.35805\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75306\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36644\n",
            "     | > avg_G_mse_fake_loss: 0.31482\n",
            "     | > avg_G_loss: 1.93273\n",
            "     | > avg_G_gen_loss: 1.14568\n",
            "     | > avg_G_adv_loss: 0.78705\n",
            "     | > avg_D_mse_gan_loss: 0.44653\n",
            "     | > avg_D_mse_gan_real_loss: 0.13801\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13756\n",
            "     | > avg_D_loss: 0.44653\n",
            "     | > avg_loader_time: 0.80461\n",
            "     | > avg_step_time: 0.57002\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78708 \u001b[0m(-0.00031)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36748 \u001b[0m(-0.00348)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70095 \u001b[0m(-0.00117)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37623 \u001b[0m(-0.01735)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32645 \u001b[0m(-0.01048)\n",
            "     | > avg_G_loss:\u001b[92m 1.93199 \u001b[0m(-0.03734)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11587 \u001b[0m(-0.01115)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81612 \u001b[0m(-0.02619)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44746 \u001b[0m(+0.00779)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14008 \u001b[0m(-0.00331)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13026 \u001b[0m(+0.01020)\n",
            "     | > avg_D_loss:\u001b[91m 0.44746 \u001b[0m(+0.00779)\n",
            "     | > avg_loader_time:\u001b[92m 0.37997 \u001b[0m(-0.05598)\n",
            "     | > avg_step_time:\u001b[92m 0.04620 \u001b[0m(-0.00467)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 413/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:13:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 26/120 -- GLOBAL_STEP: 435000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.78817  (0.80870)\n",
            "     | > G_stft_loss_sc: 0.34768  (0.35984)\n",
            "     | > G_subband_stft_loss_mg: 0.70225  (0.73948)\n",
            "     | > G_subband_stft_loss_sc: 0.36005  (0.36911)\n",
            "     | > G_mse_fake_loss: 0.31085  (0.31931)\n",
            "     | > G_loss: 1.87619  (1.93683)\n",
            "     | > G_gen_loss: 1.09907  (1.13856)\n",
            "     | > G_adv_loss: 0.77712  (0.79826)\n",
            "     | > D_mse_gan_loss: 0.45068  (0.44674)\n",
            "     | > D_mse_gan_real_loss: 0.15232  (0.13965)\n",
            "     | > D_mse_gan_fake_loss: 0.13383  (0.13680)\n",
            "     | > D_loss: 0.45068  (0.44674)\n",
            "     | > step_time: 0.58\n",
            "     | > loader_time: 0.0102\n",
            "     | > current_lr_G: 5.504250812088413e-06\n",
            "     | > current_lr_D: 5.504250812088413e-06\n",
            " > CHECKPOINT : /mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure/output/multiband-melgan/checkpoint_435000.pth.tar\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.53 sec -- GLOBAL_STEP: 435094\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80648\n",
            "     | > avg_G_stft_loss_sc: 0.35942\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73722\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36858\n",
            "     | > avg_G_mse_fake_loss: 0.31706\n",
            "     | > avg_G_loss: 1.92851\n",
            "     | > avg_G_gen_loss: 1.13585\n",
            "     | > avg_G_adv_loss: 0.79266\n",
            "     | > avg_D_mse_gan_loss: 0.44681\n",
            "     | > avg_D_mse_gan_real_loss: 0.13876\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13777\n",
            "     | > avg_D_loss: 0.44681\n",
            "     | > avg_loader_time: 0.74664\n",
            "     | > avg_step_time: 0.57380\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78480 \u001b[0m(-0.00228)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35848 \u001b[0m(-0.00900)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69919 \u001b[0m(-0.00176)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37393 \u001b[0m(-0.00231)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36114 \u001b[0m(+0.03469)\n",
            "     | > avg_G_loss:\u001b[91m 2.01105 \u001b[0m(+0.07906)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10820 \u001b[0m(-0.00767)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90285 \u001b[0m(+0.08673)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44108 \u001b[0m(-0.00637)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15823 \u001b[0m(+0.01815)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10557 \u001b[0m(-0.02469)\n",
            "     | > avg_D_loss:\u001b[92m 0.44108 \u001b[0m(-0.00637)\n",
            "     | > avg_loader_time:\u001b[91m 0.39329 \u001b[0m(+0.01332)\n",
            "     | > avg_step_time:\u001b[92m 0.04594 \u001b[0m(-0.00026)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 414/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:16:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.77 sec -- GLOBAL_STEP: 435215\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81543\n",
            "     | > avg_G_stft_loss_sc: 0.35668\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75609\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36509\n",
            "     | > avg_G_mse_fake_loss: 0.31586\n",
            "     | > avg_G_loss: 1.93631\n",
            "     | > avg_G_gen_loss: 1.14665\n",
            "     | > avg_G_adv_loss: 0.78966\n",
            "     | > avg_D_mse_gan_loss: 0.44557\n",
            "     | > avg_D_mse_gan_real_loss: 0.13776\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13752\n",
            "     | > avg_D_loss: 0.44557\n",
            "     | > avg_loader_time: 0.80089\n",
            "     | > avg_step_time: 0.56726\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78708 \u001b[0m(+0.00228)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36540 \u001b[0m(+0.00692)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70103 \u001b[0m(+0.00183)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38304 \u001b[0m(+0.00911)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35230 \u001b[0m(-0.00884)\n",
            "     | > avg_G_loss:\u001b[92m 1.99903 \u001b[0m(-0.01202)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11827 \u001b[0m(+0.01007)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88076 \u001b[0m(-0.02209)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44130 \u001b[0m(+0.00022)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15885 \u001b[0m(+0.00061)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10847 \u001b[0m(+0.00289)\n",
            "     | > avg_D_loss:\u001b[91m 0.44130 \u001b[0m(+0.00022)\n",
            "     | > avg_loader_time:\u001b[91m 0.40417 \u001b[0m(+0.01088)\n",
            "     | > avg_step_time:\u001b[91m 0.05047 \u001b[0m(+0.00453)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 415/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:19:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.98 sec -- GLOBAL_STEP: 435336\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81928\n",
            "     | > avg_G_stft_loss_sc: 0.35599\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76011\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36479\n",
            "     | > avg_G_mse_fake_loss: 0.31834\n",
            "     | > avg_G_loss: 1.94593\n",
            "     | > avg_G_gen_loss: 1.15008\n",
            "     | > avg_G_adv_loss: 0.79585\n",
            "     | > avg_D_mse_gan_loss: 0.44480\n",
            "     | > avg_D_mse_gan_real_loss: 0.13772\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13737\n",
            "     | > avg_D_loss: 0.44480\n",
            "     | > avg_loader_time: 0.79810\n",
            "     | > avg_step_time: 0.57764\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78544 \u001b[0m(-0.00164)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35430 \u001b[0m(-0.01110)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69950 \u001b[0m(-0.00152)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36748 \u001b[0m(-0.01556)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35199 \u001b[0m(-0.00031)\n",
            "     | > avg_G_loss:\u001b[92m 1.98334 \u001b[0m(-0.01569)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10336 \u001b[0m(-0.01491)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.87998 \u001b[0m(-0.00078)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44357 \u001b[0m(+0.00227)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16470 \u001b[0m(+0.00585)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10256 \u001b[0m(-0.00590)\n",
            "     | > avg_D_loss:\u001b[91m 0.44357 \u001b[0m(+0.00227)\n",
            "     | > avg_loader_time:\u001b[91m 0.40560 \u001b[0m(+0.00143)\n",
            "     | > avg_step_time:\u001b[92m 0.04927 \u001b[0m(-0.00120)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 416/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:22:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.50 sec -- GLOBAL_STEP: 435457\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80733\n",
            "     | > avg_G_stft_loss_sc: 0.35586\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73805\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36452\n",
            "     | > avg_G_mse_fake_loss: 0.31513\n",
            "     | > avg_G_loss: 1.92071\n",
            "     | > avg_G_gen_loss: 1.13288\n",
            "     | > avg_G_adv_loss: 0.78783\n",
            "     | > avg_D_mse_gan_loss: 0.44738\n",
            "     | > avg_D_mse_gan_real_loss: 0.13816\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13778\n",
            "     | > avg_D_loss: 0.44738\n",
            "     | > avg_loader_time: 0.80376\n",
            "     | > avg_step_time: 0.57350\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78630 \u001b[0m(+0.00086)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.35657 \u001b[0m(+0.00228)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70205 \u001b[0m(+0.00254)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37261 \u001b[0m(+0.00514)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34310 \u001b[0m(-0.00889)\n",
            "     | > avg_G_loss:\u001b[92m 1.96652 \u001b[0m(-0.01682)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10877 \u001b[0m(+0.00541)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85775 \u001b[0m(-0.02223)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44411 \u001b[0m(+0.00053)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14860 \u001b[0m(-0.01609)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11827 \u001b[0m(+0.01570)\n",
            "     | > avg_D_loss:\u001b[91m 0.44411 \u001b[0m(+0.00053)\n",
            "     | > avg_loader_time:\u001b[92m 0.38824 \u001b[0m(-0.01736)\n",
            "     | > avg_step_time:\u001b[92m 0.04742 \u001b[0m(-0.00185)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 417/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:25:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.97 sec -- GLOBAL_STEP: 435578\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81592\n",
            "     | > avg_G_stft_loss_sc: 0.35622\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75617\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36466\n",
            "     | > avg_G_mse_fake_loss: 0.31402\n",
            "     | > avg_G_loss: 1.93154\n",
            "     | > avg_G_gen_loss: 1.14649\n",
            "     | > avg_G_adv_loss: 0.78505\n",
            "     | > avg_D_mse_gan_loss: 0.44740\n",
            "     | > avg_D_mse_gan_real_loss: 0.13796\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13799\n",
            "     | > avg_D_loss: 0.44740\n",
            "     | > avg_loader_time: 0.82915\n",
            "     | > avg_step_time: 0.56122\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78766 \u001b[0m(+0.00136)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36304 \u001b[0m(+0.00647)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70171 \u001b[0m(-0.00034)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37362 \u001b[0m(+0.00100)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34432 \u001b[0m(+0.00122)\n",
            "     | > avg_G_loss:\u001b[91m 1.97382 \u001b[0m(+0.00730)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11301 \u001b[0m(+0.00424)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86080 \u001b[0m(+0.00305)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44426 \u001b[0m(+0.00016)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16187 \u001b[0m(+0.01326)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10465 \u001b[0m(-0.01361)\n",
            "     | > avg_D_loss:\u001b[91m 0.44426 \u001b[0m(+0.00016)\n",
            "     | > avg_loader_time:\u001b[92m 0.36093 \u001b[0m(-0.02731)\n",
            "     | > avg_step_time:\u001b[92m 0.04598 \u001b[0m(-0.00144)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 418/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:28:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.24 sec -- GLOBAL_STEP: 435699\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81842\n",
            "     | > avg_G_stft_loss_sc: 0.35596\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75810\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36449\n",
            "     | > avg_G_mse_fake_loss: 0.31882\n",
            "     | > avg_G_loss: 1.94553\n",
            "     | > avg_G_gen_loss: 1.14849\n",
            "     | > avg_G_adv_loss: 0.79704\n",
            "     | > avg_D_mse_gan_loss: 0.44416\n",
            "     | > avg_D_mse_gan_real_loss: 0.13681\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13703\n",
            "     | > avg_D_loss: 0.44416\n",
            "     | > avg_loader_time: 0.80828\n",
            "     | > avg_step_time: 0.56346\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78588 \u001b[0m(-0.00178)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35456 \u001b[0m(-0.00847)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69933 \u001b[0m(-0.00238)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36781 \u001b[0m(-0.00580)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.39488 \u001b[0m(+0.05055)\n",
            "     | > avg_G_loss:\u001b[91m 2.09098 \u001b[0m(+0.11717)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10379 \u001b[0m(-0.00922)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.98719 \u001b[0m(+0.12638)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45136 \u001b[0m(+0.00710)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17809 \u001b[0m(+0.01623)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09629 \u001b[0m(-0.00837)\n",
            "     | > avg_D_loss:\u001b[91m 0.45136 \u001b[0m(+0.00710)\n",
            "     | > avg_loader_time:\u001b[91m 0.42941 \u001b[0m(+0.06848)\n",
            "     | > avg_step_time:\u001b[91m 0.04956 \u001b[0m(+0.00358)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 419/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:30:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 66.91 sec -- GLOBAL_STEP: 435820\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81504\n",
            "     | > avg_G_stft_loss_sc: 0.35945\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75479\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36820\n",
            "     | > avg_G_mse_fake_loss: 0.31585\n",
            "     | > avg_G_loss: 1.93838\n",
            "     | > avg_G_gen_loss: 1.14875\n",
            "     | > avg_G_adv_loss: 0.78963\n",
            "     | > avg_D_mse_gan_loss: 0.44652\n",
            "     | > avg_D_mse_gan_real_loss: 0.13827\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13753\n",
            "     | > avg_D_loss: 0.44652\n",
            "     | > avg_loader_time: 0.79178\n",
            "     | > avg_step_time: 0.55278\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78819 \u001b[0m(+0.00231)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36021 \u001b[0m(+0.00564)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70147 \u001b[0m(+0.00213)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37125 \u001b[0m(+0.00344)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33063 \u001b[0m(-0.06425)\n",
            "     | > avg_G_loss:\u001b[92m 1.93713 \u001b[0m(-0.15385)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11056 \u001b[0m(+0.00676)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82657 \u001b[0m(-0.16062)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44311 \u001b[0m(-0.00825)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15388 \u001b[0m(-0.02421)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10962 \u001b[0m(+0.01333)\n",
            "     | > avg_D_loss:\u001b[92m 0.44311 \u001b[0m(-0.00825)\n",
            "     | > avg_loader_time:\u001b[92m 0.41168 \u001b[0m(-0.01774)\n",
            "     | > avg_step_time:\u001b[91m 0.05389 \u001b[0m(+0.00433)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 420/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:33:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.00 sec -- GLOBAL_STEP: 435941\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80236\n",
            "     | > avg_G_stft_loss_sc: 0.35872\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73043\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36741\n",
            "     | > avg_G_mse_fake_loss: 0.31553\n",
            "     | > avg_G_loss: 1.91827\n",
            "     | > avg_G_gen_loss: 1.12946\n",
            "     | > avg_G_adv_loss: 0.78882\n",
            "     | > avg_D_mse_gan_loss: 0.44662\n",
            "     | > avg_D_mse_gan_real_loss: 0.13768\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13756\n",
            "     | > avg_D_loss: 0.44662\n",
            "     | > avg_loader_time: 0.80877\n",
            "     | > avg_step_time: 0.56942\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78533 \u001b[0m(-0.00286)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35722 \u001b[0m(-0.00298)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70005 \u001b[0m(-0.00142)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37247 \u001b[0m(+0.00122)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35090 \u001b[0m(+0.02027)\n",
            "     | > avg_G_loss:\u001b[91m 1.98478 \u001b[0m(+0.04765)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10754 \u001b[0m(-0.00302)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.87724 \u001b[0m(+0.05067)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44630 \u001b[0m(+0.00318)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18177 \u001b[0m(+0.02789)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09292 \u001b[0m(-0.01670)\n",
            "     | > avg_D_loss:\u001b[91m 0.44630 \u001b[0m(+0.00318)\n",
            "     | > avg_loader_time:\u001b[92m 0.37655 \u001b[0m(-0.03512)\n",
            "     | > avg_step_time:\u001b[91m 0.05409 \u001b[0m(+0.00020)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 421/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:36:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 58/120 -- GLOBAL_STEP: 436000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81101  (0.81335)\n",
            "     | > G_stft_loss_sc: 0.36797  (0.36164)\n",
            "     | > G_subband_stft_loss_mg: 0.75280  (0.75211)\n",
            "     | > G_subband_stft_loss_sc: 0.38028  (0.36993)\n",
            "     | > G_mse_fake_loss: 0.30568  (0.31402)\n",
            "     | > G_loss: 1.92024  (1.93357)\n",
            "     | > G_gen_loss: 1.15604  (1.14851)\n",
            "     | > G_adv_loss: 0.76421  (0.78505)\n",
            "     | > D_mse_gan_loss: 0.44790  (0.44767)\n",
            "     | > D_mse_gan_real_loss: 0.13870  (0.13827)\n",
            "     | > D_mse_gan_fake_loss: 0.13968  (0.13808)\n",
            "     | > D_loss: 0.44790  (0.44767)\n",
            "     | > step_time: 0.57\n",
            "     | > loader_time: 0.0138\n",
            "     | > current_lr_G: 5.460370616761387e-06\n",
            "     | > current_lr_D: 5.460370616761387e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 65.89 sec -- GLOBAL_STEP: 436062\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81324\n",
            "     | > avg_G_stft_loss_sc: 0.35979\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75229\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36780\n",
            "     | > avg_G_mse_fake_loss: 0.31413\n",
            "     | > avg_G_loss: 1.93187\n",
            "     | > avg_G_gen_loss: 1.14655\n",
            "     | > avg_G_adv_loss: 0.78532\n",
            "     | > avg_D_mse_gan_loss: 0.44727\n",
            "     | > avg_D_mse_gan_real_loss: 0.13794\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13807\n",
            "     | > avg_D_loss: 0.44727\n",
            "     | > avg_loader_time: 0.81809\n",
            "     | > avg_step_time: 0.54392\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78595 \u001b[0m(+0.00062)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35633 \u001b[0m(-0.00089)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69916 \u001b[0m(-0.00089)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36688 \u001b[0m(-0.00559)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33327 \u001b[0m(-0.01762)\n",
            "     | > avg_G_loss:\u001b[92m 1.93735 \u001b[0m(-0.04743)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10416 \u001b[0m(-0.00338)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.83319 \u001b[0m(-0.04405)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44117 \u001b[0m(-0.00513)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14312 \u001b[0m(-0.03865)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11861 \u001b[0m(+0.02570)\n",
            "     | > avg_D_loss:\u001b[92m 0.44117 \u001b[0m(-0.00513)\n",
            "     | > avg_loader_time:\u001b[91m 0.46487 \u001b[0m(+0.08831)\n",
            "     | > avg_step_time:\u001b[92m 0.05311 \u001b[0m(-0.00099)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 422/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:39:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.03 sec -- GLOBAL_STEP: 436183\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81074\n",
            "     | > avg_G_stft_loss_sc: 0.35640\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74625\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36543\n",
            "     | > avg_G_mse_fake_loss: 0.31483\n",
            "     | > avg_G_loss: 1.92647\n",
            "     | > avg_G_gen_loss: 1.13941\n",
            "     | > avg_G_adv_loss: 0.78707\n",
            "     | > avg_D_mse_gan_loss: 0.44751\n",
            "     | > avg_D_mse_gan_real_loss: 0.13883\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13819\n",
            "     | > avg_D_loss: 0.44751\n",
            "     | > avg_loader_time: 0.81315\n",
            "     | > avg_step_time: 0.56948\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78810 \u001b[0m(+0.00215)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.35852 \u001b[0m(+0.00219)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70149 \u001b[0m(+0.00233)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37559 \u001b[0m(+0.00871)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34356 \u001b[0m(+0.01029)\n",
            "     | > avg_G_loss:\u001b[91m 1.97076 \u001b[0m(+0.03341)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11185 \u001b[0m(+0.00769)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85891 \u001b[0m(+0.02572)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44769 \u001b[0m(+0.00652)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16089 \u001b[0m(+0.01777)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11039 \u001b[0m(-0.00822)\n",
            "     | > avg_D_loss:\u001b[91m 0.44769 \u001b[0m(+0.00652)\n",
            "     | > avg_loader_time:\u001b[92m 0.37221 \u001b[0m(-0.09265)\n",
            "     | > avg_step_time:\u001b[92m 0.04496 \u001b[0m(-0.00815)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 423/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:42:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 66.32 sec -- GLOBAL_STEP: 436304\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81496\n",
            "     | > avg_G_stft_loss_sc: 0.36043\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75163\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36887\n",
            "     | > avg_G_mse_fake_loss: 0.31453\n",
            "     | > avg_G_loss: 1.93427\n",
            "     | > avg_G_gen_loss: 1.14794\n",
            "     | > avg_G_adv_loss: 0.78633\n",
            "     | > avg_D_mse_gan_loss: 0.44758\n",
            "     | > avg_D_mse_gan_real_loss: 0.13803\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13769\n",
            "     | > avg_D_loss: 0.44758\n",
            "     | > avg_loader_time: 0.80521\n",
            "     | > avg_step_time: 0.54744\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78786 \u001b[0m(-0.00024)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35546 \u001b[0m(-0.00306)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70036 \u001b[0m(-0.00113)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36916 \u001b[0m(-0.00642)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31626 \u001b[0m(-0.02731)\n",
            "     | > avg_G_loss:\u001b[92m 1.89707 \u001b[0m(-0.07369)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10642 \u001b[0m(-0.00543)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.79064 \u001b[0m(-0.06826)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44452 \u001b[0m(-0.00317)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14770 \u001b[0m(-0.01319)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11916 \u001b[0m(+0.00877)\n",
            "     | > avg_D_loss:\u001b[92m 0.44452 \u001b[0m(-0.00317)\n",
            "     | > avg_loader_time:\u001b[91m 0.38692 \u001b[0m(+0.01471)\n",
            "     | > avg_step_time:\u001b[91m 0.05080 \u001b[0m(+0.00585)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 424/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:45:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.22 sec -- GLOBAL_STEP: 436425\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80285\n",
            "     | > avg_G_stft_loss_sc: 0.35755\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72870\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36684\n",
            "     | > avg_G_mse_fake_loss: 0.31881\n",
            "     | > avg_G_loss: 1.92500\n",
            "     | > avg_G_gen_loss: 1.12797\n",
            "     | > avg_G_adv_loss: 0.79703\n",
            "     | > avg_D_mse_gan_loss: 0.44614\n",
            "     | > avg_D_mse_gan_real_loss: 0.13800\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13741\n",
            "     | > avg_D_loss: 0.44614\n",
            "     | > avg_loader_time: 0.80357\n",
            "     | > avg_step_time: 0.57131\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78779 \u001b[0m(-0.00007)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36517 \u001b[0m(+0.00970)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70091 \u001b[0m(+0.00055)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37000 \u001b[0m(+0.00083)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32803 \u001b[0m(+0.01178)\n",
            "     | > avg_G_loss:\u001b[91m 1.93202 \u001b[0m(+0.03495)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11193 \u001b[0m(+0.00551)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.82009 \u001b[0m(+0.02944)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44921 \u001b[0m(+0.00468)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15030 \u001b[0m(+0.00260)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12282 \u001b[0m(+0.00366)\n",
            "     | > avg_D_loss:\u001b[91m 0.44921 \u001b[0m(+0.00468)\n",
            "     | > avg_loader_time:\u001b[91m 0.39536 \u001b[0m(+0.00844)\n",
            "     | > avg_step_time:\u001b[92m 0.04881 \u001b[0m(-0.00199)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 425/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:48:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.43 sec -- GLOBAL_STEP: 436546\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81873\n",
            "     | > avg_G_stft_loss_sc: 0.35724\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75965\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36576\n",
            "     | > avg_G_mse_fake_loss: 0.31789\n",
            "     | > avg_G_loss: 1.94543\n",
            "     | > avg_G_gen_loss: 1.15069\n",
            "     | > avg_G_adv_loss: 0.79473\n",
            "     | > avg_D_mse_gan_loss: 0.44529\n",
            "     | > avg_D_mse_gan_real_loss: 0.13770\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13737\n",
            "     | > avg_D_loss: 0.44529\n",
            "     | > avg_loader_time: 0.80400\n",
            "     | > avg_step_time: 0.56442\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78872 \u001b[0m(+0.00093)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36047 \u001b[0m(-0.00470)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70072 \u001b[0m(-0.00019)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36273 \u001b[0m(-0.00727)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35314 \u001b[0m(+0.02510)\n",
            "     | > avg_G_loss:\u001b[91m 1.98916 \u001b[0m(+0.05714)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10632 \u001b[0m(-0.00561)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88284 \u001b[0m(+0.06275)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44858 \u001b[0m(-0.00063)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15498 \u001b[0m(+0.00468)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11523 \u001b[0m(-0.00759)\n",
            "     | > avg_D_loss:\u001b[92m 0.44858 \u001b[0m(-0.00063)\n",
            "     | > avg_loader_time:\u001b[92m 0.35974 \u001b[0m(-0.03563)\n",
            "     | > avg_step_time:\u001b[92m 0.04452 \u001b[0m(-0.00429)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 426/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:51:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.59 sec -- GLOBAL_STEP: 436667\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81707\n",
            "     | > avg_G_stft_loss_sc: 0.35656\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75572\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36543\n",
            "     | > avg_G_mse_fake_loss: 0.31998\n",
            "     | > avg_G_loss: 1.94735\n",
            "     | > avg_G_gen_loss: 1.14739\n",
            "     | > avg_G_adv_loss: 0.79996\n",
            "     | > avg_D_mse_gan_loss: 0.44452\n",
            "     | > avg_D_mse_gan_real_loss: 0.13827\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13761\n",
            "     | > avg_D_loss: 0.44452\n",
            "     | > avg_loader_time: 0.82054\n",
            "     | > avg_step_time: 0.57420\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78783 \u001b[0m(-0.00089)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36428 \u001b[0m(+0.00381)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70203 \u001b[0m(+0.00131)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38452 \u001b[0m(+0.02179)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33756 \u001b[0m(-0.01557)\n",
            "     | > avg_G_loss:\u001b[92m 1.96323 \u001b[0m(-0.02593)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11933 \u001b[0m(+0.01301)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84390 \u001b[0m(-0.03893)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44238 \u001b[0m(-0.00620)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16029 \u001b[0m(+0.00531)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10816 \u001b[0m(-0.00708)\n",
            "     | > avg_D_loss:\u001b[92m 0.44238 \u001b[0m(-0.00620)\n",
            "     | > avg_loader_time:\u001b[91m 0.40210 \u001b[0m(+0.04236)\n",
            "     | > avg_step_time:\u001b[91m 0.04926 \u001b[0m(+0.00474)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 427/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:54:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.04 sec -- GLOBAL_STEP: 436788\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81152\n",
            "     | > avg_G_stft_loss_sc: 0.36032\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74744\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36943\n",
            "     | > avg_G_mse_fake_loss: 0.31737\n",
            "     | > avg_G_loss: 1.93778\n",
            "     | > avg_G_gen_loss: 1.14435\n",
            "     | > avg_G_adv_loss: 0.79343\n",
            "     | > avg_D_mse_gan_loss: 0.44650\n",
            "     | > avg_D_mse_gan_real_loss: 0.13815\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13810\n",
            "     | > avg_D_loss: 0.44650\n",
            "     | > avg_loader_time: 0.81290\n",
            "     | > avg_step_time: 0.57015\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79150 \u001b[0m(+0.00367)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37106 \u001b[0m(+0.00677)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70321 \u001b[0m(+0.00118)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37138 \u001b[0m(-0.01314)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35577 \u001b[0m(+0.01821)\n",
            "     | > avg_G_loss:\u001b[91m 2.00800 \u001b[0m(+0.04476)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11858 \u001b[0m(-0.00076)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88942 \u001b[0m(+0.04552)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44821 \u001b[0m(+0.00583)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17092 \u001b[0m(+0.01063)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10330 \u001b[0m(-0.00486)\n",
            "     | > avg_D_loss:\u001b[91m 0.44821 \u001b[0m(+0.00583)\n",
            "     | > avg_loader_time:\u001b[92m 0.38211 \u001b[0m(-0.01999)\n",
            "     | > avg_step_time:\u001b[92m 0.04604 \u001b[0m(-0.00321)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 428/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:57:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.98 sec -- GLOBAL_STEP: 436909\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81971\n",
            "     | > avg_G_stft_loss_sc: 0.35861\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76028\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36728\n",
            "     | > avg_G_mse_fake_loss: 0.31924\n",
            "     | > avg_G_loss: 1.95105\n",
            "     | > avg_G_gen_loss: 1.15294\n",
            "     | > avg_G_adv_loss: 0.79811\n",
            "     | > avg_D_mse_gan_loss: 0.44461\n",
            "     | > avg_D_mse_gan_real_loss: 0.13779\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13758\n",
            "     | > avg_D_loss: 0.44461\n",
            "     | > avg_loader_time: 0.82415\n",
            "     | > avg_step_time: 0.56957\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.79040 \u001b[0m(-0.00110)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.38497 \u001b[0m(+0.01392)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70385 \u001b[0m(+0.00064)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39245 \u001b[0m(+0.02107)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33859 \u001b[0m(-0.01718)\n",
            "     | > avg_G_loss:\u001b[92m 1.98231 \u001b[0m(-0.02568)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13584 \u001b[0m(+0.01726)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84648 \u001b[0m(-0.04294)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44921 \u001b[0m(+0.00100)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15888 \u001b[0m(-0.01203)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11788 \u001b[0m(+0.01458)\n",
            "     | > avg_D_loss:\u001b[91m 0.44921 \u001b[0m(+0.00100)\n",
            "     | > avg_loader_time:\u001b[92m 0.38207 \u001b[0m(-0.00003)\n",
            "     | > avg_step_time:\u001b[91m 0.04810 \u001b[0m(+0.00205)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 429/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:00:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 90/120 -- GLOBAL_STEP: 437000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.78656  (0.80944)\n",
            "     | > G_stft_loss_sc: 0.34444  (0.36016)\n",
            "     | > G_subband_stft_loss_mg: 0.70824  (0.74201)\n",
            "     | > G_subband_stft_loss_sc: 0.36099  (0.36891)\n",
            "     | > G_mse_fake_loss: 0.30830  (0.31770)\n",
            "     | > G_loss: 1.87086  (1.93450)\n",
            "     | > G_gen_loss: 1.10011  (1.14026)\n",
            "     | > G_adv_loss: 0.77074  (0.79424)\n",
            "     | > D_mse_gan_loss: 0.45387  (0.44541)\n",
            "     | > D_mse_gan_real_loss: 0.13001  (0.13773)\n",
            "     | > D_mse_gan_fake_loss: 0.14821  (0.13748)\n",
            "     | > D_loss: 0.45387  (0.44541)\n",
            "     | > step_time: 0.57\n",
            "     | > loader_time: 1.2531\n",
            "     | > current_lr_G: 5.41684023680573e-06\n",
            "     | > current_lr_D: 5.41684023680573e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.90 sec -- GLOBAL_STEP: 437030\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80906\n",
            "     | > avg_G_stft_loss_sc: 0.35947\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74143\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36801\n",
            "     | > avg_G_mse_fake_loss: 0.31769\n",
            "     | > avg_G_loss: 1.93320\n",
            "     | > avg_G_gen_loss: 1.13898\n",
            "     | > avg_G_adv_loss: 0.79422\n",
            "     | > avg_D_mse_gan_loss: 0.44546\n",
            "     | > avg_D_mse_gan_real_loss: 0.13806\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13715\n",
            "     | > avg_D_loss: 0.44546\n",
            "     | > avg_loader_time: 0.80637\n",
            "     | > avg_step_time: 0.56837\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78828 \u001b[0m(-0.00212)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36050 \u001b[0m(-0.02447)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70112 \u001b[0m(-0.00273)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37128 \u001b[0m(-0.02117)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29990 \u001b[0m(-0.03869)\n",
            "     | > avg_G_loss:\u001b[92m 1.86034 \u001b[0m(-0.12197)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11059 \u001b[0m(-0.02524)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74975 \u001b[0m(-0.09673)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44690 \u001b[0m(-0.00231)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13762 \u001b[0m(-0.02126)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13600 \u001b[0m(+0.01812)\n",
            "     | > avg_D_loss:\u001b[92m 0.44690 \u001b[0m(-0.00231)\n",
            "     | > avg_loader_time:\u001b[91m 0.39257 \u001b[0m(+0.01050)\n",
            "     | > avg_step_time:\u001b[91m 0.05144 \u001b[0m(+0.00334)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 430/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:03:11) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.29 sec -- GLOBAL_STEP: 437151\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81737\n",
            "     | > avg_G_stft_loss_sc: 0.35770\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75745\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36639\n",
            "     | > avg_G_mse_fake_loss: 0.31858\n",
            "     | > avg_G_loss: 1.94590\n",
            "     | > avg_G_gen_loss: 1.14946\n",
            "     | > avg_G_adv_loss: 0.79644\n",
            "     | > avg_D_mse_gan_loss: 0.44496\n",
            "     | > avg_D_mse_gan_real_loss: 0.13763\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13768\n",
            "     | > avg_D_loss: 0.44496\n",
            "     | > avg_loader_time: 0.81069\n",
            "     | > avg_step_time: 0.58047\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78591 \u001b[0m(-0.00237)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35579 \u001b[0m(-0.00472)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70070 \u001b[0m(-0.00042)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36853 \u001b[0m(-0.00275)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38045 \u001b[0m(+0.08055)\n",
            "     | > avg_G_loss:\u001b[91m 2.05658 \u001b[0m(+0.19624)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10546 \u001b[0m(-0.00513)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.95112 \u001b[0m(+0.20137)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44846 \u001b[0m(+0.00156)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17214 \u001b[0m(+0.03451)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10248 \u001b[0m(-0.03352)\n",
            "     | > avg_D_loss:\u001b[91m 0.44846 \u001b[0m(+0.00156)\n",
            "     | > avg_loader_time:\u001b[91m 0.42000 \u001b[0m(+0.02743)\n",
            "     | > avg_step_time:\u001b[91m 0.05419 \u001b[0m(+0.00274)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 431/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:06:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.45 sec -- GLOBAL_STEP: 437272\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80912\n",
            "     | > avg_G_stft_loss_sc: 0.35571\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74274\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36410\n",
            "     | > avg_G_mse_fake_loss: 0.31643\n",
            "     | > avg_G_loss: 1.92692\n",
            "     | > avg_G_gen_loss: 1.13584\n",
            "     | > avg_G_adv_loss: 0.79108\n",
            "     | > avg_D_mse_gan_loss: 0.44623\n",
            "     | > avg_D_mse_gan_real_loss: 0.13838\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13780\n",
            "     | > avg_D_loss: 0.44623\n",
            "     | > avg_loader_time: 0.82121\n",
            "     | > avg_step_time: 0.56508\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78865 \u001b[0m(+0.00274)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36551 \u001b[0m(+0.00972)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70292 \u001b[0m(+0.00222)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38352 \u001b[0m(+0.01499)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.30269 \u001b[0m(-0.07776)\n",
            "     | > avg_G_loss:\u001b[92m 1.87702 \u001b[0m(-0.17956)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12030 \u001b[0m(+0.01484)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.75672 \u001b[0m(-0.19440)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44274 \u001b[0m(-0.00572)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.11862 \u001b[0m(-0.05352)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14849 \u001b[0m(+0.04601)\n",
            "     | > avg_D_loss:\u001b[92m 0.44274 \u001b[0m(-0.00572)\n",
            "     | > avg_loader_time:\u001b[92m 0.35046 \u001b[0m(-0.06953)\n",
            "     | > avg_step_time:\u001b[92m 0.04738 \u001b[0m(-0.00680)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 432/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:09:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.59 sec -- GLOBAL_STEP: 437393\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80873\n",
            "     | > avg_G_stft_loss_sc: 0.35837\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74246\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36717\n",
            "     | > avg_G_mse_fake_loss: 0.31622\n",
            "     | > avg_G_loss: 1.92891\n",
            "     | > avg_G_gen_loss: 1.13836\n",
            "     | > avg_G_adv_loss: 0.79054\n",
            "     | > avg_D_mse_gan_loss: 0.44706\n",
            "     | > avg_D_mse_gan_real_loss: 0.13924\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13783\n",
            "     | > avg_D_loss: 0.44706\n",
            "     | > avg_loader_time: 0.80911\n",
            "     | > avg_step_time: 0.58296\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79068 \u001b[0m(+0.00203)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35631 \u001b[0m(-0.00920)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70272 \u001b[0m(-0.00020)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36605 \u001b[0m(-0.01747)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.33338 \u001b[0m(+0.03070)\n",
            "     | > avg_G_loss:\u001b[91m 1.94134 \u001b[0m(+0.06432)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10788 \u001b[0m(-0.01242)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.83346 \u001b[0m(+0.07674)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44582 \u001b[0m(+0.00308)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.14507 \u001b[0m(+0.02645)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12931 \u001b[0m(-0.01918)\n",
            "     | > avg_D_loss:\u001b[91m 0.44582 \u001b[0m(+0.00308)\n",
            "     | > avg_loader_time:\u001b[91m 0.41773 \u001b[0m(+0.06726)\n",
            "     | > avg_step_time:\u001b[91m 0.05219 \u001b[0m(+0.00481)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 433/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:12:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.79 sec -- GLOBAL_STEP: 437514\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81373\n",
            "     | > avg_G_stft_loss_sc: 0.35688\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75277\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36534\n",
            "     | > avg_G_mse_fake_loss: 0.31511\n",
            "     | > avg_G_loss: 1.93213\n",
            "     | > avg_G_gen_loss: 1.14436\n",
            "     | > avg_G_adv_loss: 0.78777\n",
            "     | > avg_D_mse_gan_loss: 0.44631\n",
            "     | > avg_D_mse_gan_real_loss: 0.13819\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13800\n",
            "     | > avg_D_loss: 0.44631\n",
            "     | > avg_loader_time: 0.81533\n",
            "     | > avg_step_time: 0.57615\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78540 \u001b[0m(-0.00528)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36617 \u001b[0m(+0.00986)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69990 \u001b[0m(-0.00282)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38376 \u001b[0m(+0.01771)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31116 \u001b[0m(-0.02223)\n",
            "     | > avg_G_loss:\u001b[92m 1.89550 \u001b[0m(-0.04584)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11761 \u001b[0m(+0.00973)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.77789 \u001b[0m(-0.05557)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44392 \u001b[0m(-0.00191)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13135 \u001b[0m(-0.01372)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13548 \u001b[0m(+0.00617)\n",
            "     | > avg_D_loss:\u001b[92m 0.44392 \u001b[0m(-0.00191)\n",
            "     | > avg_loader_time:\u001b[92m 0.38647 \u001b[0m(-0.03126)\n",
            "     | > avg_step_time:\u001b[92m 0.04985 \u001b[0m(-0.00234)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 434/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:15:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.30 sec -- GLOBAL_STEP: 437635\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80486\n",
            "     | > avg_G_stft_loss_sc: 0.35900\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73548\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36760\n",
            "     | > avg_G_mse_fake_loss: 0.31474\n",
            "     | > avg_G_loss: 1.92030\n",
            "     | > avg_G_gen_loss: 1.13347\n",
            "     | > avg_G_adv_loss: 0.78684\n",
            "     | > avg_D_mse_gan_loss: 0.44727\n",
            "     | > avg_D_mse_gan_real_loss: 0.13840\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13758\n",
            "     | > avg_D_loss: 0.44727\n",
            "     | > avg_loader_time: 0.81806\n",
            "     | > avg_step_time: 0.56379\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79117 \u001b[0m(+0.00577)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36144 \u001b[0m(-0.00473)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70417 \u001b[0m(+0.00427)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.38038 \u001b[0m(-0.00337)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.33660 \u001b[0m(+0.02545)\n",
            "     | > avg_G_loss:\u001b[91m 1.96008 \u001b[0m(+0.06459)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11858 \u001b[0m(+0.00097)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.84151 \u001b[0m(+0.06362)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44407 \u001b[0m(+0.00015)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16629 \u001b[0m(+0.03494)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10774 \u001b[0m(-0.02774)\n",
            "     | > avg_D_loss:\u001b[91m 0.44407 \u001b[0m(+0.00015)\n",
            "     | > avg_loader_time:\u001b[92m 0.38484 \u001b[0m(-0.00163)\n",
            "     | > avg_step_time:\u001b[92m 0.04708 \u001b[0m(-0.00278)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 435/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:17:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.83 sec -- GLOBAL_STEP: 437756\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81646\n",
            "     | > avg_G_stft_loss_sc: 0.35873\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75682\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36770\n",
            "     | > avg_G_mse_fake_loss: 0.31700\n",
            "     | > avg_G_loss: 1.94236\n",
            "     | > avg_G_gen_loss: 1.14985\n",
            "     | > avg_G_adv_loss: 0.79251\n",
            "     | > avg_D_mse_gan_loss: 0.44559\n",
            "     | > avg_D_mse_gan_real_loss: 0.13742\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13740\n",
            "     | > avg_D_loss: 0.44559\n",
            "     | > avg_loader_time: 0.82017\n",
            "     | > avg_step_time: 0.56812\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78638 \u001b[0m(-0.00479)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35868 \u001b[0m(-0.00276)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69921 \u001b[0m(-0.00496)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36596 \u001b[0m(-0.01442)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.40738 \u001b[0m(+0.07078)\n",
            "     | > avg_G_loss:\u001b[91m 2.12357 \u001b[0m(+0.16349)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10511 \u001b[0m(-0.01347)\n",
            "     | > avg_G_adv_loss:\u001b[91m 1.01846 \u001b[0m(+0.17695)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45220 \u001b[0m(+0.00814)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17840 \u001b[0m(+0.01210)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09390 \u001b[0m(-0.01384)\n",
            "     | > avg_D_loss:\u001b[91m 0.45220 \u001b[0m(+0.00814)\n",
            "     | > avg_loader_time:\u001b[91m 0.40759 \u001b[0m(+0.02275)\n",
            "     | > avg_step_time:\u001b[91m 0.05426 \u001b[0m(+0.00719)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 436/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:20:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.32 sec -- GLOBAL_STEP: 437877\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82096\n",
            "     | > avg_G_stft_loss_sc: 0.35734\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76149\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36645\n",
            "     | > avg_G_mse_fake_loss: 0.32011\n",
            "     | > avg_G_loss: 1.95339\n",
            "     | > avg_G_gen_loss: 1.15312\n",
            "     | > avg_G_adv_loss: 0.80027\n",
            "     | > avg_D_mse_gan_loss: 0.44468\n",
            "     | > avg_D_mse_gan_real_loss: 0.13802\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13815\n",
            "     | > avg_D_loss: 0.44468\n",
            "     | > avg_loader_time: 0.80403\n",
            "     | > avg_step_time: 0.55582\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78655 \u001b[0m(+0.00018)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36545 \u001b[0m(+0.00677)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70041 \u001b[0m(+0.00120)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38465 \u001b[0m(+0.01869)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.37710 \u001b[0m(-0.03028)\n",
            "     | > avg_G_loss:\u001b[92m 2.06129 \u001b[0m(-0.06228)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11853 \u001b[0m(+0.01342)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.94276 \u001b[0m(-0.07570)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.45030 \u001b[0m(-0.00190)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.17647 \u001b[0m(-0.00193)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10134 \u001b[0m(+0.00745)\n",
            "     | > avg_D_loss:\u001b[92m 0.45030 \u001b[0m(-0.00190)\n",
            "     | > avg_loader_time:\u001b[91m 0.44642 \u001b[0m(+0.03883)\n",
            "     | > avg_step_time:\u001b[91m 0.05493 \u001b[0m(+0.00067)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 437/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:23:49) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.77 sec -- GLOBAL_STEP: 437998\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81963\n",
            "     | > avg_G_stft_loss_sc: 0.35890\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76066\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36745\n",
            "     | > avg_G_mse_fake_loss: 0.31951\n",
            "     | > avg_G_loss: 1.95209\n",
            "     | > avg_G_gen_loss: 1.15332\n",
            "     | > avg_G_adv_loss: 0.79877\n",
            "     | > avg_D_mse_gan_loss: 0.44491\n",
            "     | > avg_D_mse_gan_real_loss: 0.13816\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13766\n",
            "     | > avg_D_loss: 0.44491\n",
            "     | > avg_loader_time: 0.81653\n",
            "     | > avg_step_time: 0.56743\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78606 \u001b[0m(-0.00049)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35724 \u001b[0m(-0.00821)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69972 \u001b[0m(-0.00069)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37361 \u001b[0m(-0.01104)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32010 \u001b[0m(-0.05701)\n",
            "     | > avg_G_loss:\u001b[92m 1.90855 \u001b[0m(-0.15274)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10831 \u001b[0m(-0.01022)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.80024 \u001b[0m(-0.14252)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44361 \u001b[0m(-0.00669)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15333 \u001b[0m(-0.02314)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11462 \u001b[0m(+0.01327)\n",
            "     | > avg_D_loss:\u001b[92m 0.44361 \u001b[0m(-0.00669)\n",
            "     | > avg_loader_time:\u001b[92m 0.38783 \u001b[0m(-0.05859)\n",
            "     | > avg_step_time:\u001b[92m 0.04674 \u001b[0m(-0.00819)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 438/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:26:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 1/120 -- GLOBAL_STEP: 438000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.82177  (0.82177)\n",
            "     | > G_stft_loss_sc: 0.34543  (0.34543)\n",
            "     | > G_subband_stft_loss_mg: 0.76435  (0.76435)\n",
            "     | > G_subband_stft_loss_sc: 0.35697  (0.35697)\n",
            "     | > G_mse_fake_loss: 0.30694  (0.30694)\n",
            "     | > G_loss: 1.91161  (1.91161)\n",
            "     | > G_gen_loss: 1.14426  (1.14426)\n",
            "     | > G_adv_loss: 0.76735  (0.76735)\n",
            "     | > D_mse_gan_loss: 0.44252  (0.44252)\n",
            "     | > D_mse_gan_real_loss: 0.13900  (0.13900)\n",
            "     | > D_mse_gan_fake_loss: 0.13601  (0.13601)\n",
            "     | > D_loss: 0.44252  (0.44252)\n",
            "     | > step_time: 0.51\n",
            "     | > loader_time: 0.0092\n",
            "     | > current_lr_G: 5.368283226590263e-06\n",
            "     | > current_lr_D: 5.368283226590263e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.06 sec -- GLOBAL_STEP: 438119\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81230\n",
            "     | > avg_G_stft_loss_sc: 0.36008\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74937\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36858\n",
            "     | > avg_G_mse_fake_loss: 0.31546\n",
            "     | > avg_G_loss: 1.93381\n",
            "     | > avg_G_gen_loss: 1.14516\n",
            "     | > avg_G_adv_loss: 0.78865\n",
            "     | > avg_D_mse_gan_loss: 0.44559\n",
            "     | > avg_D_mse_gan_real_loss: 0.13786\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13720\n",
            "     | > avg_D_loss: 0.44559\n",
            "     | > avg_loader_time: 0.80534\n",
            "     | > avg_step_time: 0.55310\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78797 \u001b[0m(+0.00190)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36684 \u001b[0m(+0.00960)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70256 \u001b[0m(+0.00284)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38764 \u001b[0m(+0.01403)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32147 \u001b[0m(+0.00137)\n",
            "     | > avg_G_loss:\u001b[91m 1.92617 \u001b[0m(+0.01761)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12250 \u001b[0m(+0.01419)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.80367 \u001b[0m(+0.00343)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44014 \u001b[0m(-0.00347)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14413 \u001b[0m(-0.00920)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12370 \u001b[0m(+0.00909)\n",
            "     | > avg_D_loss:\u001b[92m 0.44014 \u001b[0m(-0.00347)\n",
            "     | > avg_loader_time:\u001b[91m 0.40166 \u001b[0m(+0.01383)\n",
            "     | > avg_step_time:\u001b[91m 0.05418 \u001b[0m(+0.00744)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 439/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:29:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.97 sec -- GLOBAL_STEP: 438240\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81295\n",
            "     | > avg_G_stft_loss_sc: 0.35582\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74872\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36486\n",
            "     | > avg_G_mse_fake_loss: 0.31798\n",
            "     | > avg_G_loss: 1.93613\n",
            "     | > avg_G_gen_loss: 1.14118\n",
            "     | > avg_G_adv_loss: 0.79495\n",
            "     | > avg_D_mse_gan_loss: 0.44566\n",
            "     | > avg_D_mse_gan_real_loss: 0.13835\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13739\n",
            "     | > avg_D_loss: 0.44566\n",
            "     | > avg_loader_time: 0.81683\n",
            "     | > avg_step_time: 0.56923\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78776 \u001b[0m(-0.00021)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36695 \u001b[0m(+0.00012)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70027 \u001b[0m(-0.00229)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37003 \u001b[0m(-0.01761)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34644 \u001b[0m(+0.02498)\n",
            "     | > avg_G_loss:\u001b[91m 1.97862 \u001b[0m(+0.05245)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11251 \u001b[0m(-0.00999)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86611 \u001b[0m(+0.06244)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44686 \u001b[0m(+0.00672)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14213 \u001b[0m(-0.00199)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12514 \u001b[0m(+0.00144)\n",
            "     | > avg_D_loss:\u001b[91m 0.44686 \u001b[0m(+0.00672)\n",
            "     | > avg_loader_time:\u001b[91m 0.40740 \u001b[0m(+0.00574)\n",
            "     | > avg_step_time:\u001b[92m 0.04462 \u001b[0m(-0.00956)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 440/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:32:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.23 sec -- GLOBAL_STEP: 438361\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81924\n",
            "     | > avg_G_stft_loss_sc: 0.35713\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75941\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36591\n",
            "     | > avg_G_mse_fake_loss: 0.31881\n",
            "     | > avg_G_loss: 1.94788\n",
            "     | > avg_G_gen_loss: 1.15084\n",
            "     | > avg_G_adv_loss: 0.79703\n",
            "     | > avg_D_mse_gan_loss: 0.44487\n",
            "     | > avg_D_mse_gan_real_loss: 0.13810\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13788\n",
            "     | > avg_D_loss: 0.44487\n",
            "     | > avg_loader_time: 0.79601\n",
            "     | > avg_step_time: 0.55493\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78873 \u001b[0m(+0.00097)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37120 \u001b[0m(+0.00425)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70118 \u001b[0m(+0.00091)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37537 \u001b[0m(+0.00534)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.39309 \u001b[0m(+0.04665)\n",
            "     | > avg_G_loss:\u001b[91m 2.10096 \u001b[0m(+0.12235)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11824 \u001b[0m(+0.00573)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.98272 \u001b[0m(+0.11662)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45350 \u001b[0m(+0.00664)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17503 \u001b[0m(+0.03290)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10068 \u001b[0m(-0.02446)\n",
            "     | > avg_D_loss:\u001b[91m 0.45350 \u001b[0m(+0.00664)\n",
            "     | > avg_loader_time:\u001b[92m 0.36905 \u001b[0m(-0.03835)\n",
            "     | > avg_step_time:\u001b[91m 0.04722 \u001b[0m(+0.00260)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 441/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:35:30) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.46 sec -- GLOBAL_STEP: 438482\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80516\n",
            "     | > avg_G_stft_loss_sc: 0.36552\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73898\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37363\n",
            "     | > avg_G_mse_fake_loss: 0.31129\n",
            "     | > avg_G_loss: 1.91987\n",
            "     | > avg_G_gen_loss: 1.14164\n",
            "     | > avg_G_adv_loss: 0.77823\n",
            "     | > avg_D_mse_gan_loss: 0.44859\n",
            "     | > avg_D_mse_gan_real_loss: 0.13930\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13825\n",
            "     | > avg_D_loss: 0.44859\n",
            "     | > avg_loader_time: 0.83776\n",
            "     | > avg_step_time: 0.55731\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78643 \u001b[0m(-0.00230)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35659 \u001b[0m(-0.01461)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70043 \u001b[0m(-0.00076)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36501 \u001b[0m(-0.01036)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32760 \u001b[0m(-0.06549)\n",
            "     | > avg_G_loss:\u001b[92m 1.92324 \u001b[0m(-0.17772)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10423 \u001b[0m(-0.01401)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81901 \u001b[0m(-0.16371)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44039 \u001b[0m(-0.01311)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14235 \u001b[0m(-0.03268)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12135 \u001b[0m(+0.02067)\n",
            "     | > avg_D_loss:\u001b[92m 0.44039 \u001b[0m(-0.01311)\n",
            "     | > avg_loader_time:\u001b[92m 0.36281 \u001b[0m(-0.00625)\n",
            "     | > avg_step_time:\u001b[91m 0.04981 \u001b[0m(+0.00259)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 442/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:38:27) \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEcPFZiYYICO"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"$DATAROOT/jsut_ver1.1_ljspeech_structure/output/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}