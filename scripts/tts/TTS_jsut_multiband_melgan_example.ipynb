{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TTS_jsut_vocoder_melgan_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-kamiya/machine-learning-samples/blob/feature%2Ftts-scripts/TTS_jsut_multiband_melgan_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjD0xW0cEMVT"
      },
      "source": [
        "## Hands-on example for 🐸 [Coqui TTS](https://github.com/coqui-ai/TTS)\n",
        "\n",
        "This notebook trains Tacotron model on LJSpeech dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR5s0u9TdB9d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xspM7pnX7Zbj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls /gdrive\n",
        "\n",
        "!ln -s \"/gdrive/My Drive\" /mydrive\n",
        "DATAROOT='/mydrive/machine-learning/tts/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yjg-wRlPuO9"
      },
      "source": [
        "# zipに固めてあった学習データを展開\n",
        "!cp -r \"$DATAROOT/jsut_ljspeech_structure_22050.zip\" /content/\n",
        "!unzip -q /content/jsut_ljspeech_structure_22050.zip -d /content/\n",
        "\n",
        "!cp \"$DATAROOT/jsut_ver1.1_ljspeech_structure/scale_stats.npy\" /content/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwvg3-nVDL5t"
      },
      "source": [
        "# get TTS to your local\n",
        "!git clone https://github.com/coqui-ai/TTS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tEdu7hPisWl"
      },
      "source": [
        "%cd TTS\n",
        "!git checkout v0.0.13\n",
        "!pip install -e .\n",
        "!pip install numba==0.48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7_Xao7uNOvX"
      },
      "source": [
        "# load the default config file and update with the local paths and settings.\n",
        "import json\n",
        "from TTS.utils.io import load_config\n",
        "\n",
        "DATAROOT = '/content/ljspeech_structure_22050'\n",
        "DATAROOT_DRIVE ='/mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure'\n",
        "\n",
        "CONFIG = load_config('TTS/vocoder/configs/multiband_melgan_config.json') \n",
        "\n",
        "CONFIG['data_path'] = f\"{DATAROOT}/wavs/\"\n",
        "CONFIG['audio']['stats_path'] = None\n",
        "CONFIG['output_path'] = f\"{DATAROOT_DRIVE}/output\"\n",
        "CONFIG['num_loader_workers'] = 4\n",
        "CONFIG['num_val_loader_workers'] = 1\n",
        "CONFIG['test_sentences_file'] = f\"{DATAROOT_DRIVE}/test_sentences_file\"\n",
        "CONFIG['print_step'] = 1000\n",
        "CONFIG['save_step'] = 5000\n",
        "\n",
        "CONFIG['use_l1_spec_loss'] = False\n",
        "CONFIG['diff_samples_for_G_and_D'] = False\n",
        "\n",
        "\n",
        "with open('config.json', 'w') as fp:\n",
        "    json.dump(CONFIG, fp)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1fxmcT2qGmb"
      },
      "source": [
        "%%script false --no-raise-error\n",
        "!CUDA_VISIBLE_DEVICES=\"0\" python TTS/bin/train_vocoder_gan.py --config_path config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L3JjJOBErxq",
        "outputId": "58dccfc1-d12f-4b78-a0bb-c633005f57f5"
      },
      "source": [
        "#%%script false --no-raise-error\n",
        "# 学習再開\n",
        "!cp config.json $DATAROOT_DRIVE/output/multiband-melgan\n",
        "!CUDA_VISIBLE_DEVICES=\"0\" python TTS/bin/train_vocoder_gan.py --continue_path $DATAROOT_DRIVE/output/multiband-melgan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "     | > avg_D_mse_gan_real_loss: 0.13808\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13824\n",
            "     | > avg_D_loss: 0.44636\n",
            "     | > avg_loader_time: 0.86925\n",
            "     | > avg_step_time: 0.62491\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78846 \u001b[0m(+0.00223)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37229 \u001b[0m(+0.00812)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70276 \u001b[0m(+0.00310)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39029 \u001b[0m(+0.01677)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35986 \u001b[0m(+0.00595)\n",
            "     | > avg_G_loss:\u001b[91m 2.02654 \u001b[0m(+0.03000)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12690 \u001b[0m(+0.01511)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89964 \u001b[0m(+0.01488)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44544 \u001b[0m(+0.00003)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.17272 \u001b[0m(-0.00232)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10046 \u001b[0m(+0.00031)\n",
            "     | > avg_D_loss:\u001b[91m 0.44544 \u001b[0m(+0.00003)\n",
            "     | > avg_loader_time:\u001b[92m 0.42305 \u001b[0m(-0.01350)\n",
            "     | > avg_step_time:\u001b[91m 0.05826 \u001b[0m(+0.00613)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 327/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:45:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.95 sec -- GLOBAL_STEP: 424688\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81460\n",
            "     | > avg_G_stft_loss_sc: 0.35678\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75489\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36518\n",
            "     | > avg_G_mse_fake_loss: 0.31409\n",
            "     | > avg_G_loss: 1.93095\n",
            "     | > avg_G_gen_loss: 1.14572\n",
            "     | > avg_G_adv_loss: 0.78523\n",
            "     | > avg_D_mse_gan_loss: 0.44672\n",
            "     | > avg_D_mse_gan_real_loss: 0.13800\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13810\n",
            "     | > avg_D_loss: 0.44672\n",
            "     | > avg_loader_time: 0.86390\n",
            "     | > avg_step_time: 0.64280\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78785 \u001b[0m(-0.00061)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37244 \u001b[0m(+0.00015)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70120 \u001b[0m(-0.00156)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37558 \u001b[0m(-0.01471)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34362 \u001b[0m(-0.01624)\n",
            "     | > avg_G_loss:\u001b[92m 1.97758 \u001b[0m(-0.04896)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11853 \u001b[0m(-0.00837)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85904 \u001b[0m(-0.04060)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44341 \u001b[0m(-0.00203)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16161 \u001b[0m(-0.01111)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10783 \u001b[0m(+0.00737)\n",
            "     | > avg_D_loss:\u001b[92m 0.44341 \u001b[0m(-0.00203)\n",
            "     | > avg_loader_time:\u001b[92m 0.40216 \u001b[0m(-0.02089)\n",
            "     | > avg_step_time:\u001b[92m 0.04822 \u001b[0m(-0.01004)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 328/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:49:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.46 sec -- GLOBAL_STEP: 424809\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81730\n",
            "     | > avg_G_stft_loss_sc: 0.35944\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75655\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36807\n",
            "     | > avg_G_mse_fake_loss: 0.31697\n",
            "     | > avg_G_loss: 1.94311\n",
            "     | > avg_G_gen_loss: 1.15067\n",
            "     | > avg_G_adv_loss: 0.79243\n",
            "     | > avg_D_mse_gan_loss: 0.44646\n",
            "     | > avg_D_mse_gan_real_loss: 0.13828\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13837\n",
            "     | > avg_D_loss: 0.44646\n",
            "     | > avg_loader_time: 0.87532\n",
            "     | > avg_step_time: 0.63084\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78710 \u001b[0m(-0.00075)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36135 \u001b[0m(-0.01109)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70052 \u001b[0m(-0.00068)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37610 \u001b[0m(+0.00052)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38211 \u001b[0m(+0.03850)\n",
            "     | > avg_G_loss:\u001b[91m 2.06781 \u001b[0m(+0.09024)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11253 \u001b[0m(-0.00600)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.95528 \u001b[0m(+0.09624)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45263 \u001b[0m(+0.00922)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17857 \u001b[0m(+0.01696)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09984 \u001b[0m(-0.00800)\n",
            "     | > avg_D_loss:\u001b[91m 0.45263 \u001b[0m(+0.00922)\n",
            "     | > avg_loader_time:\u001b[91m 0.40617 \u001b[0m(+0.00401)\n",
            "     | > avg_step_time:\u001b[91m 0.05434 \u001b[0m(+0.00613)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 329/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:52:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.26 sec -- GLOBAL_STEP: 424930\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82230\n",
            "     | > avg_G_stft_loss_sc: 0.35774\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76319\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36655\n",
            "     | > avg_G_mse_fake_loss: 0.32056\n",
            "     | > avg_G_loss: 1.95629\n",
            "     | > avg_G_gen_loss: 1.15489\n",
            "     | > avg_G_adv_loss: 0.80140\n",
            "     | > avg_D_mse_gan_loss: 0.44416\n",
            "     | > avg_D_mse_gan_real_loss: 0.13773\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13783\n",
            "     | > avg_D_loss: 0.44416\n",
            "     | > avg_loader_time: 0.88407\n",
            "     | > avg_step_time: 0.62916\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78553 \u001b[0m(-0.00156)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35905 \u001b[0m(-0.00230)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69910 \u001b[0m(-0.00142)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37064 \u001b[0m(-0.00546)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38972 \u001b[0m(+0.00760)\n",
            "     | > avg_G_loss:\u001b[91m 2.08145 \u001b[0m(+0.01364)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10716 \u001b[0m(-0.00537)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.97429 \u001b[0m(+0.01901)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.45108 \u001b[0m(-0.00156)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.17229 \u001b[0m(-0.00627)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09914 \u001b[0m(-0.00069)\n",
            "     | > avg_D_loss:\u001b[92m 0.45108 \u001b[0m(-0.00156)\n",
            "     | > avg_loader_time:\u001b[92m 0.36657 \u001b[0m(-0.03960)\n",
            "     | > avg_step_time:\u001b[92m 0.05255 \u001b[0m(-0.00180)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 330/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:55:29) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 69/120 -- GLOBAL_STEP: 425000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81741  (0.80104)\n",
            "     | > G_stft_loss_sc: 0.36273  (0.36292)\n",
            "     | > G_subband_stft_loss_mg: 0.75820  (0.72700)\n",
            "     | > G_subband_stft_loss_sc: 0.36428  (0.37158)\n",
            "     | > G_mse_fake_loss: 0.33554  (0.31326)\n",
            "     | > G_loss: 1.99017  (1.91442)\n",
            "     | > G_gen_loss: 1.15131  (1.13127)\n",
            "     | > G_adv_loss: 0.83885  (0.78315)\n",
            "     | > D_mse_gan_loss: 0.44023  (0.44851)\n",
            "     | > D_mse_gan_real_loss: 0.14867  (0.13899)\n",
            "     | > D_mse_gan_fake_loss: 0.11914  (0.13820)\n",
            "     | > D_loss: 0.44023  (0.44851)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 0.0030\n",
            "     | > current_lr_G: 5.980846997657298e-06\n",
            "     | > current_lr_D: 5.980846997657298e-06\n",
            " > CHECKPOINT : /mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure/output/multiband-melgan/checkpoint_425000.pth.tar\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.39 sec -- GLOBAL_STEP: 425051\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80059\n",
            "     | > avg_G_stft_loss_sc: 0.36194\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72644\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37061\n",
            "     | > avg_G_mse_fake_loss: 0.31279\n",
            "     | > avg_G_loss: 1.91177\n",
            "     | > avg_G_gen_loss: 1.12979\n",
            "     | > avg_G_adv_loss: 0.78198\n",
            "     | > avg_D_mse_gan_loss: 0.44839\n",
            "     | > avg_D_mse_gan_real_loss: 0.13879\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13842\n",
            "     | > avg_D_loss: 0.44839\n",
            "     | > avg_loader_time: 0.80281\n",
            "     | > avg_step_time: 0.62103\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78708 \u001b[0m(+0.00155)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35718 \u001b[0m(-0.00187)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70198 \u001b[0m(+0.00288)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37489 \u001b[0m(+0.00424)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35348 \u001b[0m(-0.03624)\n",
            "     | > avg_G_loss:\u001b[92m 1.99425 \u001b[0m(-0.08720)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11056 \u001b[0m(+0.00340)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88369 \u001b[0m(-0.09060)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44563 \u001b[0m(-0.00544)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16668 \u001b[0m(-0.00561)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10412 \u001b[0m(+0.00497)\n",
            "     | > avg_D_loss:\u001b[92m 0.44563 \u001b[0m(-0.00544)\n",
            "     | > avg_loader_time:\u001b[91m 0.37634 \u001b[0m(+0.00977)\n",
            "     | > avg_step_time:\u001b[92m 0.05101 \u001b[0m(-0.00154)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 331/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 18:58:41) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.27 sec -- GLOBAL_STEP: 425172\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81802\n",
            "     | > avg_G_stft_loss_sc: 0.35745\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75690\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36632\n",
            "     | > avg_G_mse_fake_loss: 0.31576\n",
            "     | > avg_G_loss: 1.93874\n",
            "     | > avg_G_gen_loss: 1.14934\n",
            "     | > avg_G_adv_loss: 0.78939\n",
            "     | > avg_D_mse_gan_loss: 0.44721\n",
            "     | > avg_D_mse_gan_real_loss: 0.13868\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13791\n",
            "     | > avg_D_loss: 0.44721\n",
            "     | > avg_loader_time: 0.85863\n",
            "     | > avg_step_time: 0.60426\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78973 \u001b[0m(+0.00265)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37478 \u001b[0m(+0.01761)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70311 \u001b[0m(+0.00113)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39071 \u001b[0m(+0.01583)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33861 \u001b[0m(-0.01486)\n",
            "     | > avg_G_loss:\u001b[92m 1.97570 \u001b[0m(-0.01855)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12917 \u001b[0m(+0.01861)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84653 \u001b[0m(-0.03716)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44554 \u001b[0m(-0.00009)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15371 \u001b[0m(-0.01297)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11763 \u001b[0m(+0.01351)\n",
            "     | > avg_D_loss:\u001b[92m 0.44554 \u001b[0m(-0.00009)\n",
            "     | > avg_loader_time:\u001b[91m 0.38683 \u001b[0m(+0.01049)\n",
            "     | > avg_step_time:\u001b[91m 0.05438 \u001b[0m(+0.00337)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 332/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:01:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.37 sec -- GLOBAL_STEP: 425293\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81627\n",
            "     | > avg_G_stft_loss_sc: 0.36356\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75539\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37215\n",
            "     | > avg_G_mse_fake_loss: 0.31436\n",
            "     | > avg_G_loss: 1.93959\n",
            "     | > avg_G_gen_loss: 1.15368\n",
            "     | > avg_G_adv_loss: 0.78590\n",
            "     | > avg_D_mse_gan_loss: 0.44794\n",
            "     | > avg_D_mse_gan_real_loss: 0.13873\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13825\n",
            "     | > avg_D_loss: 0.44794\n",
            "     | > avg_loader_time: 0.86303\n",
            "     | > avg_step_time: 0.61995\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78664 \u001b[0m(-0.00310)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35612 \u001b[0m(-0.01867)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70086 \u001b[0m(-0.00225)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37154 \u001b[0m(-0.01918)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29623 \u001b[0m(-0.04238)\n",
            "     | > avg_G_loss:\u001b[92m 1.84816 \u001b[0m(-0.12754)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10757 \u001b[0m(-0.02159)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74058 \u001b[0m(-0.10595)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44152 \u001b[0m(-0.00402)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12102 \u001b[0m(-0.03269)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14527 \u001b[0m(+0.02764)\n",
            "     | > avg_D_loss:\u001b[92m 0.44152 \u001b[0m(-0.00402)\n",
            "     | > avg_loader_time:\u001b[91m 0.42525 \u001b[0m(+0.03842)\n",
            "     | > avg_step_time:\u001b[92m 0.05033 \u001b[0m(-0.00405)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 333/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:04:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.99 sec -- GLOBAL_STEP: 425414\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81213\n",
            "     | > avg_G_stft_loss_sc: 0.36017\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74920\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36860\n",
            "     | > avg_G_mse_fake_loss: 0.31395\n",
            "     | > avg_G_loss: 1.92993\n",
            "     | > avg_G_gen_loss: 1.14505\n",
            "     | > avg_G_adv_loss: 0.78488\n",
            "     | > avg_D_mse_gan_loss: 0.44732\n",
            "     | > avg_D_mse_gan_real_loss: 0.13865\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13729\n",
            "     | > avg_D_loss: 0.44732\n",
            "     | > avg_loader_time: 0.86567\n",
            "     | > avg_step_time: 0.61100\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78612 \u001b[0m(-0.00051)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36081 \u001b[0m(+0.00469)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70125 \u001b[0m(+0.00039)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37739 \u001b[0m(+0.00585)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.29767 \u001b[0m(+0.00143)\n",
            "     | > avg_G_loss:\u001b[91m 1.85695 \u001b[0m(+0.00880)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11279 \u001b[0m(+0.00521)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.74417 \u001b[0m(+0.00358)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44323 \u001b[0m(+0.00171)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.12221 \u001b[0m(+0.00119)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14717 \u001b[0m(+0.00190)\n",
            "     | > avg_D_loss:\u001b[91m 0.44323 \u001b[0m(+0.00171)\n",
            "     | > avg_loader_time:\u001b[92m 0.42073 \u001b[0m(-0.00452)\n",
            "     | > avg_step_time:\u001b[91m 0.05359 \u001b[0m(+0.00326)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 334/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:08:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.37 sec -- GLOBAL_STEP: 425535\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81619\n",
            "     | > avg_G_stft_loss_sc: 0.35787\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75605\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36629\n",
            "     | > avg_G_mse_fake_loss: 0.31257\n",
            "     | > avg_G_loss: 1.92962\n",
            "     | > avg_G_gen_loss: 1.14820\n",
            "     | > avg_G_adv_loss: 0.78142\n",
            "     | > avg_D_mse_gan_loss: 0.44804\n",
            "     | > avg_D_mse_gan_real_loss: 0.13837\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13785\n",
            "     | > avg_D_loss: 0.44804\n",
            "     | > avg_loader_time: 0.85676\n",
            "     | > avg_step_time: 0.59717\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78936 \u001b[0m(+0.00323)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37318 \u001b[0m(+0.01237)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70249 \u001b[0m(+0.00123)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38546 \u001b[0m(+0.00807)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34461 \u001b[0m(+0.04695)\n",
            "     | > avg_G_loss:\u001b[91m 1.98678 \u001b[0m(+0.12982)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12524 \u001b[0m(+0.01246)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86153 \u001b[0m(+0.11737)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44158 \u001b[0m(-0.00165)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16539 \u001b[0m(+0.04318)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10122 \u001b[0m(-0.04595)\n",
            "     | > avg_D_loss:\u001b[92m 0.44158 \u001b[0m(-0.00165)\n",
            "     | > avg_loader_time:\u001b[91m 0.43020 \u001b[0m(+0.00948)\n",
            "     | > avg_step_time:\u001b[91m 0.05378 \u001b[0m(+0.00019)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 335/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:11:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.84 sec -- GLOBAL_STEP: 425656\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81795\n",
            "     | > avg_G_stft_loss_sc: 0.35870\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75827\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36717\n",
            "     | > avg_G_mse_fake_loss: 0.31693\n",
            "     | > avg_G_loss: 1.94336\n",
            "     | > avg_G_gen_loss: 1.15104\n",
            "     | > avg_G_adv_loss: 0.79232\n",
            "     | > avg_D_mse_gan_loss: 0.44591\n",
            "     | > avg_D_mse_gan_real_loss: 0.13784\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13817\n",
            "     | > avg_D_loss: 0.44591\n",
            "     | > avg_loader_time: 0.85059\n",
            "     | > avg_step_time: 0.59271\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78770 \u001b[0m(-0.00166)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36274 \u001b[0m(-0.01044)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70101 \u001b[0m(-0.00148)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37000 \u001b[0m(-0.01546)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37166 \u001b[0m(+0.02705)\n",
            "     | > avg_G_loss:\u001b[91m 2.03988 \u001b[0m(+0.05311)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11072 \u001b[0m(-0.01452)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.92916 \u001b[0m(+0.06763)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44813 \u001b[0m(+0.00655)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16844 \u001b[0m(+0.00306)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10206 \u001b[0m(+0.00084)\n",
            "     | > avg_D_loss:\u001b[91m 0.44813 \u001b[0m(+0.00655)\n",
            "     | > avg_loader_time:\u001b[92m 0.42507 \u001b[0m(-0.00513)\n",
            "     | > avg_step_time:\u001b[91m 0.05642 \u001b[0m(+0.00264)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 336/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:14:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.69 sec -- GLOBAL_STEP: 425777\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80809\n",
            "     | > avg_G_stft_loss_sc: 0.36193\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74224\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37060\n",
            "     | > avg_G_mse_fake_loss: 0.31340\n",
            "     | > avg_G_loss: 1.92494\n",
            "     | > avg_G_gen_loss: 1.14143\n",
            "     | > avg_G_adv_loss: 0.78350\n",
            "     | > avg_D_mse_gan_loss: 0.44767\n",
            "     | > avg_D_mse_gan_real_loss: 0.13857\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13821\n",
            "     | > avg_D_loss: 0.44767\n",
            "     | > avg_loader_time: 0.84164\n",
            "     | > avg_step_time: 0.59985\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78638 \u001b[0m(-0.00133)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35826 \u001b[0m(-0.00447)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69997 \u001b[0m(-0.00104)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37245 \u001b[0m(+0.00244)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34744 \u001b[0m(-0.02422)\n",
            "     | > avg_G_loss:\u001b[92m 1.97714 \u001b[0m(-0.06275)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10853 \u001b[0m(-0.00220)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.86861 \u001b[0m(-0.06055)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44308 \u001b[0m(-0.00505)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16544 \u001b[0m(-0.00300)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10480 \u001b[0m(+0.00274)\n",
            "     | > avg_D_loss:\u001b[92m 0.44308 \u001b[0m(-0.00505)\n",
            "     | > avg_loader_time:\u001b[91m 0.48179 \u001b[0m(+0.05672)\n",
            "     | > avg_step_time:\u001b[91m 0.05875 \u001b[0m(+0.00233)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 337/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:17:21) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.15 sec -- GLOBAL_STEP: 425898\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81184\n",
            "     | > avg_G_stft_loss_sc: 0.35914\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75024\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36772\n",
            "     | > avg_G_mse_fake_loss: 0.31258\n",
            "     | > avg_G_loss: 1.92592\n",
            "     | > avg_G_gen_loss: 1.14447\n",
            "     | > avg_G_adv_loss: 0.78145\n",
            "     | > avg_D_mse_gan_loss: 0.44754\n",
            "     | > avg_D_mse_gan_real_loss: 0.13847\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13850\n",
            "     | > avg_D_loss: 0.44754\n",
            "     | > avg_loader_time: 0.84983\n",
            "     | > avg_step_time: 0.59536\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78794 \u001b[0m(+0.00157)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36821 \u001b[0m(+0.00994)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70140 \u001b[0m(+0.00143)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37523 \u001b[0m(+0.00278)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37430 \u001b[0m(+0.02686)\n",
            "     | > avg_G_loss:\u001b[91m 2.05215 \u001b[0m(+0.07501)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11639 \u001b[0m(+0.00786)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93575 \u001b[0m(+0.06715)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45041 \u001b[0m(+0.00733)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.19842 \u001b[0m(+0.03298)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08528 \u001b[0m(-0.01952)\n",
            "     | > avg_D_loss:\u001b[91m 0.45041 \u001b[0m(+0.00733)\n",
            "     | > avg_loader_time:\u001b[92m 0.39512 \u001b[0m(-0.08667)\n",
            "     | > avg_step_time:\u001b[92m 0.05093 \u001b[0m(-0.00781)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 338/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:20:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 101/120 -- GLOBAL_STEP: 426000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.82060  (0.81982)\n",
            "     | > G_stft_loss_sc: 0.35791  (0.36066)\n",
            "     | > G_subband_stft_loss_mg: 0.76454  (0.75928)\n",
            "     | > G_subband_stft_loss_sc: 0.37386  (0.36954)\n",
            "     | > G_mse_fake_loss: 0.32008  (0.31966)\n",
            "     | > G_loss: 1.95865  (1.95380)\n",
            "     | > G_gen_loss: 1.15845  (1.15465)\n",
            "     | > G_adv_loss: 0.80020  (0.79915)\n",
            "     | > D_mse_gan_loss: 0.44934  (0.44431)\n",
            "     | > D_mse_gan_real_loss: 0.15055  (0.13789)\n",
            "     | > D_mse_gan_fake_loss: 0.13353  (0.13741)\n",
            "     | > D_loss: 0.44934  (0.44431)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 0.0247\n",
            "     | > current_lr_G: 5.933167350882866e-06\n",
            "     | > current_lr_D: 5.933167350882866e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.31 sec -- GLOBAL_STEP: 426019\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81973\n",
            "     | > avg_G_stft_loss_sc: 0.36027\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75926\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36918\n",
            "     | > avg_G_mse_fake_loss: 0.31927\n",
            "     | > avg_G_loss: 1.95239\n",
            "     | > avg_G_gen_loss: 1.15422\n",
            "     | > avg_G_adv_loss: 0.79817\n",
            "     | > avg_D_mse_gan_loss: 0.44445\n",
            "     | > avg_D_mse_gan_real_loss: 0.13769\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13782\n",
            "     | > avg_D_loss: 0.44445\n",
            "     | > avg_loader_time: 0.86944\n",
            "     | > avg_step_time: 0.61339\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78931 \u001b[0m(+0.00136)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37463 \u001b[0m(+0.00642)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70157 \u001b[0m(+0.00017)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37875 \u001b[0m(+0.00353)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.36377 \u001b[0m(-0.01053)\n",
            "     | > avg_G_loss:\u001b[92m 2.03155 \u001b[0m(-0.02060)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12213 \u001b[0m(+0.00574)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.90942 \u001b[0m(-0.02633)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44946 \u001b[0m(-0.00095)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16388 \u001b[0m(-0.03454)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10838 \u001b[0m(+0.02311)\n",
            "     | > avg_D_loss:\u001b[92m 0.44946 \u001b[0m(-0.00095)\n",
            "     | > avg_loader_time:\u001b[92m 0.37215 \u001b[0m(-0.02297)\n",
            "     | > avg_step_time:\u001b[92m 0.04565 \u001b[0m(-0.00528)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 339/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:23:34) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.63 sec -- GLOBAL_STEP: 426140\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81423\n",
            "     | > avg_G_stft_loss_sc: 0.35989\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75501\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36845\n",
            "     | > avg_G_mse_fake_loss: 0.31294\n",
            "     | > avg_G_loss: 1.93114\n",
            "     | > avg_G_gen_loss: 1.14879\n",
            "     | > avg_G_adv_loss: 0.78235\n",
            "     | > avg_D_mse_gan_loss: 0.44763\n",
            "     | > avg_D_mse_gan_real_loss: 0.13818\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13772\n",
            "     | > avg_D_loss: 0.44763\n",
            "     | > avg_loader_time: 0.85696\n",
            "     | > avg_step_time: 0.61600\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78712 \u001b[0m(-0.00218)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36275 \u001b[0m(-0.01188)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70109 \u001b[0m(-0.00048)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38098 \u001b[0m(+0.00222)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32510 \u001b[0m(-0.03867)\n",
            "     | > avg_G_loss:\u001b[92m 1.92872 \u001b[0m(-0.10283)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11597 \u001b[0m(-0.00616)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81275 \u001b[0m(-0.09667)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44166 \u001b[0m(-0.00780)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16064 \u001b[0m(-0.00324)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10765 \u001b[0m(-0.00073)\n",
            "     | > avg_D_loss:\u001b[92m 0.44166 \u001b[0m(-0.00780)\n",
            "     | > avg_loader_time:\u001b[91m 0.42494 \u001b[0m(+0.05278)\n",
            "     | > avg_step_time:\u001b[91m 0.05334 \u001b[0m(+0.00769)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 340/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:26:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.50 sec -- GLOBAL_STEP: 426261\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80285\n",
            "     | > avg_G_stft_loss_sc: 0.35779\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72786\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36685\n",
            "     | > avg_G_mse_fake_loss: 0.31820\n",
            "     | > avg_G_loss: 1.92317\n",
            "     | > avg_G_gen_loss: 1.12767\n",
            "     | > avg_G_adv_loss: 0.79549\n",
            "     | > avg_D_mse_gan_loss: 0.44688\n",
            "     | > avg_D_mse_gan_real_loss: 0.13814\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13830\n",
            "     | > avg_D_loss: 0.44688\n",
            "     | > avg_loader_time: 0.85789\n",
            "     | > avg_step_time: 0.61485\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78601 \u001b[0m(-0.00111)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36570 \u001b[0m(+0.00295)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70017 \u001b[0m(-0.00093)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37841 \u001b[0m(-0.00257)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37452 \u001b[0m(+0.04942)\n",
            "     | > avg_G_loss:\u001b[91m 2.05143 \u001b[0m(+0.12272)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11514 \u001b[0m(-0.00083)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93629 \u001b[0m(+0.12354)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45144 \u001b[0m(+0.00978)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.19254 \u001b[0m(+0.03190)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08995 \u001b[0m(-0.01770)\n",
            "     | > avg_D_loss:\u001b[91m 0.45144 \u001b[0m(+0.00978)\n",
            "     | > avg_loader_time:\u001b[92m 0.39795 \u001b[0m(-0.02699)\n",
            "     | > avg_step_time:\u001b[92m 0.05188 \u001b[0m(-0.00146)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 341/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:29:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.09 sec -- GLOBAL_STEP: 426382\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81589\n",
            "     | > avg_G_stft_loss_sc: 0.35891\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75352\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36775\n",
            "     | > avg_G_mse_fake_loss: 0.31848\n",
            "     | > avg_G_loss: 1.94423\n",
            "     | > avg_G_gen_loss: 1.14803\n",
            "     | > avg_G_adv_loss: 0.79620\n",
            "     | > avg_D_mse_gan_loss: 0.44655\n",
            "     | > avg_D_mse_gan_real_loss: 0.13904\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13842\n",
            "     | > avg_D_loss: 0.44655\n",
            "     | > avg_loader_time: 0.84581\n",
            "     | > avg_step_time: 0.61922\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78701 \u001b[0m(+0.00099)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35967 \u001b[0m(-0.00603)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70039 \u001b[0m(+0.00022)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37589 \u001b[0m(-0.00252)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34815 \u001b[0m(-0.02637)\n",
            "     | > avg_G_loss:\u001b[92m 1.98185 \u001b[0m(-0.06958)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11147 \u001b[0m(-0.00367)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.87037 \u001b[0m(-0.06592)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44876 \u001b[0m(-0.00268)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15981 \u001b[0m(-0.03273)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11417 \u001b[0m(+0.02422)\n",
            "     | > avg_D_loss:\u001b[92m 0.44876 \u001b[0m(-0.00268)\n",
            "     | > avg_loader_time:\u001b[91m 0.41815 \u001b[0m(+0.02020)\n",
            "     | > avg_step_time:\u001b[91m 0.05329 \u001b[0m(+0.00141)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 342/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:32:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.82 sec -- GLOBAL_STEP: 426503\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81164\n",
            "     | > avg_G_stft_loss_sc: 0.36295\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74697\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37138\n",
            "     | > avg_G_mse_fake_loss: 0.31204\n",
            "     | > avg_G_loss: 1.92657\n",
            "     | > avg_G_gen_loss: 1.14647\n",
            "     | > avg_G_adv_loss: 0.78010\n",
            "     | > avg_D_mse_gan_loss: 0.44844\n",
            "     | > avg_D_mse_gan_real_loss: 0.13882\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13794\n",
            "     | > avg_D_loss: 0.44844\n",
            "     | > avg_loader_time: 0.83674\n",
            "     | > avg_step_time: 0.60105\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78583 \u001b[0m(-0.00117)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36435 \u001b[0m(+0.00469)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70061 \u001b[0m(+0.00023)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37851 \u001b[0m(+0.00262)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31335 \u001b[0m(-0.03480)\n",
            "     | > avg_G_loss:\u001b[92m 1.89804 \u001b[0m(-0.08381)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11465 \u001b[0m(+0.00318)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.78338 \u001b[0m(-0.08699)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44502 \u001b[0m(-0.00374)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13616 \u001b[0m(-0.02365)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13148 \u001b[0m(+0.01731)\n",
            "     | > avg_D_loss:\u001b[92m 0.44502 \u001b[0m(-0.00374)\n",
            "     | > avg_loader_time:\u001b[91m 0.44866 \u001b[0m(+0.03051)\n",
            "     | > avg_step_time:\u001b[91m 0.05475 \u001b[0m(+0.00147)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 343/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:36:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.17 sec -- GLOBAL_STEP: 426624\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81957\n",
            "     | > avg_G_stft_loss_sc: 0.35994\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75882\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36914\n",
            "     | > avg_G_mse_fake_loss: 0.31981\n",
            "     | > avg_G_loss: 1.95327\n",
            "     | > avg_G_gen_loss: 1.15374\n",
            "     | > avg_G_adv_loss: 0.79952\n",
            "     | > avg_D_mse_gan_loss: 0.44668\n",
            "     | > avg_D_mse_gan_real_loss: 0.13899\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13816\n",
            "     | > avg_D_loss: 0.44668\n",
            "     | > avg_loader_time: 0.86638\n",
            "     | > avg_step_time: 0.62025\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78846 \u001b[0m(+0.00263)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36104 \u001b[0m(-0.00331)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70223 \u001b[0m(+0.00162)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37630 \u001b[0m(-0.00221)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32265 \u001b[0m(+0.00930)\n",
            "     | > avg_G_loss:\u001b[91m 1.92065 \u001b[0m(+0.02261)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11402 \u001b[0m(-0.00064)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.80663 \u001b[0m(+0.02325)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44598 \u001b[0m(+0.00096)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.13791 \u001b[0m(+0.00174)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13400 \u001b[0m(+0.00252)\n",
            "     | > avg_D_loss:\u001b[91m 0.44598 \u001b[0m(+0.00096)\n",
            "     | > avg_loader_time:\u001b[91m 0.45070 \u001b[0m(+0.00204)\n",
            "     | > avg_step_time:\u001b[92m 0.05265 \u001b[0m(-0.00211)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 344/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:39:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.39 sec -- GLOBAL_STEP: 426745\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81273\n",
            "     | > avg_G_stft_loss_sc: 0.35991\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75143\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36834\n",
            "     | > avg_G_mse_fake_loss: 0.31276\n",
            "     | > avg_G_loss: 1.92812\n",
            "     | > avg_G_gen_loss: 1.14621\n",
            "     | > avg_G_adv_loss: 0.78191\n",
            "     | > avg_D_mse_gan_loss: 0.44747\n",
            "     | > avg_D_mse_gan_real_loss: 0.13825\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13798\n",
            "     | > avg_D_loss: 0.44747\n",
            "     | > avg_loader_time: 0.85475\n",
            "     | > avg_step_time: 0.61392\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79097 \u001b[0m(+0.00251)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36253 \u001b[0m(+0.00149)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70286 \u001b[0m(+0.00063)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37227 \u001b[0m(-0.00403)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34185 \u001b[0m(+0.01919)\n",
            "     | > avg_G_loss:\u001b[91m 1.96893 \u001b[0m(+0.04828)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11432 \u001b[0m(+0.00030)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85461 \u001b[0m(+0.04798)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44261 \u001b[0m(-0.00337)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16337 \u001b[0m(+0.02546)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10390 \u001b[0m(-0.03010)\n",
            "     | > avg_D_loss:\u001b[92m 0.44261 \u001b[0m(-0.00337)\n",
            "     | > avg_loader_time:\u001b[92m 0.41999 \u001b[0m(-0.03071)\n",
            "     | > avg_step_time:\u001b[92m 0.05260 \u001b[0m(-0.00005)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 345/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:42:19) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.47 sec -- GLOBAL_STEP: 426866\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82002\n",
            "     | > avg_G_stft_loss_sc: 0.35871\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75935\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36746\n",
            "     | > avg_G_mse_fake_loss: 0.31742\n",
            "     | > avg_G_loss: 1.94633\n",
            "     | > avg_G_gen_loss: 1.15277\n",
            "     | > avg_G_adv_loss: 0.79355\n",
            "     | > avg_D_mse_gan_loss: 0.44591\n",
            "     | > avg_D_mse_gan_real_loss: 0.13797\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13782\n",
            "     | > avg_D_loss: 0.44591\n",
            "     | > avg_loader_time: 0.85071\n",
            "     | > avg_step_time: 0.61406\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79115 \u001b[0m(+0.00018)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37662 \u001b[0m(+0.01409)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70611 \u001b[0m(+0.00325)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39718 \u001b[0m(+0.02491)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32542 \u001b[0m(-0.01642)\n",
            "     | > avg_G_loss:\u001b[92m 1.94909 \u001b[0m(-0.01984)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13553 \u001b[0m(+0.02122)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81356 \u001b[0m(-0.04105)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44115 \u001b[0m(-0.00145)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14217 \u001b[0m(-0.02120)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12570 \u001b[0m(+0.02180)\n",
            "     | > avg_D_loss:\u001b[92m 0.44115 \u001b[0m(-0.00145)\n",
            "     | > avg_loader_time:\u001b[92m 0.40780 \u001b[0m(-0.01219)\n",
            "     | > avg_step_time:\u001b[92m 0.05033 \u001b[0m(-0.00227)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 346/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:45:27) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.34 sec -- GLOBAL_STEP: 426987\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81878\n",
            "     | > avg_G_stft_loss_sc: 0.35989\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76139\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36836\n",
            "     | > avg_G_mse_fake_loss: 0.31527\n",
            "     | > avg_G_loss: 1.94239\n",
            "     | > avg_G_gen_loss: 1.15421\n",
            "     | > avg_G_adv_loss: 0.78818\n",
            "     | > avg_D_mse_gan_loss: 0.44716\n",
            "     | > avg_D_mse_gan_real_loss: 0.13867\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13798\n",
            "     | > avg_D_loss: 0.44716\n",
            "     | > avg_loader_time: 0.84629\n",
            "     | > avg_step_time: 0.60492\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78844 \u001b[0m(-0.00271)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35943 \u001b[0m(-0.01719)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70001 \u001b[0m(-0.00610)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36735 \u001b[0m(-0.02983)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36058 \u001b[0m(+0.03515)\n",
            "     | > avg_G_loss:\u001b[91m 2.00906 \u001b[0m(+0.05997)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10762 \u001b[0m(-0.02792)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90144 \u001b[0m(+0.08788)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44447 \u001b[0m(+0.00331)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16344 \u001b[0m(+0.02127)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10655 \u001b[0m(-0.01915)\n",
            "     | > avg_D_loss:\u001b[91m 0.44447 \u001b[0m(+0.00331)\n",
            "     | > avg_loader_time:\u001b[92m 0.39941 \u001b[0m(-0.00838)\n",
            "     | > avg_step_time:\u001b[91m 0.05255 \u001b[0m(+0.00222)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 347/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:48:32) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 12/120 -- GLOBAL_STEP: 427000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80527  (0.81582)\n",
            "     | > G_stft_loss_sc: 0.36205  (0.36028)\n",
            "     | > G_subband_stft_loss_mg: 0.74203  (0.75547)\n",
            "     | > G_subband_stft_loss_sc: 0.35833  (0.36867)\n",
            "     | > G_mse_fake_loss: 0.32380  (0.31734)\n",
            "     | > G_loss: 1.94335  (1.94348)\n",
            "     | > G_gen_loss: 1.13384  (1.15012)\n",
            "     | > G_adv_loss: 0.80951  (0.79336)\n",
            "     | > D_mse_gan_loss: 0.45558  (0.44426)\n",
            "     | > D_mse_gan_real_loss: 0.15603  (0.13868)\n",
            "     | > D_mse_gan_fake_loss: 0.13112  (0.13664)\n",
            "     | > D_loss: 0.45558  (0.44426)\n",
            "     | > step_time: 0.61\n",
            "     | > loader_time: 3.7690\n",
            "     | > current_lr_G: 5.879981941110327e-06\n",
            "     | > current_lr_D: 5.879981941110327e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.74 sec -- GLOBAL_STEP: 427108\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81521\n",
            "     | > avg_G_stft_loss_sc: 0.35869\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75470\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36742\n",
            "     | > avg_G_mse_fake_loss: 0.31594\n",
            "     | > avg_G_loss: 1.93786\n",
            "     | > avg_G_gen_loss: 1.14801\n",
            "     | > avg_G_adv_loss: 0.78985\n",
            "     | > avg_D_mse_gan_loss: 0.44536\n",
            "     | > avg_D_mse_gan_real_loss: 0.13762\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13765\n",
            "     | > avg_D_loss: 0.44536\n",
            "     | > avg_loader_time: 0.84690\n",
            "     | > avg_step_time: 0.62440\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79089 \u001b[0m(+0.00245)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37818 \u001b[0m(+0.01875)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70338 \u001b[0m(+0.00337)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38999 \u001b[0m(+0.02264)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35090 \u001b[0m(-0.00968)\n",
            "     | > avg_G_loss:\u001b[92m 2.00847 \u001b[0m(-0.00059)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13122 \u001b[0m(+0.02361)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.87724 \u001b[0m(-0.02420)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44726 \u001b[0m(+0.00279)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15953 \u001b[0m(-0.00391)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11144 \u001b[0m(+0.00490)\n",
            "     | > avg_D_loss:\u001b[91m 0.44726 \u001b[0m(+0.00279)\n",
            "     | > avg_loader_time:\u001b[91m 0.40120 \u001b[0m(+0.00179)\n",
            "     | > avg_step_time:\u001b[91m 0.05263 \u001b[0m(+0.00008)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 348/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:51:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.99 sec -- GLOBAL_STEP: 427229\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80737\n",
            "     | > avg_G_stft_loss_sc: 0.35845\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73804\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36733\n",
            "     | > avg_G_mse_fake_loss: 0.31505\n",
            "     | > avg_G_loss: 1.92321\n",
            "     | > avg_G_gen_loss: 1.13560\n",
            "     | > avg_G_adv_loss: 0.78761\n",
            "     | > avg_D_mse_gan_loss: 0.44773\n",
            "     | > avg_D_mse_gan_real_loss: 0.13894\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13842\n",
            "     | > avg_D_loss: 0.44773\n",
            "     | > avg_loader_time: 0.86966\n",
            "     | > avg_step_time: 0.61950\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.79013 \u001b[0m(-0.00076)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.37551 \u001b[0m(-0.00267)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70196 \u001b[0m(-0.00142)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37849 \u001b[0m(-0.01150)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35441 \u001b[0m(+0.00352)\n",
            "     | > avg_G_loss:\u001b[91m 2.00908 \u001b[0m(+0.00061)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.12305 \u001b[0m(-0.00818)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88603 \u001b[0m(+0.00879)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45252 \u001b[0m(+0.00526)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16421 \u001b[0m(+0.00469)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11222 \u001b[0m(+0.00078)\n",
            "     | > avg_D_loss:\u001b[91m 0.45252 \u001b[0m(+0.00526)\n",
            "     | > avg_loader_time:\u001b[91m 0.42109 \u001b[0m(+0.01989)\n",
            "     | > avg_step_time:\u001b[92m 0.05246 \u001b[0m(-0.00017)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 349/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:54:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.43 sec -- GLOBAL_STEP: 427350\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80482\n",
            "     | > avg_G_stft_loss_sc: 0.35953\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73284\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36855\n",
            "     | > avg_G_mse_fake_loss: 0.31806\n",
            "     | > avg_G_loss: 1.92801\n",
            "     | > avg_G_gen_loss: 1.13287\n",
            "     | > avg_G_adv_loss: 0.79514\n",
            "     | > avg_D_mse_gan_loss: 0.44692\n",
            "     | > avg_D_mse_gan_real_loss: 0.13863\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13778\n",
            "     | > avg_D_loss: 0.44692\n",
            "     | > avg_loader_time: 0.84571\n",
            "     | > avg_step_time: 0.58909\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78665 \u001b[0m(-0.00348)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36888 \u001b[0m(-0.00664)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70202 \u001b[0m(+0.00006)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38744 \u001b[0m(+0.00895)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33384 \u001b[0m(-0.02057)\n",
            "     | > avg_G_loss:\u001b[92m 1.95710 \u001b[0m(-0.05198)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.12250 \u001b[0m(-0.00055)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.83461 \u001b[0m(-0.05143)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44956 \u001b[0m(-0.00295)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16517 \u001b[0m(+0.00096)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11308 \u001b[0m(+0.00086)\n",
            "     | > avg_D_loss:\u001b[92m 0.44956 \u001b[0m(-0.00295)\n",
            "     | > avg_loader_time:\u001b[92m 0.40457 \u001b[0m(-0.01652)\n",
            "     | > avg_step_time:\u001b[92m 0.05035 \u001b[0m(-0.00211)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 350/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 19:57:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.84 sec -- GLOBAL_STEP: 427471\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81635\n",
            "     | > avg_G_stft_loss_sc: 0.35977\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75586\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36806\n",
            "     | > avg_G_mse_fake_loss: 0.31586\n",
            "     | > avg_G_loss: 1.93968\n",
            "     | > avg_G_gen_loss: 1.15002\n",
            "     | > avg_G_adv_loss: 0.78966\n",
            "     | > avg_D_mse_gan_loss: 0.44617\n",
            "     | > avg_D_mse_gan_real_loss: 0.13803\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13796\n",
            "     | > avg_D_loss: 0.44617\n",
            "     | > avg_loader_time: 0.84860\n",
            "     | > avg_step_time: 0.59973\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79001 \u001b[0m(+0.00336)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37293 \u001b[0m(+0.00405)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70133 \u001b[0m(-0.00070)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36828 \u001b[0m(-0.01916)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34373 \u001b[0m(+0.00988)\n",
            "     | > avg_G_loss:\u001b[91m 1.97558 \u001b[0m(+0.01848)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11627 \u001b[0m(-0.00623)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85931 \u001b[0m(+0.02471)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44692 \u001b[0m(-0.00264)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14369 \u001b[0m(-0.02148)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12407 \u001b[0m(+0.01099)\n",
            "     | > avg_D_loss:\u001b[92m 0.44692 \u001b[0m(-0.00264)\n",
            "     | > avg_loader_time:\u001b[92m 0.40241 \u001b[0m(-0.00216)\n",
            "     | > avg_step_time:\u001b[91m 0.05418 \u001b[0m(+0.00383)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 351/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:01:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.98 sec -- GLOBAL_STEP: 427592\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80621\n",
            "     | > avg_G_stft_loss_sc: 0.35892\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73653\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36785\n",
            "     | > avg_G_mse_fake_loss: 0.31596\n",
            "     | > avg_G_loss: 1.92465\n",
            "     | > avg_G_gen_loss: 1.13475\n",
            "     | > avg_G_adv_loss: 0.78990\n",
            "     | > avg_D_mse_gan_loss: 0.44688\n",
            "     | > avg_D_mse_gan_real_loss: 0.13882\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13802\n",
            "     | > avg_D_loss: 0.44688\n",
            "     | > avg_loader_time: 0.83835\n",
            "     | > avg_step_time: 0.60232\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78593 \u001b[0m(-0.00408)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36097 \u001b[0m(-0.01196)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70098 \u001b[0m(-0.00035)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37859 \u001b[0m(+0.01031)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33781 \u001b[0m(-0.00591)\n",
            "     | > avg_G_loss:\u001b[92m 1.95776 \u001b[0m(-0.01782)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11323 \u001b[0m(-0.00304)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84453 \u001b[0m(-0.01479)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44238 \u001b[0m(-0.00454)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15427 \u001b[0m(+0.01058)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11570 \u001b[0m(-0.00837)\n",
            "     | > avg_D_loss:\u001b[92m 0.44238 \u001b[0m(-0.00454)\n",
            "     | > avg_loader_time:\u001b[91m 0.48486 \u001b[0m(+0.08245)\n",
            "     | > avg_step_time:\u001b[91m 0.05426 \u001b[0m(+0.00008)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 352/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:04:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.47 sec -- GLOBAL_STEP: 427713\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81416\n",
            "     | > avg_G_stft_loss_sc: 0.35758\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75177\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36604\n",
            "     | > avg_G_mse_fake_loss: 0.31698\n",
            "     | > avg_G_loss: 1.93721\n",
            "     | > avg_G_gen_loss: 1.14477\n",
            "     | > avg_G_adv_loss: 0.79244\n",
            "     | > avg_D_mse_gan_loss: 0.44628\n",
            "     | > avg_D_mse_gan_real_loss: 0.13890\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13805\n",
            "     | > avg_D_loss: 0.44628\n",
            "     | > avg_loader_time: 0.84344\n",
            "     | > avg_step_time: 0.59784\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78677 \u001b[0m(+0.00084)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35860 \u001b[0m(-0.00237)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69994 \u001b[0m(-0.00104)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37083 \u001b[0m(-0.00776)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31042 \u001b[0m(-0.02739)\n",
            "     | > avg_G_loss:\u001b[92m 1.88413 \u001b[0m(-0.07363)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10807 \u001b[0m(-0.00516)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.77605 \u001b[0m(-0.06847)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44378 \u001b[0m(+0.00140)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14010 \u001b[0m(-0.01417)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12475 \u001b[0m(+0.00904)\n",
            "     | > avg_D_loss:\u001b[91m 0.44378 \u001b[0m(+0.00140)\n",
            "     | > avg_loader_time:\u001b[92m 0.40931 \u001b[0m(-0.07554)\n",
            "     | > avg_step_time:\u001b[92m 0.04949 \u001b[0m(-0.00477)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 353/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:07:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.98 sec -- GLOBAL_STEP: 427834\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81475\n",
            "     | > avg_G_stft_loss_sc: 0.35935\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75413\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36803\n",
            "     | > avg_G_mse_fake_loss: 0.31648\n",
            "     | > avg_G_loss: 1.93933\n",
            "     | > avg_G_gen_loss: 1.14813\n",
            "     | > avg_G_adv_loss: 0.79120\n",
            "     | > avg_D_mse_gan_loss: 0.44539\n",
            "     | > avg_D_mse_gan_real_loss: 0.13796\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13773\n",
            "     | > avg_D_loss: 0.44539\n",
            "     | > avg_loader_time: 0.84780\n",
            "     | > avg_step_time: 0.60216\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78628 \u001b[0m(-0.00049)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36007 \u001b[0m(+0.00147)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70017 \u001b[0m(+0.00023)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37172 \u001b[0m(+0.00088)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38926 \u001b[0m(+0.07884)\n",
            "     | > avg_G_loss:\u001b[91m 2.08227 \u001b[0m(+0.19814)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10912 \u001b[0m(+0.00104)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.97315 \u001b[0m(+0.19710)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44750 \u001b[0m(+0.00371)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17404 \u001b[0m(+0.03394)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09887 \u001b[0m(-0.02588)\n",
            "     | > avg_D_loss:\u001b[91m 0.44750 \u001b[0m(+0.00371)\n",
            "     | > avg_loader_time:\u001b[92m 0.37445 \u001b[0m(-0.03486)\n",
            "     | > avg_step_time:\u001b[91m 0.05046 \u001b[0m(+0.00097)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 354/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:10:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.52 sec -- GLOBAL_STEP: 427955\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81674\n",
            "     | > avg_G_stft_loss_sc: 0.35925\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75800\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36765\n",
            "     | > avg_G_mse_fake_loss: 0.31571\n",
            "     | > avg_G_loss: 1.94010\n",
            "     | > avg_G_gen_loss: 1.15082\n",
            "     | > avg_G_adv_loss: 0.78928\n",
            "     | > avg_D_mse_gan_loss: 0.44634\n",
            "     | > avg_D_mse_gan_real_loss: 0.13790\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13784\n",
            "     | > avg_D_loss: 0.44634\n",
            "     | > avg_loader_time: 0.83954\n",
            "     | > avg_step_time: 0.59006\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78980 \u001b[0m(+0.00352)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37111 \u001b[0m(+0.01103)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70387 \u001b[0m(+0.00370)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39195 \u001b[0m(+0.02024)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34073 \u001b[0m(-0.04853)\n",
            "     | > avg_G_loss:\u001b[92m 1.98018 \u001b[0m(-0.10209)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12836 \u001b[0m(+0.01924)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85182 \u001b[0m(-0.12133)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44421 \u001b[0m(-0.00329)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16919 \u001b[0m(-0.00485)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10349 \u001b[0m(+0.00462)\n",
            "     | > avg_D_loss:\u001b[92m 0.44421 \u001b[0m(-0.00329)\n",
            "     | > avg_loader_time:\u001b[91m 0.44341 \u001b[0m(+0.06896)\n",
            "     | > avg_step_time:\u001b[91m 0.05123 \u001b[0m(+0.00076)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 355/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:13:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 44/120 -- GLOBAL_STEP: 428000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81467  (0.81443)\n",
            "     | > G_stft_loss_sc: 0.35674  (0.35842)\n",
            "     | > G_subband_stft_loss_mg: 0.75448  (0.75438)\n",
            "     | > G_subband_stft_loss_sc: 0.36266  (0.36662)\n",
            "     | > G_mse_fake_loss: 0.31317  (0.31268)\n",
            "     | > G_loss: 1.92721  (1.92862)\n",
            "     | > G_gen_loss: 1.14428  (1.14693)\n",
            "     | > G_adv_loss: 0.78293  (0.78169)\n",
            "     | > D_mse_gan_loss: 0.45161  (0.44831)\n",
            "     | > D_mse_gan_real_loss: 0.14360  (0.13936)\n",
            "     | > D_mse_gan_fake_loss: 0.14314  (0.13956)\n",
            "     | > D_loss: 0.45161  (0.44831)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 1.9389\n",
            "     | > current_lr_G: 5.833106396208075e-06\n",
            "     | > current_lr_D: 5.833106396208075e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.50 sec -- GLOBAL_STEP: 428076\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81432\n",
            "     | > avg_G_stft_loss_sc: 0.35902\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75453\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36726\n",
            "     | > avg_G_mse_fake_loss: 0.31282\n",
            "     | > avg_G_loss: 1.92960\n",
            "     | > avg_G_gen_loss: 1.14756\n",
            "     | > avg_G_adv_loss: 0.78204\n",
            "     | > avg_D_mse_gan_loss: 0.44793\n",
            "     | > avg_D_mse_gan_real_loss: 0.13878\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13870\n",
            "     | > avg_D_loss: 0.44793\n",
            "     | > avg_loader_time: 0.83960\n",
            "     | > avg_step_time: 0.59847\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78847 \u001b[0m(-0.00133)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35800 \u001b[0m(-0.01311)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70220 \u001b[0m(-0.00166)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37356 \u001b[0m(-0.01840)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35963 \u001b[0m(+0.01890)\n",
            "     | > avg_G_loss:\u001b[91m 2.01018 \u001b[0m(+0.03000)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11112 \u001b[0m(-0.01725)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89906 \u001b[0m(+0.04724)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44707 \u001b[0m(+0.00286)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15185 \u001b[0m(-0.01735)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11841 \u001b[0m(+0.01492)\n",
            "     | > avg_D_loss:\u001b[91m 0.44707 \u001b[0m(+0.00286)\n",
            "     | > avg_loader_time:\u001b[91m 0.46068 \u001b[0m(+0.01727)\n",
            "     | > avg_step_time:\u001b[92m 0.04941 \u001b[0m(-0.00182)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 356/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:16:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.94 sec -- GLOBAL_STEP: 428197\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81415\n",
            "     | > avg_G_stft_loss_sc: 0.35932\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75157\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36820\n",
            "     | > avg_G_mse_fake_loss: 0.31597\n",
            "     | > avg_G_loss: 1.93655\n",
            "     | > avg_G_gen_loss: 1.14663\n",
            "     | > avg_G_adv_loss: 0.78993\n",
            "     | > avg_D_mse_gan_loss: 0.44636\n",
            "     | > avg_D_mse_gan_real_loss: 0.13874\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13792\n",
            "     | > avg_D_loss: 0.44636\n",
            "     | > avg_loader_time: 0.83955\n",
            "     | > avg_step_time: 0.61823\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79020 \u001b[0m(+0.00173)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36963 \u001b[0m(+0.01164)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70195 \u001b[0m(-0.00025)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37856 \u001b[0m(+0.00501)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36455 \u001b[0m(+0.00492)\n",
            "     | > avg_G_loss:\u001b[91m 2.03155 \u001b[0m(+0.02137)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12018 \u001b[0m(+0.00906)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91138 \u001b[0m(+0.01231)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44557 \u001b[0m(-0.00150)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16362 \u001b[0m(+0.01178)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10843 \u001b[0m(-0.00998)\n",
            "     | > avg_D_loss:\u001b[92m 0.44557 \u001b[0m(-0.00150)\n",
            "     | > avg_loader_time:\u001b[92m 0.39335 \u001b[0m(-0.06734)\n",
            "     | > avg_step_time:\u001b[91m 0.04963 \u001b[0m(+0.00022)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 357/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:19:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.53 sec -- GLOBAL_STEP: 428318\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81022\n",
            "     | > avg_G_stft_loss_sc: 0.35830\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74625\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36653\n",
            "     | > avg_G_mse_fake_loss: 0.31286\n",
            "     | > avg_G_loss: 1.92279\n",
            "     | > avg_G_gen_loss: 1.14065\n",
            "     | > avg_G_adv_loss: 0.78214\n",
            "     | > avg_D_mse_gan_loss: 0.44706\n",
            "     | > avg_D_mse_gan_real_loss: 0.13818\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13802\n",
            "     | > avg_D_loss: 0.44706\n",
            "     | > avg_loader_time: 0.84675\n",
            "     | > avg_step_time: 0.61534\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78741 \u001b[0m(-0.00279)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36172 \u001b[0m(-0.00791)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69987 \u001b[0m(-0.00208)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37576 \u001b[0m(-0.00281)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35253 \u001b[0m(-0.01202)\n",
            "     | > avg_G_loss:\u001b[92m 1.99369 \u001b[0m(-0.03786)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11238 \u001b[0m(-0.00780)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88131 \u001b[0m(-0.03006)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44787 \u001b[0m(+0.00230)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18005 \u001b[0m(+0.01643)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09453 \u001b[0m(-0.01390)\n",
            "     | > avg_D_loss:\u001b[91m 0.44787 \u001b[0m(+0.00230)\n",
            "     | > avg_loader_time:\u001b[91m 0.44976 \u001b[0m(+0.05641)\n",
            "     | > avg_step_time:\u001b[91m 0.05167 \u001b[0m(+0.00204)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 358/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:22:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.84 sec -- GLOBAL_STEP: 428439\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81490\n",
            "     | > avg_G_stft_loss_sc: 0.35730\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75638\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36581\n",
            "     | > avg_G_mse_fake_loss: 0.31334\n",
            "     | > avg_G_loss: 1.93054\n",
            "     | > avg_G_gen_loss: 1.14720\n",
            "     | > avg_G_adv_loss: 0.78335\n",
            "     | > avg_D_mse_gan_loss: 0.44752\n",
            "     | > avg_D_mse_gan_real_loss: 0.13826\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13864\n",
            "     | > avg_D_loss: 0.44752\n",
            "     | > avg_loader_time: 0.86960\n",
            "     | > avg_step_time: 0.61617\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78899 \u001b[0m(+0.00158)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36399 \u001b[0m(+0.00227)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70112 \u001b[0m(+0.00124)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37343 \u001b[0m(-0.00232)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36314 \u001b[0m(+0.01062)\n",
            "     | > avg_G_loss:\u001b[91m 2.02162 \u001b[0m(+0.02793)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11377 \u001b[0m(+0.00139)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90785 \u001b[0m(+0.02654)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45032 \u001b[0m(+0.00244)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16111 \u001b[0m(-0.01895)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11144 \u001b[0m(+0.01691)\n",
            "     | > avg_D_loss:\u001b[91m 0.45032 \u001b[0m(+0.00244)\n",
            "     | > avg_loader_time:\u001b[92m 0.38583 \u001b[0m(-0.06392)\n",
            "     | > avg_step_time:\u001b[92m 0.05083 \u001b[0m(-0.00084)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 359/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:25:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.12 sec -- GLOBAL_STEP: 428560\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80296\n",
            "     | > avg_G_stft_loss_sc: 0.35773\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72798\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36698\n",
            "     | > avg_G_mse_fake_loss: 0.31967\n",
            "     | > avg_G_loss: 1.92701\n",
            "     | > avg_G_gen_loss: 1.12783\n",
            "     | > avg_G_adv_loss: 0.79919\n",
            "     | > avg_D_mse_gan_loss: 0.44710\n",
            "     | > avg_D_mse_gan_real_loss: 0.13907\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13803\n",
            "     | > avg_D_loss: 0.44710\n",
            "     | > avg_loader_time: 0.87793\n",
            "     | > avg_step_time: 0.61043\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78843 \u001b[0m(-0.00056)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36631 \u001b[0m(+0.00231)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70234 \u001b[0m(+0.00123)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38397 \u001b[0m(+0.01054)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33025 \u001b[0m(-0.03290)\n",
            "     | > avg_G_loss:\u001b[92m 1.94614 \u001b[0m(-0.07548)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12053 \u001b[0m(+0.00676)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82561 \u001b[0m(-0.08224)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44925 \u001b[0m(-0.00107)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15788 \u001b[0m(-0.00322)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11980 \u001b[0m(+0.00835)\n",
            "     | > avg_D_loss:\u001b[92m 0.44925 \u001b[0m(-0.00107)\n",
            "     | > avg_loader_time:\u001b[91m 0.39357 \u001b[0m(+0.00773)\n",
            "     | > avg_step_time:\u001b[91m 0.05179 \u001b[0m(+0.00095)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 360/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:28:53) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.52 sec -- GLOBAL_STEP: 428681\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81735\n",
            "     | > avg_G_stft_loss_sc: 0.36014\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75747\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36899\n",
            "     | > avg_G_mse_fake_loss: 0.31571\n",
            "     | > avg_G_loss: 1.94124\n",
            "     | > avg_G_gen_loss: 1.15198\n",
            "     | > avg_G_adv_loss: 0.78926\n",
            "     | > avg_D_mse_gan_loss: 0.44725\n",
            "     | > avg_D_mse_gan_real_loss: 0.13919\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13861\n",
            "     | > avg_D_loss: 0.44725\n",
            "     | > avg_loader_time: 0.85075\n",
            "     | > avg_step_time: 0.60726\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78707 \u001b[0m(-0.00136)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36760 \u001b[0m(+0.00130)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70106 \u001b[0m(-0.00128)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38548 \u001b[0m(+0.00151)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31832 \u001b[0m(-0.01192)\n",
            "     | > avg_G_loss:\u001b[92m 1.91641 \u001b[0m(-0.02973)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12061 \u001b[0m(+0.00008)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.79581 \u001b[0m(-0.02981)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44229 \u001b[0m(-0.00696)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13626 \u001b[0m(-0.02163)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13242 \u001b[0m(+0.01263)\n",
            "     | > avg_D_loss:\u001b[92m 0.44229 \u001b[0m(-0.00696)\n",
            "     | > avg_loader_time:\u001b[91m 0.41067 \u001b[0m(+0.01710)\n",
            "     | > avg_step_time:\u001b[91m 0.05591 \u001b[0m(+0.00412)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 361/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:32:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.91 sec -- GLOBAL_STEP: 428802\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81329\n",
            "     | > avg_G_stft_loss_sc: 0.36042\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74986\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36952\n",
            "     | > avg_G_mse_fake_loss: 0.31739\n",
            "     | > avg_G_loss: 1.94001\n",
            "     | > avg_G_gen_loss: 1.14654\n",
            "     | > avg_G_adv_loss: 0.79346\n",
            "     | > avg_D_mse_gan_loss: 0.44642\n",
            "     | > avg_D_mse_gan_real_loss: 0.13843\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13761\n",
            "     | > avg_D_loss: 0.44642\n",
            "     | > avg_loader_time: 0.86443\n",
            "     | > avg_step_time: 0.61791\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78794 \u001b[0m(+0.00088)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35996 \u001b[0m(-0.00764)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70174 \u001b[0m(+0.00068)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37495 \u001b[0m(-0.01053)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34421 \u001b[0m(+0.02589)\n",
            "     | > avg_G_loss:\u001b[91m 1.97284 \u001b[0m(+0.05642)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11230 \u001b[0m(-0.00831)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86054 \u001b[0m(+0.06473)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44317 \u001b[0m(+0.00088)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15070 \u001b[0m(+0.01444)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11704 \u001b[0m(-0.01538)\n",
            "     | > avg_D_loss:\u001b[91m 0.44317 \u001b[0m(+0.00088)\n",
            "     | > avg_loader_time:\u001b[91m 0.42369 \u001b[0m(+0.01303)\n",
            "     | > avg_step_time:\u001b[92m 0.05393 \u001b[0m(-0.00198)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 362/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:35:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.31 sec -- GLOBAL_STEP: 428923\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82044\n",
            "     | > avg_G_stft_loss_sc: 0.35965\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76160\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36864\n",
            "     | > avg_G_mse_fake_loss: 0.31910\n",
            "     | > avg_G_loss: 1.95292\n",
            "     | > avg_G_gen_loss: 1.15517\n",
            "     | > avg_G_adv_loss: 0.79776\n",
            "     | > avg_D_mse_gan_loss: 0.44598\n",
            "     | > avg_D_mse_gan_real_loss: 0.13859\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13841\n",
            "     | > avg_D_loss: 0.44598\n",
            "     | > avg_loader_time: 0.85808\n",
            "     | > avg_step_time: 0.62154\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79013 \u001b[0m(+0.00218)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37119 \u001b[0m(+0.01123)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70176 \u001b[0m(+0.00001)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37357 \u001b[0m(-0.00137)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37592 \u001b[0m(+0.03170)\n",
            "     | > avg_G_loss:\u001b[91m 2.05811 \u001b[0m(+0.08528)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11832 \u001b[0m(+0.00603)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93979 \u001b[0m(+0.07925)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45154 \u001b[0m(+0.00837)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18180 \u001b[0m(+0.03110)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09623 \u001b[0m(-0.02080)\n",
            "     | > avg_D_loss:\u001b[91m 0.45154 \u001b[0m(+0.00837)\n",
            "     | > avg_loader_time:\u001b[91m 0.46452 \u001b[0m(+0.04083)\n",
            "     | > avg_step_time:\u001b[91m 0.05650 \u001b[0m(+0.00258)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 363/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:38:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 76/120 -- GLOBAL_STEP: 429000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80426  (0.80788)\n",
            "     | > G_stft_loss_sc: 0.37307  (0.35913)\n",
            "     | > G_subband_stft_loss_mg: 0.73431  (0.73743)\n",
            "     | > G_subband_stft_loss_sc: 0.38147  (0.36843)\n",
            "     | > G_mse_fake_loss: 0.34040  (0.31841)\n",
            "     | > G_loss: 1.99755  (1.93245)\n",
            "     | > G_gen_loss: 1.14655  (1.13644)\n",
            "     | > G_adv_loss: 0.85100  (0.79602)\n",
            "     | > D_mse_gan_loss: 0.45379  (0.44689)\n",
            "     | > D_mse_gan_real_loss: 0.15649  (0.13911)\n",
            "     | > D_mse_gan_fake_loss: 0.12641  (0.13823)\n",
            "     | > D_loss: 0.45379  (0.44689)\n",
            "     | > step_time: 0.65\n",
            "     | > loader_time: 0.8720\n",
            "     | > current_lr_G: 5.786604545771537e-06\n",
            "     | > current_lr_D: 5.786604545771537e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.00 sec -- GLOBAL_STEP: 429044\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80798\n",
            "     | > avg_G_stft_loss_sc: 0.35893\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73732\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36799\n",
            "     | > avg_G_mse_fake_loss: 0.31830\n",
            "     | > avg_G_loss: 1.93185\n",
            "     | > avg_G_gen_loss: 1.13611\n",
            "     | > avg_G_adv_loss: 0.79574\n",
            "     | > avg_D_mse_gan_loss: 0.44681\n",
            "     | > avg_D_mse_gan_real_loss: 0.13901\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13819\n",
            "     | > avg_D_loss: 0.44681\n",
            "     | > avg_loader_time: 0.88976\n",
            "     | > avg_step_time: 0.63549\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78557 \u001b[0m(-0.00456)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36745 \u001b[0m(-0.00374)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70008 \u001b[0m(-0.00167)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38350 \u001b[0m(+0.00993)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33684 \u001b[0m(-0.03908)\n",
            "     | > avg_G_loss:\u001b[92m 1.96040 \u001b[0m(-0.09771)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11830 \u001b[0m(-0.00002)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84210 \u001b[0m(-0.09769)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44474 \u001b[0m(-0.00680)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15927 \u001b[0m(-0.02253)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11069 \u001b[0m(+0.01445)\n",
            "     | > avg_D_loss:\u001b[92m 0.44474 \u001b[0m(-0.00680)\n",
            "     | > avg_loader_time:\u001b[92m 0.43315 \u001b[0m(-0.03137)\n",
            "     | > avg_step_time:\u001b[92m 0.05364 \u001b[0m(-0.00287)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 364/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:41:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.65 sec -- GLOBAL_STEP: 429165\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80547\n",
            "     | > avg_G_stft_loss_sc: 0.36070\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73505\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36944\n",
            "     | > avg_G_mse_fake_loss: 0.31581\n",
            "     | > avg_G_loss: 1.92485\n",
            "     | > avg_G_gen_loss: 1.13533\n",
            "     | > avg_G_adv_loss: 0.78952\n",
            "     | > avg_D_mse_gan_loss: 0.44825\n",
            "     | > avg_D_mse_gan_real_loss: 0.13942\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13849\n",
            "     | > avg_D_loss: 0.44825\n",
            "     | > avg_loader_time: 0.86018\n",
            "     | > avg_step_time: 0.62182\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78795 \u001b[0m(+0.00238)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37390 \u001b[0m(+0.00645)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70366 \u001b[0m(+0.00358)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39615 \u001b[0m(+0.01264)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.30654 \u001b[0m(-0.03030)\n",
            "     | > avg_G_loss:\u001b[92m 1.89719 \u001b[0m(-0.06321)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13083 \u001b[0m(+0.01252)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.76636 \u001b[0m(-0.07574)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44551 \u001b[0m(+0.00077)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15195 \u001b[0m(-0.00732)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11893 \u001b[0m(+0.00824)\n",
            "     | > avg_D_loss:\u001b[91m 0.44551 \u001b[0m(+0.00077)\n",
            "     | > avg_loader_time:\u001b[92m 0.42972 \u001b[0m(-0.00343)\n",
            "     | > avg_step_time:\u001b[91m 0.05523 \u001b[0m(+0.00159)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 365/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:44:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.83 sec -- GLOBAL_STEP: 429286\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81462\n",
            "     | > avg_G_stft_loss_sc: 0.35756\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75360\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36602\n",
            "     | > avg_G_mse_fake_loss: 0.31402\n",
            "     | > avg_G_loss: 1.93094\n",
            "     | > avg_G_gen_loss: 1.14590\n",
            "     | > avg_G_adv_loss: 0.78504\n",
            "     | > avg_D_mse_gan_loss: 0.44744\n",
            "     | > avg_D_mse_gan_real_loss: 0.13910\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13891\n",
            "     | > avg_D_loss: 0.44744\n",
            "     | > avg_loader_time: 0.85002\n",
            "     | > avg_step_time: 0.60104\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78572 \u001b[0m(-0.00223)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36105 \u001b[0m(-0.01285)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69933 \u001b[0m(-0.00433)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36962 \u001b[0m(-0.02653)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36064 \u001b[0m(+0.05409)\n",
            "     | > avg_G_loss:\u001b[91m 2.00945 \u001b[0m(+0.11226)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10786 \u001b[0m(-0.02297)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90159 \u001b[0m(+0.13523)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44480 \u001b[0m(-0.00072)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17920 \u001b[0m(+0.02725)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09373 \u001b[0m(-0.02520)\n",
            "     | > avg_D_loss:\u001b[92m 0.44480 \u001b[0m(-0.00072)\n",
            "     | > avg_loader_time:\u001b[92m 0.40285 \u001b[0m(-0.02687)\n",
            "     | > avg_step_time:\u001b[92m 0.05058 \u001b[0m(-0.00466)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 366/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:47:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.81 sec -- GLOBAL_STEP: 429407\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81510\n",
            "     | > avg_G_stft_loss_sc: 0.35671\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75555\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36543\n",
            "     | > avg_G_mse_fake_loss: 0.31435\n",
            "     | > avg_G_loss: 1.93226\n",
            "     | > avg_G_gen_loss: 1.14639\n",
            "     | > avg_G_adv_loss: 0.78586\n",
            "     | > avg_D_mse_gan_loss: 0.44717\n",
            "     | > avg_D_mse_gan_real_loss: 0.13839\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13890\n",
            "     | > avg_D_loss: 0.44717\n",
            "     | > avg_loader_time: 0.85933\n",
            "     | > avg_step_time: 0.61666\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78848 \u001b[0m(+0.00276)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36660 \u001b[0m(+0.00556)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70168 \u001b[0m(+0.00235)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37949 \u001b[0m(+0.00987)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37410 \u001b[0m(+0.01347)\n",
            "     | > avg_G_loss:\u001b[91m 2.05339 \u001b[0m(+0.04394)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11813 \u001b[0m(+0.01027)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93526 \u001b[0m(+0.03367)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44977 \u001b[0m(+0.00498)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16692 \u001b[0m(-0.01228)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10602 \u001b[0m(+0.01229)\n",
            "     | > avg_D_loss:\u001b[91m 0.44977 \u001b[0m(+0.00498)\n",
            "     | > avg_loader_time:\u001b[92m 0.38783 \u001b[0m(-0.01502)\n",
            "     | > avg_step_time:\u001b[91m 0.05077 \u001b[0m(+0.00020)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 367/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:50:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.64 sec -- GLOBAL_STEP: 429528\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81248\n",
            "     | > avg_G_stft_loss_sc: 0.35563\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74779\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36462\n",
            "     | > avg_G_mse_fake_loss: 0.31798\n",
            "     | > avg_G_loss: 1.93520\n",
            "     | > avg_G_gen_loss: 1.14026\n",
            "     | > avg_G_adv_loss: 0.79494\n",
            "     | > avg_D_mse_gan_loss: 0.44523\n",
            "     | > avg_D_mse_gan_real_loss: 0.13800\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13746\n",
            "     | > avg_D_loss: 0.44523\n",
            "     | > avg_loader_time: 0.84937\n",
            "     | > avg_step_time: 0.59938\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78600 \u001b[0m(-0.00248)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37195 \u001b[0m(+0.00534)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70009 \u001b[0m(-0.00159)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38772 \u001b[0m(+0.00823)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34488 \u001b[0m(-0.02922)\n",
            "     | > avg_G_loss:\u001b[92m 1.98509 \u001b[0m(-0.06829)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12288 \u001b[0m(+0.00475)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.86221 \u001b[0m(-0.07305)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44333 \u001b[0m(-0.00644)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15239 \u001b[0m(-0.01453)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11350 \u001b[0m(+0.00748)\n",
            "     | > avg_D_loss:\u001b[92m 0.44333 \u001b[0m(-0.00644)\n",
            "     | > avg_loader_time:\u001b[91m 0.41683 \u001b[0m(+0.02899)\n",
            "     | > avg_step_time:\u001b[91m 0.05411 \u001b[0m(+0.00334)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 368/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:54:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.91 sec -- GLOBAL_STEP: 429649\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81376\n",
            "     | > avg_G_stft_loss_sc: 0.35850\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75097\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36711\n",
            "     | > avg_G_mse_fake_loss: 0.31652\n",
            "     | > avg_G_loss: 1.93647\n",
            "     | > avg_G_gen_loss: 1.14517\n",
            "     | > avg_G_adv_loss: 0.79130\n",
            "     | > avg_D_mse_gan_loss: 0.44733\n",
            "     | > avg_D_mse_gan_real_loss: 0.13902\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13829\n",
            "     | > avg_D_loss: 0.44733\n",
            "     | > avg_loader_time: 0.87856\n",
            "     | > avg_step_time: 0.61817\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78606 \u001b[0m(+0.00006)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36458 \u001b[0m(-0.00737)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69973 \u001b[0m(-0.00036)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37205 \u001b[0m(-0.01567)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31469 \u001b[0m(-0.03019)\n",
            "     | > avg_G_loss:\u001b[92m 1.89795 \u001b[0m(-0.08715)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11121 \u001b[0m(-0.01167)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.78673 \u001b[0m(-0.07548)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44173 \u001b[0m(-0.00160)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13762 \u001b[0m(-0.01477)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12959 \u001b[0m(+0.01609)\n",
            "     | > avg_D_loss:\u001b[92m 0.44173 \u001b[0m(-0.00160)\n",
            "     | > avg_loader_time:\u001b[92m 0.40939 \u001b[0m(-0.00744)\n",
            "     | > avg_step_time:\u001b[92m 0.05288 \u001b[0m(-0.00123)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 369/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 20:57:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.51 sec -- GLOBAL_STEP: 429770\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81602\n",
            "     | > avg_G_stft_loss_sc: 0.35890\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75413\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36749\n",
            "     | > avg_G_mse_fake_loss: 0.31800\n",
            "     | > avg_G_loss: 1.94328\n",
            "     | > avg_G_gen_loss: 1.14827\n",
            "     | > avg_G_adv_loss: 0.79501\n",
            "     | > avg_D_mse_gan_loss: 0.44563\n",
            "     | > avg_D_mse_gan_real_loss: 0.13806\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13751\n",
            "     | > avg_D_loss: 0.44563\n",
            "     | > avg_loader_time: 0.88204\n",
            "     | > avg_step_time: 0.62324\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78576 \u001b[0m(-0.00030)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36130 \u001b[0m(-0.00328)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70003 \u001b[0m(+0.00030)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37506 \u001b[0m(+0.00301)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.31705 \u001b[0m(+0.00236)\n",
            "     | > avg_G_loss:\u001b[91m 1.90370 \u001b[0m(+0.00576)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11108 \u001b[0m(-0.00014)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.79263 \u001b[0m(+0.00589)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44534 \u001b[0m(+0.00361)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.13937 \u001b[0m(+0.00175)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13022 \u001b[0m(+0.00063)\n",
            "     | > avg_D_loss:\u001b[91m 0.44534 \u001b[0m(+0.00361)\n",
            "     | > avg_loader_time:\u001b[92m 0.40899 \u001b[0m(-0.00040)\n",
            "     | > avg_step_time:\u001b[91m 0.05731 \u001b[0m(+0.00443)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 370/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:00:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.21 sec -- GLOBAL_STEP: 429891\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81318\n",
            "     | > avg_G_stft_loss_sc: 0.36154\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75111\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36963\n",
            "     | > avg_G_mse_fake_loss: 0.31450\n",
            "     | > avg_G_loss: 1.93399\n",
            "     | > avg_G_gen_loss: 1.14773\n",
            "     | > avg_G_adv_loss: 0.78626\n",
            "     | > avg_D_mse_gan_loss: 0.44718\n",
            "     | > avg_D_mse_gan_real_loss: 0.13880\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13814\n",
            "     | > avg_D_loss: 0.44718\n",
            "     | > avg_loader_time: 0.89035\n",
            "     | > avg_step_time: 0.63736\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78642 \u001b[0m(+0.00066)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36757 \u001b[0m(+0.00627)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70081 \u001b[0m(+0.00078)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38038 \u001b[0m(+0.00532)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32233 \u001b[0m(+0.00528)\n",
            "     | > avg_G_loss:\u001b[91m 1.92340 \u001b[0m(+0.01970)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11759 \u001b[0m(+0.00651)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.80582 \u001b[0m(+0.01319)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44540 \u001b[0m(+0.00006)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.14175 \u001b[0m(+0.00238)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12998 \u001b[0m(-0.00024)\n",
            "     | > avg_D_loss:\u001b[91m 0.44540 \u001b[0m(+0.00006)\n",
            "     | > avg_loader_time:\u001b[92m 0.40452 \u001b[0m(-0.00447)\n",
            "     | > avg_step_time:\u001b[92m 0.05219 \u001b[0m(-0.00512)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 371/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:03:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 108/120 -- GLOBAL_STEP: 430000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80969  (0.81671)\n",
            "     | > G_stft_loss_sc: 0.36923  (0.35842)\n",
            "     | > G_subband_stft_loss_mg: 0.74269  (0.75651)\n",
            "     | > G_subband_stft_loss_sc: 0.37496  (0.36682)\n",
            "     | > G_mse_fake_loss: 0.31860  (0.31557)\n",
            "     | > G_loss: 1.94479  (1.93814)\n",
            "     | > G_gen_loss: 1.14829  (1.14922)\n",
            "     | > G_adv_loss: 0.79650  (0.78892)\n",
            "     | > D_mse_gan_loss: 0.45221  (0.44616)\n",
            "     | > D_mse_gan_real_loss: 0.14008  (0.13854)\n",
            "     | > D_mse_gan_fake_loss: 0.13865  (0.13770)\n",
            "     | > D_loss: 0.45221  (0.44616)\n",
            "     | > step_time: 0.56\n",
            "     | > loader_time: 1.0965\n",
            "     | > current_lr_G: 5.74047341068753e-06\n",
            "     | > current_lr_D: 5.74047341068753e-06\n",
            " > CHECKPOINT : /mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure/output/multiband-melgan/checkpoint_430000.pth.tar\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.12 sec -- GLOBAL_STEP: 430012\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81638\n",
            "     | > avg_G_stft_loss_sc: 0.35833\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75603\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36685\n",
            "     | > avg_G_mse_fake_loss: 0.31544\n",
            "     | > avg_G_loss: 1.93738\n",
            "     | > avg_G_gen_loss: 1.14879\n",
            "     | > avg_G_adv_loss: 0.78859\n",
            "     | > avg_D_mse_gan_loss: 0.44608\n",
            "     | > avg_D_mse_gan_real_loss: 0.13849\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13778\n",
            "     | > avg_D_loss: 0.44608\n",
            "     | > avg_loader_time: 0.81315\n",
            "     | > avg_step_time: 0.62019\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78745 \u001b[0m(+0.00103)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36621 \u001b[0m(-0.00136)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70086 \u001b[0m(+0.00005)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37384 \u001b[0m(-0.00654)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.37463 \u001b[0m(+0.05230)\n",
            "     | > avg_G_loss:\u001b[91m 2.05074 \u001b[0m(+0.12734)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11418 \u001b[0m(-0.00341)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.93656 \u001b[0m(+0.13075)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45036 \u001b[0m(+0.00497)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15664 \u001b[0m(+0.01489)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11651 \u001b[0m(-0.01347)\n",
            "     | > avg_D_loss:\u001b[91m 0.45036 \u001b[0m(+0.00497)\n",
            "     | > avg_loader_time:\u001b[92m 0.37473 \u001b[0m(-0.02979)\n",
            "     | > avg_step_time:\u001b[92m 0.04950 \u001b[0m(-0.00269)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 372/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:06:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.80 sec -- GLOBAL_STEP: 430133\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81370\n",
            "     | > avg_G_stft_loss_sc: 0.36117\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75002\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36977\n",
            "     | > avg_G_mse_fake_loss: 0.31627\n",
            "     | > avg_G_loss: 1.93801\n",
            "     | > avg_G_gen_loss: 1.14733\n",
            "     | > avg_G_adv_loss: 0.79068\n",
            "     | > avg_D_mse_gan_loss: 0.44619\n",
            "     | > avg_D_mse_gan_real_loss: 0.13856\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13799\n",
            "     | > avg_D_loss: 0.44619\n",
            "     | > avg_loader_time: 0.84947\n",
            "     | > avg_step_time: 0.60053\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79015 \u001b[0m(+0.00270)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37933 \u001b[0m(+0.01312)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70236 \u001b[0m(+0.00150)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37574 \u001b[0m(+0.00190)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31207 \u001b[0m(-0.06255)\n",
            "     | > avg_G_loss:\u001b[92m 1.90397 \u001b[0m(-0.14677)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12380 \u001b[0m(+0.00962)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.78018 \u001b[0m(-0.15639)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44800 \u001b[0m(-0.00236)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13693 \u001b[0m(-0.01972)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13682 \u001b[0m(+0.02031)\n",
            "     | > avg_D_loss:\u001b[92m 0.44800 \u001b[0m(-0.00236)\n",
            "     | > avg_loader_time:\u001b[91m 0.39587 \u001b[0m(+0.02114)\n",
            "     | > avg_step_time:\u001b[91m 0.05222 \u001b[0m(+0.00272)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 373/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:09:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.33 sec -- GLOBAL_STEP: 430254\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81756\n",
            "     | > avg_G_stft_loss_sc: 0.35644\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75808\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36529\n",
            "     | > avg_G_mse_fake_loss: 0.31523\n",
            "     | > avg_G_loss: 1.93677\n",
            "     | > avg_G_gen_loss: 1.14868\n",
            "     | > avg_G_adv_loss: 0.78808\n",
            "     | > avg_D_mse_gan_loss: 0.44692\n",
            "     | > avg_D_mse_gan_real_loss: 0.13871\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13837\n",
            "     | > avg_D_loss: 0.44692\n",
            "     | > avg_loader_time: 0.85985\n",
            "     | > avg_step_time: 0.60561\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78933 \u001b[0m(-0.00082)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.37172 \u001b[0m(-0.00762)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70219 \u001b[0m(-0.00017)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37668 \u001b[0m(+0.00094)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36450 \u001b[0m(+0.05243)\n",
            "     | > avg_G_loss:\u001b[91m 2.03122 \u001b[0m(+0.12725)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11996 \u001b[0m(-0.00384)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91126 \u001b[0m(+0.13108)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44815 \u001b[0m(+0.00015)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15086 \u001b[0m(+0.01393)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12089 \u001b[0m(-0.01593)\n",
            "     | > avg_D_loss:\u001b[91m 0.44815 \u001b[0m(+0.00015)\n",
            "     | > avg_loader_time:\u001b[91m 0.40015 \u001b[0m(+0.00428)\n",
            "     | > avg_step_time:\u001b[92m 0.05130 \u001b[0m(-0.00091)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 374/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:13:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.21 sec -- GLOBAL_STEP: 430375\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81589\n",
            "     | > avg_G_stft_loss_sc: 0.35880\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75424\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36755\n",
            "     | > avg_G_mse_fake_loss: 0.31578\n",
            "     | > avg_G_loss: 1.93769\n",
            "     | > avg_G_gen_loss: 1.14824\n",
            "     | > avg_G_adv_loss: 0.78945\n",
            "     | > avg_D_mse_gan_loss: 0.44612\n",
            "     | > avg_D_mse_gan_real_loss: 0.13824\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13780\n",
            "     | > avg_D_loss: 0.44612\n",
            "     | > avg_loader_time: 0.85157\n",
            "     | > avg_step_time: 0.59535\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79016 \u001b[0m(+0.00083)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35971 \u001b[0m(-0.01200)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70206 \u001b[0m(-0.00013)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37052 \u001b[0m(-0.00616)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33123 \u001b[0m(-0.03328)\n",
            "     | > avg_G_loss:\u001b[92m 1.93929 \u001b[0m(-0.09193)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11122 \u001b[0m(-0.00873)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82806 \u001b[0m(-0.08320)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.43994 \u001b[0m(-0.00820)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14439 \u001b[0m(-0.00647)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12092 \u001b[0m(+0.00004)\n",
            "     | > avg_D_loss:\u001b[92m 0.43994 \u001b[0m(-0.00820)\n",
            "     | > avg_loader_time:\u001b[91m 0.43435 \u001b[0m(+0.03420)\n",
            "     | > avg_step_time:\u001b[91m 0.05413 \u001b[0m(+0.00282)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 375/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:16:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.60 sec -- GLOBAL_STEP: 430496\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80731\n",
            "     | > avg_G_stft_loss_sc: 0.36312\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74306\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37124\n",
            "     | > avg_G_mse_fake_loss: 0.31122\n",
            "     | > avg_G_loss: 1.92041\n",
            "     | > avg_G_gen_loss: 1.14237\n",
            "     | > avg_G_adv_loss: 0.77804\n",
            "     | > avg_D_mse_gan_loss: 0.44841\n",
            "     | > avg_D_mse_gan_real_loss: 0.13801\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13833\n",
            "     | > avg_D_loss: 0.44841\n",
            "     | > avg_loader_time: 0.85208\n",
            "     | > avg_step_time: 0.59878\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78912 \u001b[0m(-0.00103)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35879 \u001b[0m(-0.00092)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70194 \u001b[0m(-0.00011)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37131 \u001b[0m(+0.00079)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36761 \u001b[0m(+0.03639)\n",
            "     | > avg_G_loss:\u001b[91m 2.02961 \u001b[0m(+0.09032)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11058 \u001b[0m(-0.00064)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91903 \u001b[0m(+0.09096)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44277 \u001b[0m(+0.00282)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18300 \u001b[0m(+0.03861)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08761 \u001b[0m(-0.03332)\n",
            "     | > avg_D_loss:\u001b[91m 0.44277 \u001b[0m(+0.00282)\n",
            "     | > avg_loader_time:\u001b[92m 0.40105 \u001b[0m(-0.03331)\n",
            "     | > avg_step_time:\u001b[92m 0.05113 \u001b[0m(-0.00300)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 376/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:19:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.80 sec -- GLOBAL_STEP: 430617\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81359\n",
            "     | > avg_G_stft_loss_sc: 0.35768\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74913\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36681\n",
            "     | > avg_G_mse_fake_loss: 0.31863\n",
            "     | > avg_G_loss: 1.94018\n",
            "     | > avg_G_gen_loss: 1.14360\n",
            "     | > avg_G_adv_loss: 0.79657\n",
            "     | > avg_D_mse_gan_loss: 0.44610\n",
            "     | > avg_D_mse_gan_real_loss: 0.13844\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13821\n",
            "     | > avg_D_loss: 0.44610\n",
            "     | > avg_loader_time: 0.84834\n",
            "     | > avg_step_time: 0.60932\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78973 \u001b[0m(+0.00061)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36900 \u001b[0m(+0.01021)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70462 \u001b[0m(+0.00268)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38598 \u001b[0m(+0.01467)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32516 \u001b[0m(-0.04245)\n",
            "     | > avg_G_loss:\u001b[92m 1.93756 \u001b[0m(-0.09205)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12466 \u001b[0m(+0.01408)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81290 \u001b[0m(-0.10613)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44483 \u001b[0m(+0.00206)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15577 \u001b[0m(-0.02723)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11974 \u001b[0m(+0.03213)\n",
            "     | > avg_D_loss:\u001b[91m 0.44483 \u001b[0m(+0.00206)\n",
            "     | > avg_loader_time:\u001b[92m 0.39874 \u001b[0m(-0.00231)\n",
            "     | > avg_step_time:\u001b[92m 0.04989 \u001b[0m(-0.00124)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 377/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:22:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.78 sec -- GLOBAL_STEP: 430738\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82093\n",
            "     | > avg_G_stft_loss_sc: 0.36066\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76253\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36935\n",
            "     | > avg_G_mse_fake_loss: 0.31885\n",
            "     | > avg_G_loss: 1.95386\n",
            "     | > avg_G_gen_loss: 1.15673\n",
            "     | > avg_G_adv_loss: 0.79713\n",
            "     | > avg_D_mse_gan_loss: 0.44445\n",
            "     | > avg_D_mse_gan_real_loss: 0.13764\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13761\n",
            "     | > avg_D_loss: 0.44445\n",
            "     | > avg_loader_time: 0.87037\n",
            "     | > avg_step_time: 0.62561\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78520 \u001b[0m(-0.00453)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36235 \u001b[0m(-0.00665)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69879 \u001b[0m(-0.00583)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36989 \u001b[0m(-0.01609)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.40854 \u001b[0m(+0.08338)\n",
            "     | > avg_G_loss:\u001b[91m 2.12947 \u001b[0m(+0.19191)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10811 \u001b[0m(-0.01655)\n",
            "     | > avg_G_adv_loss:\u001b[91m 1.02136 \u001b[0m(+0.20845)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45834 \u001b[0m(+0.01351)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17527 \u001b[0m(+0.01950)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10080 \u001b[0m(-0.01894)\n",
            "     | > avg_D_loss:\u001b[91m 0.45834 \u001b[0m(+0.01351)\n",
            "     | > avg_loader_time:\u001b[91m 0.47715 \u001b[0m(+0.07841)\n",
            "     | > avg_step_time:\u001b[91m 0.05874 \u001b[0m(+0.00885)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 378/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:25:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.65 sec -- GLOBAL_STEP: 430859\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81478\n",
            "     | > avg_G_stft_loss_sc: 0.35809\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75462\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36681\n",
            "     | > avg_G_mse_fake_loss: 0.31515\n",
            "     | > avg_G_loss: 1.93501\n",
            "     | > avg_G_gen_loss: 1.14715\n",
            "     | > avg_G_adv_loss: 0.78786\n",
            "     | > avg_D_mse_gan_loss: 0.44634\n",
            "     | > avg_D_mse_gan_real_loss: 0.13843\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13791\n",
            "     | > avg_D_loss: 0.44634\n",
            "     | > avg_loader_time: 0.87883\n",
            "     | > avg_step_time: 0.63206\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78540 \u001b[0m(+0.00020)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36088 \u001b[0m(-0.00147)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.69956 \u001b[0m(+0.00077)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37626 \u001b[0m(+0.00637)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34582 \u001b[0m(-0.06272)\n",
            "     | > avg_G_loss:\u001b[92m 1.97561 \u001b[0m(-0.15386)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11105 \u001b[0m(+0.00293)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.86456 \u001b[0m(-0.15680)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44315 \u001b[0m(-0.01519)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15829 \u001b[0m(-0.01698)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10825 \u001b[0m(+0.00745)\n",
            "     | > avg_D_loss:\u001b[92m 0.44315 \u001b[0m(-0.01519)\n",
            "     | > avg_loader_time:\u001b[92m 0.42347 \u001b[0m(-0.05368)\n",
            "     | > avg_step_time:\u001b[92m 0.05053 \u001b[0m(-0.00821)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 379/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:28:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.54 sec -- GLOBAL_STEP: 430980\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81700\n",
            "     | > avg_G_stft_loss_sc: 0.35672\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75872\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36504\n",
            "     | > avg_G_mse_fake_loss: 0.31446\n",
            "     | > avg_G_loss: 1.93490\n",
            "     | > avg_G_gen_loss: 1.14874\n",
            "     | > avg_G_adv_loss: 0.78616\n",
            "     | > avg_D_mse_gan_loss: 0.44697\n",
            "     | > avg_D_mse_gan_real_loss: 0.13844\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13829\n",
            "     | > avg_D_loss: 0.44697\n",
            "     | > avg_loader_time: 0.84999\n",
            "     | > avg_step_time: 0.59815\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78698 \u001b[0m(+0.00158)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36669 \u001b[0m(+0.00581)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70100 \u001b[0m(+0.00144)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38253 \u001b[0m(+0.00627)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32441 \u001b[0m(-0.02142)\n",
            "     | > avg_G_loss:\u001b[92m 1.92962 \u001b[0m(-0.04599)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11860 \u001b[0m(+0.00755)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81102 \u001b[0m(-0.05354)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.43994 \u001b[0m(-0.00321)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13016 \u001b[0m(-0.02813)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13474 \u001b[0m(+0.02649)\n",
            "     | > avg_D_loss:\u001b[92m 0.43994 \u001b[0m(-0.00321)\n",
            "     | > avg_loader_time:\u001b[92m 0.40707 \u001b[0m(-0.01640)\n",
            "     | > avg_step_time:\u001b[91m 0.05308 \u001b[0m(+0.00254)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 380/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:31:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 19/120 -- GLOBAL_STEP: 431000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81968  (0.81504)\n",
            "     | > G_stft_loss_sc: 0.35347  (0.36048)\n",
            "     | > G_subband_stft_loss_mg: 0.76395  (0.75335)\n",
            "     | > G_subband_stft_loss_sc: 0.36663  (0.36940)\n",
            "     | > G_mse_fake_loss: 0.29518  (0.31530)\n",
            "     | > G_loss: 1.88981  (1.93739)\n",
            "     | > G_gen_loss: 1.15187  (1.14914)\n",
            "     | > G_adv_loss: 0.73794  (0.78825)\n",
            "     | > D_mse_gan_loss: 0.44384  (0.44748)\n",
            "     | > D_mse_gan_real_loss: 0.10896  (0.13772)\n",
            "     | > D_mse_gan_fake_loss: 0.16742  (0.13908)\n",
            "     | > D_loss: 0.44384  (0.44748)\n",
            "     | > step_time: 0.75\n",
            "     | > loader_time: 0.0070\n",
            "     | > current_lr_G: 5.689015325556938e-06\n",
            "     | > current_lr_D: 5.689015325556938e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.27 sec -- GLOBAL_STEP: 431101\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81455\n",
            "     | > avg_G_stft_loss_sc: 0.35897\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75297\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36785\n",
            "     | > avg_G_mse_fake_loss: 0.31533\n",
            "     | > avg_G_loss: 1.93549\n",
            "     | > avg_G_gen_loss: 1.14717\n",
            "     | > avg_G_adv_loss: 0.78833\n",
            "     | > avg_D_mse_gan_loss: 0.44727\n",
            "     | > avg_D_mse_gan_real_loss: 0.13894\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13820\n",
            "     | > avg_D_loss: 0.44727\n",
            "     | > avg_loader_time: 0.85084\n",
            "     | > avg_step_time: 0.59658\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78858 \u001b[0m(+0.00159)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37644 \u001b[0m(+0.00976)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70404 \u001b[0m(+0.00304)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38937 \u001b[0m(+0.00685)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32687 \u001b[0m(+0.00247)\n",
            "     | > avg_G_loss:\u001b[91m 1.94640 \u001b[0m(+0.01678)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12922 \u001b[0m(+0.01062)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.81718 \u001b[0m(+0.00617)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44387 \u001b[0m(+0.00393)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.13763 \u001b[0m(+0.00747)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.13100 \u001b[0m(-0.00373)\n",
            "     | > avg_D_loss:\u001b[91m 0.44387 \u001b[0m(+0.00393)\n",
            "     | > avg_loader_time:\u001b[91m 0.47072 \u001b[0m(+0.06364)\n",
            "     | > avg_step_time:\u001b[91m 0.05622 \u001b[0m(+0.00315)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 381/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:34:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.67 sec -- GLOBAL_STEP: 431222\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81690\n",
            "     | > avg_G_stft_loss_sc: 0.35937\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75704\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36789\n",
            "     | > avg_G_mse_fake_loss: 0.31538\n",
            "     | > avg_G_loss: 1.93905\n",
            "     | > avg_G_gen_loss: 1.15060\n",
            "     | > avg_G_adv_loss: 0.78845\n",
            "     | > avg_D_mse_gan_loss: 0.44630\n",
            "     | > avg_D_mse_gan_real_loss: 0.13844\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13776\n",
            "     | > avg_D_loss: 0.44630\n",
            "     | > avg_loader_time: 0.82709\n",
            "     | > avg_step_time: 0.58296\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78844 \u001b[0m(-0.00014)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36154 \u001b[0m(-0.01490)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70061 \u001b[0m(-0.00343)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37268 \u001b[0m(-0.01669)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32787 \u001b[0m(+0.00099)\n",
            "     | > avg_G_loss:\u001b[92m 1.93130 \u001b[0m(-0.01510)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11164 \u001b[0m(-0.01758)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.81967 \u001b[0m(+0.00248)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44449 \u001b[0m(+0.00062)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13089 \u001b[0m(-0.00674)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13386 \u001b[0m(+0.00285)\n",
            "     | > avg_D_loss:\u001b[91m 0.44449 \u001b[0m(+0.00062)\n",
            "     | > avg_loader_time:\u001b[92m 0.42609 \u001b[0m(-0.04463)\n",
            "     | > avg_step_time:\u001b[92m 0.05287 \u001b[0m(-0.00335)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 382/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:37:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 72.32 sec -- GLOBAL_STEP: 431343\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82127\n",
            "     | > avg_G_stft_loss_sc: 0.35810\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76231\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36688\n",
            "     | > avg_G_mse_fake_loss: 0.31989\n",
            "     | > avg_G_loss: 1.95400\n",
            "     | > avg_G_gen_loss: 1.15428\n",
            "     | > avg_G_adv_loss: 0.79971\n",
            "     | > avg_D_mse_gan_loss: 0.44461\n",
            "     | > avg_D_mse_gan_real_loss: 0.13779\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13733\n",
            "     | > avg_D_loss: 0.44461\n",
            "     | > avg_loader_time: 0.84549\n",
            "     | > avg_step_time: 0.59666\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78748 \u001b[0m(-0.00096)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35913 \u001b[0m(-0.00241)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70050 \u001b[0m(-0.00011)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37263 \u001b[0m(-0.00005)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38932 \u001b[0m(+0.06145)\n",
            "     | > avg_G_loss:\u001b[91m 2.08316 \u001b[0m(+0.15186)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10987 \u001b[0m(-0.00176)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.97329 \u001b[0m(+0.15363)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44808 \u001b[0m(+0.00359)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17001 \u001b[0m(+0.03912)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09998 \u001b[0m(-0.03387)\n",
            "     | > avg_D_loss:\u001b[91m 0.44808 \u001b[0m(+0.00359)\n",
            "     | > avg_loader_time:\u001b[91m 0.42891 \u001b[0m(+0.00282)\n",
            "     | > avg_step_time:\u001b[92m 0.04920 \u001b[0m(-0.00367)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 383/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:41:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.04 sec -- GLOBAL_STEP: 431464\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81916\n",
            "     | > avg_G_stft_loss_sc: 0.35819\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76020\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36687\n",
            "     | > avg_G_mse_fake_loss: 0.31759\n",
            "     | > avg_G_loss: 1.94617\n",
            "     | > avg_G_gen_loss: 1.15221\n",
            "     | > avg_G_adv_loss: 0.79396\n",
            "     | > avg_D_mse_gan_loss: 0.44563\n",
            "     | > avg_D_mse_gan_real_loss: 0.13804\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13745\n",
            "     | > avg_D_loss: 0.44563\n",
            "     | > avg_loader_time: 0.83863\n",
            "     | > avg_step_time: 0.58649\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78533 \u001b[0m(-0.00215)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35746 \u001b[0m(-0.00167)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69865 \u001b[0m(-0.00185)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36840 \u001b[0m(-0.00423)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29711 \u001b[0m(-0.09221)\n",
            "     | > avg_G_loss:\u001b[92m 1.84770 \u001b[0m(-0.23546)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10492 \u001b[0m(-0.00495)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74278 \u001b[0m(-0.23051)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44282 \u001b[0m(-0.00526)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12335 \u001b[0m(-0.04667)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14447 \u001b[0m(+0.04448)\n",
            "     | > avg_D_loss:\u001b[92m 0.44282 \u001b[0m(-0.00526)\n",
            "     | > avg_loader_time:\u001b[92m 0.39752 \u001b[0m(-0.03139)\n",
            "     | > avg_step_time:\u001b[92m 0.04854 \u001b[0m(-0.00066)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 384/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:44:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.86 sec -- GLOBAL_STEP: 431585\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81372\n",
            "     | > avg_G_stft_loss_sc: 0.35953\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75166\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36843\n",
            "     | > avg_G_mse_fake_loss: 0.31563\n",
            "     | > avg_G_loss: 1.93576\n",
            "     | > avg_G_gen_loss: 1.14667\n",
            "     | > avg_G_adv_loss: 0.78909\n",
            "     | > avg_D_mse_gan_loss: 0.44608\n",
            "     | > avg_D_mse_gan_real_loss: 0.13823\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13769\n",
            "     | > avg_D_loss: 0.44608\n",
            "     | > avg_loader_time: 0.82425\n",
            "     | > avg_step_time: 0.58500\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78610 \u001b[0m(+0.00077)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36147 \u001b[0m(+0.00401)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70010 \u001b[0m(+0.00144)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37698 \u001b[0m(+0.00858)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35960 \u001b[0m(+0.06249)\n",
            "     | > avg_G_loss:\u001b[91m 2.01133 \u001b[0m(+0.16363)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11232 \u001b[0m(+0.00740)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89900 \u001b[0m(+0.15622)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44112 \u001b[0m(-0.00170)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18135 \u001b[0m(+0.05800)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09003 \u001b[0m(-0.05444)\n",
            "     | > avg_D_loss:\u001b[92m 0.44112 \u001b[0m(-0.00170)\n",
            "     | > avg_loader_time:\u001b[91m 0.43432 \u001b[0m(+0.03680)\n",
            "     | > avg_step_time:\u001b[91m 0.05517 \u001b[0m(+0.00663)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 385/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:47:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.97 sec -- GLOBAL_STEP: 431706\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81522\n",
            "     | > avg_G_stft_loss_sc: 0.36128\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75453\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36962\n",
            "     | > avg_G_mse_fake_loss: 0.31481\n",
            "     | > avg_G_loss: 1.93734\n",
            "     | > avg_G_gen_loss: 1.15033\n",
            "     | > avg_G_adv_loss: 0.78702\n",
            "     | > avg_D_mse_gan_loss: 0.44679\n",
            "     | > avg_D_mse_gan_real_loss: 0.13812\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13758\n",
            "     | > avg_D_loss: 0.44679\n",
            "     | > avg_loader_time: 0.82513\n",
            "     | > avg_step_time: 0.57751\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78916 \u001b[0m(+0.00306)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36242 \u001b[0m(+0.00095)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70203 \u001b[0m(+0.00193)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37203 \u001b[0m(-0.00496)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35938 \u001b[0m(-0.00022)\n",
            "     | > avg_G_loss:\u001b[92m 2.01127 \u001b[0m(-0.00005)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11282 \u001b[0m(+0.00049)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.89846 \u001b[0m(-0.00055)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44168 \u001b[0m(+0.00056)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15666 \u001b[0m(-0.02469)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10785 \u001b[0m(+0.01782)\n",
            "     | > avg_D_loss:\u001b[91m 0.44168 \u001b[0m(+0.00056)\n",
            "     | > avg_loader_time:\u001b[92m 0.38427 \u001b[0m(-0.05005)\n",
            "     | > avg_step_time:\u001b[92m 0.04937 \u001b[0m(-0.00581)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 386/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:50:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.88 sec -- GLOBAL_STEP: 431827\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81992\n",
            "     | > avg_G_stft_loss_sc: 0.35777\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76182\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36631\n",
            "     | > avg_G_mse_fake_loss: 0.31723\n",
            "     | > avg_G_loss: 1.94599\n",
            "     | > avg_G_gen_loss: 1.15291\n",
            "     | > avg_G_adv_loss: 0.79307\n",
            "     | > avg_D_mse_gan_loss: 0.44519\n",
            "     | > avg_D_mse_gan_real_loss: 0.13758\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13751\n",
            "     | > avg_D_loss: 0.44519\n",
            "     | > avg_loader_time: 0.81651\n",
            "     | > avg_step_time: 0.58549\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78794 \u001b[0m(-0.00123)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35940 \u001b[0m(-0.00301)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70174 \u001b[0m(-0.00029)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36801 \u001b[0m(-0.00401)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35369 \u001b[0m(-0.00569)\n",
            "     | > avg_G_loss:\u001b[92m 1.99277 \u001b[0m(-0.01850)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10855 \u001b[0m(-0.00427)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88423 \u001b[0m(-0.01423)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44282 \u001b[0m(+0.00114)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15584 \u001b[0m(-0.00082)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10918 \u001b[0m(+0.00133)\n",
            "     | > avg_D_loss:\u001b[91m 0.44282 \u001b[0m(+0.00114)\n",
            "     | > avg_loader_time:\u001b[91m 0.45814 \u001b[0m(+0.07388)\n",
            "     | > avg_step_time:\u001b[91m 0.05164 \u001b[0m(+0.00227)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 387/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:53:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.61 sec -- GLOBAL_STEP: 431948\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81670\n",
            "     | > avg_G_stft_loss_sc: 0.35699\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75677\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36561\n",
            "     | > avg_G_mse_fake_loss: 0.31559\n",
            "     | > avg_G_loss: 1.93701\n",
            "     | > avg_G_gen_loss: 1.14803\n",
            "     | > avg_G_adv_loss: 0.78897\n",
            "     | > avg_D_mse_gan_loss: 0.44621\n",
            "     | > avg_D_mse_gan_real_loss: 0.13839\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13785\n",
            "     | > avg_D_loss: 0.44621\n",
            "     | > avg_loader_time: 0.82723\n",
            "     | > avg_step_time: 0.58258\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78835 \u001b[0m(+0.00041)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36850 \u001b[0m(+0.00910)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70138 \u001b[0m(-0.00036)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38501 \u001b[0m(+0.01700)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33119 \u001b[0m(-0.02250)\n",
            "     | > avg_G_loss:\u001b[92m 1.94959 \u001b[0m(-0.04318)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12162 \u001b[0m(+0.01308)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82797 \u001b[0m(-0.05626)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44397 \u001b[0m(+0.00115)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13743 \u001b[0m(-0.01842)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13112 \u001b[0m(+0.02194)\n",
            "     | > avg_D_loss:\u001b[91m 0.44397 \u001b[0m(+0.00115)\n",
            "     | > avg_loader_time:\u001b[92m 0.37526 \u001b[0m(-0.08288)\n",
            "     | > avg_step_time:\u001b[92m 0.04826 \u001b[0m(-0.00338)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 388/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:56:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 51/120 -- GLOBAL_STEP: 432000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81073  (0.81376)\n",
            "     | > G_stft_loss_sc: 0.35727  (0.35914)\n",
            "     | > G_subband_stft_loss_mg: 0.75047  (0.75257)\n",
            "     | > G_subband_stft_loss_sc: 0.36331  (0.36753)\n",
            "     | > G_mse_fake_loss: 0.31016  (0.31553)\n",
            "     | > G_loss: 1.91630  (1.93531)\n",
            "     | > G_gen_loss: 1.14089  (1.14650)\n",
            "     | > G_adv_loss: 0.77541  (0.78881)\n",
            "     | > D_mse_gan_loss: 0.44749  (0.44615)\n",
            "     | > D_mse_gan_real_loss: 0.13770  (0.13840)\n",
            "     | > D_mse_gan_fake_loss: 0.14037  (0.13763)\n",
            "     | > D_loss: 0.44749  (0.44615)\n",
            "     | > step_time: 0.63\n",
            "     | > loader_time: 0.0073\n",
            "     | > current_lr_G: 5.643662177194653e-06\n",
            "     | > current_lr_D: 5.643662177194653e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.59 sec -- GLOBAL_STEP: 432069\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81445\n",
            "     | > avg_G_stft_loss_sc: 0.35871\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75366\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36726\n",
            "     | > avg_G_mse_fake_loss: 0.31559\n",
            "     | > avg_G_loss: 1.93603\n",
            "     | > avg_G_gen_loss: 1.14704\n",
            "     | > avg_G_adv_loss: 0.78899\n",
            "     | > avg_D_mse_gan_loss: 0.44602\n",
            "     | > avg_D_mse_gan_real_loss: 0.13825\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13780\n",
            "     | > avg_D_loss: 0.44602\n",
            "     | > avg_loader_time: 0.82775\n",
            "     | > avg_step_time: 0.57418\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78570 \u001b[0m(-0.00265)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35819 \u001b[0m(-0.01031)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69935 \u001b[0m(-0.00203)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36870 \u001b[0m(-0.01631)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35306 \u001b[0m(+0.02187)\n",
            "     | > avg_G_loss:\u001b[91m 1.98863 \u001b[0m(+0.03903)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10597 \u001b[0m(-0.01565)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88265 \u001b[0m(+0.05468)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44505 \u001b[0m(+0.00108)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15492 \u001b[0m(+0.01749)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11602 \u001b[0m(-0.01510)\n",
            "     | > avg_D_loss:\u001b[91m 0.44505 \u001b[0m(+0.00108)\n",
            "     | > avg_loader_time:\u001b[91m 0.40262 \u001b[0m(+0.02736)\n",
            "     | > avg_step_time:\u001b[91m 0.04897 \u001b[0m(+0.00071)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 389/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 21:59:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.55 sec -- GLOBAL_STEP: 432190\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80823\n",
            "     | > avg_G_stft_loss_sc: 0.35920\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73795\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36865\n",
            "     | > avg_G_mse_fake_loss: 0.32015\n",
            "     | > avg_G_loss: 1.93739\n",
            "     | > avg_G_gen_loss: 1.13702\n",
            "     | > avg_G_adv_loss: 0.80037\n",
            "     | > avg_D_mse_gan_loss: 0.44537\n",
            "     | > avg_D_mse_gan_real_loss: 0.13780\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13738\n",
            "     | > avg_D_loss: 0.44537\n",
            "     | > avg_loader_time: 0.81576\n",
            "     | > avg_step_time: 0.56551\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78639 \u001b[0m(+0.00069)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36192 \u001b[0m(+0.00373)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.69947 \u001b[0m(+0.00012)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.36927 \u001b[0m(+0.00057)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36997 \u001b[0m(+0.01691)\n",
            "     | > avg_G_loss:\u001b[91m 2.03345 \u001b[0m(+0.04482)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10853 \u001b[0m(+0.00256)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.92492 \u001b[0m(+0.04227)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44580 \u001b[0m(+0.00074)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16945 \u001b[0m(+0.01453)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10224 \u001b[0m(-0.01378)\n",
            "     | > avg_D_loss:\u001b[91m 0.44580 \u001b[0m(+0.00074)\n",
            "     | > avg_loader_time:\u001b[91m 0.41684 \u001b[0m(+0.01421)\n",
            "     | > avg_step_time:\u001b[91m 0.04981 \u001b[0m(+0.00083)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 390/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:01:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.71 sec -- GLOBAL_STEP: 432311\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81779\n",
            "     | > avg_G_stft_loss_sc: 0.36194\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75752\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37078\n",
            "     | > avg_G_mse_fake_loss: 0.31820\n",
            "     | > avg_G_loss: 1.94952\n",
            "     | > avg_G_gen_loss: 1.15402\n",
            "     | > avg_G_adv_loss: 0.79550\n",
            "     | > avg_D_mse_gan_loss: 0.44510\n",
            "     | > avg_D_mse_gan_real_loss: 0.13836\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13738\n",
            "     | > avg_D_loss: 0.44510\n",
            "     | > avg_loader_time: 0.82430\n",
            "     | > avg_step_time: 0.58339\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78883 \u001b[0m(+0.00244)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37596 \u001b[0m(+0.01404)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70172 \u001b[0m(+0.00225)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37547 \u001b[0m(+0.00619)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33659 \u001b[0m(-0.03337)\n",
            "     | > avg_G_loss:\u001b[92m 1.96247 \u001b[0m(-0.07097)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12099 \u001b[0m(+0.01246)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84149 \u001b[0m(-0.08343)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44757 \u001b[0m(+0.00177)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14459 \u001b[0m(-0.02485)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12599 \u001b[0m(+0.02374)\n",
            "     | > avg_D_loss:\u001b[91m 0.44757 \u001b[0m(+0.00177)\n",
            "     | > avg_loader_time:\u001b[92m 0.38880 \u001b[0m(-0.02803)\n",
            "     | > avg_step_time:\u001b[92m 0.04683 \u001b[0m(-0.00298)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 391/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:04:56) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.91 sec -- GLOBAL_STEP: 432432\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82269\n",
            "     | > avg_G_stft_loss_sc: 0.35735\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76392\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36658\n",
            "     | > avg_G_mse_fake_loss: 0.32159\n",
            "     | > avg_G_loss: 1.95926\n",
            "     | > avg_G_gen_loss: 1.15527\n",
            "     | > avg_G_adv_loss: 0.80399\n",
            "     | > avg_D_mse_gan_loss: 0.44374\n",
            "     | > avg_D_mse_gan_real_loss: 0.13793\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13756\n",
            "     | > avg_D_loss: 0.44374\n",
            "     | > avg_loader_time: 0.81684\n",
            "     | > avg_step_time: 0.56860\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78899 \u001b[0m(+0.00016)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37850 \u001b[0m(+0.00253)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70301 \u001b[0m(+0.00129)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39537 \u001b[0m(+0.01991)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36280 \u001b[0m(+0.02621)\n",
            "     | > avg_G_loss:\u001b[91m 2.03993 \u001b[0m(+0.07746)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13293 \u001b[0m(+0.01195)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90700 \u001b[0m(+0.06551)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44550 \u001b[0m(-0.00207)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15932 \u001b[0m(+0.01473)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11140 \u001b[0m(-0.01459)\n",
            "     | > avg_D_loss:\u001b[92m 0.44550 \u001b[0m(-0.00207)\n",
            "     | > avg_loader_time:\u001b[91m 0.42939 \u001b[0m(+0.04059)\n",
            "     | > avg_step_time:\u001b[91m 0.04949 \u001b[0m(+0.00266)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 392/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:07:54) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 74.08 sec -- GLOBAL_STEP: 432553\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80869\n",
            "     | > avg_G_stft_loss_sc: 0.35987\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73923\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36851\n",
            "     | > avg_G_mse_fake_loss: 0.31743\n",
            "     | > avg_G_loss: 1.93173\n",
            "     | > avg_G_gen_loss: 1.13815\n",
            "     | > avg_G_adv_loss: 0.79358\n",
            "     | > avg_D_mse_gan_loss: 0.44693\n",
            "     | > avg_D_mse_gan_real_loss: 0.13867\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13867\n",
            "     | > avg_D_loss: 0.44693\n",
            "     | > avg_loader_time: 0.85067\n",
            "     | > avg_step_time: 0.61003\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78765 \u001b[0m(-0.00134)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.37396 \u001b[0m(-0.00454)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70291 \u001b[0m(-0.00010)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.39263 \u001b[0m(-0.00274)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.39213 \u001b[0m(+0.02932)\n",
            "     | > avg_G_loss:\u001b[91m 2.10889 \u001b[0m(+0.06895)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.12857 \u001b[0m(-0.00436)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.98031 \u001b[0m(+0.07331)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45300 \u001b[0m(+0.00750)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.19134 \u001b[0m(+0.03202)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.08890 \u001b[0m(-0.02250)\n",
            "     | > avg_D_loss:\u001b[91m 0.45300 \u001b[0m(+0.00750)\n",
            "     | > avg_loader_time:\u001b[92m 0.42938 \u001b[0m(-0.00001)\n",
            "     | > avg_step_time:\u001b[91m 0.05217 \u001b[0m(+0.00268)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 393/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:11:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.35 sec -- GLOBAL_STEP: 432674\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80992\n",
            "     | > avg_G_stft_loss_sc: 0.36231\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74723\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37037\n",
            "     | > avg_G_mse_fake_loss: 0.31225\n",
            "     | > avg_G_loss: 1.92553\n",
            "     | > avg_G_gen_loss: 1.14492\n",
            "     | > avg_G_adv_loss: 0.78062\n",
            "     | > avg_D_mse_gan_loss: 0.44844\n",
            "     | > avg_D_mse_gan_real_loss: 0.13907\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13838\n",
            "     | > avg_D_loss: 0.44844\n",
            "     | > avg_loader_time: 0.87032\n",
            "     | > avg_step_time: 0.62192\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78470 \u001b[0m(-0.00296)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36035 \u001b[0m(-0.01361)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69923 \u001b[0m(-0.00367)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37474 \u001b[0m(-0.01790)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32937 \u001b[0m(-0.06275)\n",
            "     | > avg_G_loss:\u001b[92m 1.93294 \u001b[0m(-0.17595)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10951 \u001b[0m(-0.01907)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82343 \u001b[0m(-0.15688)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44069 \u001b[0m(-0.01230)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13749 \u001b[0m(-0.05385)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12770 \u001b[0m(+0.03880)\n",
            "     | > avg_D_loss:\u001b[92m 0.44069 \u001b[0m(-0.01230)\n",
            "     | > avg_loader_time:\u001b[92m 0.40956 \u001b[0m(-0.01981)\n",
            "     | > avg_step_time:\u001b[92m 0.05142 \u001b[0m(-0.00075)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 394/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:14:11) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.76 sec -- GLOBAL_STEP: 432795\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81806\n",
            "     | > avg_G_stft_loss_sc: 0.36003\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75749\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36882\n",
            "     | > avg_G_mse_fake_loss: 0.31917\n",
            "     | > avg_G_loss: 1.95011\n",
            "     | > avg_G_gen_loss: 1.15219\n",
            "     | > avg_G_adv_loss: 0.79792\n",
            "     | > avg_D_mse_gan_loss: 0.44525\n",
            "     | > avg_D_mse_gan_real_loss: 0.13831\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13744\n",
            "     | > avg_D_loss: 0.44525\n",
            "     | > avg_loader_time: 0.88179\n",
            "     | > avg_step_time: 0.64266\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78851 \u001b[0m(+0.00381)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35809 \u001b[0m(-0.00226)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70254 \u001b[0m(+0.00330)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37478 \u001b[0m(+0.00004)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32795 \u001b[0m(-0.00142)\n",
            "     | > avg_G_loss:\u001b[92m 1.93183 \u001b[0m(-0.00111)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11196 \u001b[0m(+0.00245)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81987 \u001b[0m(-0.00356)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44223 \u001b[0m(+0.00153)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15993 \u001b[0m(+0.02243)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10827 \u001b[0m(-0.01943)\n",
            "     | > avg_D_loss:\u001b[91m 0.44223 \u001b[0m(+0.00153)\n",
            "     | > avg_loader_time:\u001b[91m 0.41775 \u001b[0m(+0.00819)\n",
            "     | > avg_step_time:\u001b[91m 0.05291 \u001b[0m(+0.00149)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 395/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:17:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.15 sec -- GLOBAL_STEP: 432916\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80572\n",
            "     | > avg_G_stft_loss_sc: 0.36122\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73987\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36976\n",
            "     | > avg_G_mse_fake_loss: 0.31191\n",
            "     | > avg_G_loss: 1.91806\n",
            "     | > avg_G_gen_loss: 1.13829\n",
            "     | > avg_G_adv_loss: 0.77977\n",
            "     | > avg_D_mse_gan_loss: 0.44796\n",
            "     | > avg_D_mse_gan_real_loss: 0.13870\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13807\n",
            "     | > avg_D_loss: 0.44796\n",
            "     | > avg_loader_time: 0.86810\n",
            "     | > avg_step_time: 0.61994\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78807 \u001b[0m(-0.00043)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36064 \u001b[0m(+0.00255)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70094 \u001b[0m(-0.00160)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36419 \u001b[0m(-0.01059)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34831 \u001b[0m(+0.02036)\n",
            "     | > avg_G_loss:\u001b[91m 1.97770 \u001b[0m(+0.04587)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10692 \u001b[0m(-0.00504)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.87078 \u001b[0m(+0.05091)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44222 \u001b[0m(-0.00001)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16387 \u001b[0m(+0.00395)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10601 \u001b[0m(-0.00226)\n",
            "     | > avg_D_loss:\u001b[92m 0.44222 \u001b[0m(-0.00001)\n",
            "     | > avg_loader_time:\u001b[92m 0.40931 \u001b[0m(-0.00844)\n",
            "     | > avg_step_time:\u001b[91m 0.05448 \u001b[0m(+0.00157)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 396/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:20:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 83/120 -- GLOBAL_STEP: 433000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.82059  (0.81471)\n",
            "     | > G_stft_loss_sc: 0.34925  (0.35812)\n",
            "     | > G_subband_stft_loss_mg: 0.75859  (0.75310)\n",
            "     | > G_subband_stft_loss_sc: 0.35999  (0.36686)\n",
            "     | > G_mse_fake_loss: 0.30995  (0.31724)\n",
            "     | > G_loss: 1.91909  (1.93950)\n",
            "     | > G_gen_loss: 1.14421  (1.14640)\n",
            "     | > G_adv_loss: 0.77488  (0.79311)\n",
            "     | > D_mse_gan_loss: 0.44190  (0.44599)\n",
            "     | > D_mse_gan_real_loss: 0.13020  (0.13805)\n",
            "     | > D_mse_gan_fake_loss: 0.14510  (0.13753)\n",
            "     | > D_loss: 0.44190  (0.44599)\n",
            "     | > step_time: 0.65\n",
            "     | > loader_time: 0.0064\n",
            "     | > current_lr_G: 5.598670586667716e-06\n",
            "     | > current_lr_D: 5.598670586667716e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 73.55 sec -- GLOBAL_STEP: 433037\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81438\n",
            "     | > avg_G_stft_loss_sc: 0.35781\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75296\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36672\n",
            "     | > avg_G_mse_fake_loss: 0.31680\n",
            "     | > avg_G_loss: 1.93794\n",
            "     | > avg_G_gen_loss: 1.14593\n",
            "     | > avg_G_adv_loss: 0.79201\n",
            "     | > avg_D_mse_gan_loss: 0.44635\n",
            "     | > avg_D_mse_gan_real_loss: 0.13838\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13753\n",
            "     | > avg_D_loss: 0.44635\n",
            "     | > avg_loader_time: 0.84510\n",
            "     | > avg_step_time: 0.60717\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78891 \u001b[0m(+0.00084)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36410 \u001b[0m(+0.00346)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70148 \u001b[0m(+0.00055)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37654 \u001b[0m(+0.01236)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33915 \u001b[0m(-0.00916)\n",
            "     | > avg_G_loss:\u001b[92m 1.96340 \u001b[0m(-0.01430)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11552 \u001b[0m(+0.00860)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84788 \u001b[0m(-0.02290)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44584 \u001b[0m(+0.00362)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13638 \u001b[0m(-0.02749)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13149 \u001b[0m(+0.02548)\n",
            "     | > avg_D_loss:\u001b[91m 0.44584 \u001b[0m(+0.00362)\n",
            "     | > avg_loader_time:\u001b[92m 0.40311 \u001b[0m(-0.00620)\n",
            "     | > avg_step_time:\u001b[92m 0.05305 \u001b[0m(-0.00142)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 397/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:23:41) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 78.02 sec -- GLOBAL_STEP: 433158\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81658\n",
            "     | > avg_G_stft_loss_sc: 0.35927\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75709\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36781\n",
            "     | > avg_G_mse_fake_loss: 0.31474\n",
            "     | > avg_G_loss: 1.93723\n",
            "     | > avg_G_gen_loss: 1.15038\n",
            "     | > avg_G_adv_loss: 0.78686\n",
            "     | > avg_D_mse_gan_loss: 0.44694\n",
            "     | > avg_D_mse_gan_real_loss: 0.13865\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13813\n",
            "     | > avg_D_loss: 0.44694\n",
            "     | > avg_loader_time: 0.91029\n",
            "     | > avg_step_time: 0.64351\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78813 \u001b[0m(-0.00078)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36550 \u001b[0m(+0.00140)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70065 \u001b[0m(-0.00083)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37258 \u001b[0m(-0.00396)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33678 \u001b[0m(-0.00237)\n",
            "     | > avg_G_loss:\u001b[92m 1.95538 \u001b[0m(-0.00801)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11343 \u001b[0m(-0.00209)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84195 \u001b[0m(-0.00593)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44517 \u001b[0m(-0.00066)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.14763 \u001b[0m(+0.01124)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12390 \u001b[0m(-0.00759)\n",
            "     | > avg_D_loss:\u001b[92m 0.44517 \u001b[0m(-0.00066)\n",
            "     | > avg_loader_time:\u001b[91m 0.44251 \u001b[0m(+0.03940)\n",
            "     | > avg_step_time:\u001b[91m 0.05592 \u001b[0m(+0.00287)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 398/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:27:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.35 sec -- GLOBAL_STEP: 433279\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81747\n",
            "     | > avg_G_stft_loss_sc: 0.35814\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75807\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36685\n",
            "     | > avg_G_mse_fake_loss: 0.31750\n",
            "     | > avg_G_loss: 1.94400\n",
            "     | > avg_G_gen_loss: 1.15026\n",
            "     | > avg_G_adv_loss: 0.79374\n",
            "     | > avg_D_mse_gan_loss: 0.44556\n",
            "     | > avg_D_mse_gan_real_loss: 0.13787\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13766\n",
            "     | > avg_D_loss: 0.44556\n",
            "     | > avg_loader_time: 0.88394\n",
            "     | > avg_step_time: 0.62957\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78493 \u001b[0m(-0.00320)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36305 \u001b[0m(-0.00244)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69887 \u001b[0m(-0.00178)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37057 \u001b[0m(-0.00202)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34499 \u001b[0m(+0.00821)\n",
            "     | > avg_G_loss:\u001b[91m 1.97119 \u001b[0m(+0.01581)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10871 \u001b[0m(-0.00472)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86248 \u001b[0m(+0.02053)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44494 \u001b[0m(-0.00024)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15277 \u001b[0m(+0.00515)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11609 \u001b[0m(-0.00781)\n",
            "     | > avg_D_loss:\u001b[92m 0.44494 \u001b[0m(-0.00024)\n",
            "     | > avg_loader_time:\u001b[92m 0.39398 \u001b[0m(-0.04852)\n",
            "     | > avg_step_time:\u001b[92m 0.05176 \u001b[0m(-0.00416)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 399/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:30:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 77.74 sec -- GLOBAL_STEP: 433400\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81743\n",
            "     | > avg_G_stft_loss_sc: 0.35782\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75818\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36620\n",
            "     | > avg_G_mse_fake_loss: 0.31549\n",
            "     | > avg_G_loss: 1.93855\n",
            "     | > avg_G_gen_loss: 1.14981\n",
            "     | > avg_G_adv_loss: 0.78874\n",
            "     | > avg_D_mse_gan_loss: 0.44636\n",
            "     | > avg_D_mse_gan_real_loss: 0.13803\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13774\n",
            "     | > avg_D_loss: 0.44636\n",
            "     | > avg_loader_time: 0.88456\n",
            "     | > avg_step_time: 0.63985\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79029 \u001b[0m(+0.00537)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36925 \u001b[0m(+0.00619)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70241 \u001b[0m(+0.00353)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37345 \u001b[0m(+0.00289)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35925 \u001b[0m(+0.01426)\n",
            "     | > avg_G_loss:\u001b[91m 2.01582 \u001b[0m(+0.04463)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11770 \u001b[0m(+0.00899)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89812 \u001b[0m(+0.03564)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44742 \u001b[0m(+0.00248)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16565 \u001b[0m(+0.01287)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10628 \u001b[0m(-0.00981)\n",
            "     | > avg_D_loss:\u001b[91m 0.44742 \u001b[0m(+0.00248)\n",
            "     | > avg_loader_time:\u001b[91m 0.40886 \u001b[0m(+0.01488)\n",
            "     | > avg_step_time:\u001b[92m 0.05093 \u001b[0m(-0.00083)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 400/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:33:29) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.52 sec -- GLOBAL_STEP: 433521\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81494\n",
            "     | > avg_G_stft_loss_sc: 0.35610\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75312\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36495\n",
            "     | > avg_G_mse_fake_loss: 0.31802\n",
            "     | > avg_G_loss: 1.93961\n",
            "     | > avg_G_gen_loss: 1.14455\n",
            "     | > avg_G_adv_loss: 0.79506\n",
            "     | > avg_D_mse_gan_loss: 0.44506\n",
            "     | > avg_D_mse_gan_real_loss: 0.13832\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13714\n",
            "     | > avg_D_loss: 0.44506\n",
            "     | > avg_loader_time: 0.85447\n",
            "     | > avg_step_time: 0.62269\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78588 \u001b[0m(-0.00442)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35546 \u001b[0m(-0.01379)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69932 \u001b[0m(-0.00308)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37051 \u001b[0m(-0.00295)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29788 \u001b[0m(-0.06137)\n",
            "     | > avg_G_loss:\u001b[92m 1.85028 \u001b[0m(-0.16554)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10558 \u001b[0m(-0.01212)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74470 \u001b[0m(-0.15342)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44186 \u001b[0m(-0.00556)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12553 \u001b[0m(-0.04012)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13892 \u001b[0m(+0.03264)\n",
            "     | > avg_D_loss:\u001b[92m 0.44186 \u001b[0m(-0.00556)\n",
            "     | > avg_loader_time:\u001b[91m 0.43313 \u001b[0m(+0.02427)\n",
            "     | > avg_step_time:\u001b[91m 0.05558 \u001b[0m(+0.00465)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 401/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:36:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 76.03 sec -- GLOBAL_STEP: 433642\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81845\n",
            "     | > avg_G_stft_loss_sc: 0.35963\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75694\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36838\n",
            "     | > avg_G_mse_fake_loss: 0.32049\n",
            "     | > avg_G_loss: 1.95293\n",
            "     | > avg_G_gen_loss: 1.15170\n",
            "     | > avg_G_adv_loss: 0.80123\n",
            "     | > avg_D_mse_gan_loss: 0.44365\n",
            "     | > avg_D_mse_gan_real_loss: 0.13795\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13660\n",
            "     | > avg_D_loss: 0.44365\n",
            "     | > avg_loader_time: 0.88618\n",
            "     | > avg_step_time: 0.62782\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78757 \u001b[0m(+0.00170)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36510 \u001b[0m(+0.00964)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70066 \u001b[0m(+0.00134)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36881 \u001b[0m(-0.00169)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.30028 \u001b[0m(+0.00240)\n",
            "     | > avg_G_loss:\u001b[91m 1.86178 \u001b[0m(+0.01150)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11108 \u001b[0m(+0.00549)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.75071 \u001b[0m(+0.00601)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44192 \u001b[0m(+0.00007)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.12536 \u001b[0m(-0.00017)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14163 \u001b[0m(+0.00271)\n",
            "     | > avg_D_loss:\u001b[91m 0.44192 \u001b[0m(+0.00007)\n",
            "     | > avg_loader_time:\u001b[91m 0.44137 \u001b[0m(+0.00825)\n",
            "     | > avg_step_time:\u001b[91m 0.05606 \u001b[0m(+0.00048)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 402/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:39:51) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 80.45 sec -- GLOBAL_STEP: 433763\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81258\n",
            "     | > avg_G_stft_loss_sc: 0.36160\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75000\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37006\n",
            "     | > avg_G_mse_fake_loss: 0.31450\n",
            "     | > avg_G_loss: 1.93337\n",
            "     | > avg_G_gen_loss: 1.14712\n",
            "     | > avg_G_adv_loss: 0.78625\n",
            "     | > avg_D_mse_gan_loss: 0.44706\n",
            "     | > avg_D_mse_gan_real_loss: 0.13836\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13834\n",
            "     | > avg_D_loss: 0.44706\n",
            "     | > avg_loader_time: 0.91099\n",
            "     | > avg_step_time: 0.66336\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78686 \u001b[0m(-0.00072)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36106 \u001b[0m(-0.00405)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70054 \u001b[0m(-0.00013)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37473 \u001b[0m(+0.00592)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34995 \u001b[0m(+0.04967)\n",
            "     | > avg_G_loss:\u001b[91m 1.98647 \u001b[0m(+0.12469)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11159 \u001b[0m(+0.00052)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.87488 \u001b[0m(+0.12417)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44634 \u001b[0m(+0.00441)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17777 \u001b[0m(+0.05241)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09651 \u001b[0m(-0.04512)\n",
            "     | > avg_D_loss:\u001b[91m 0.44634 \u001b[0m(+0.00441)\n",
            "     | > avg_loader_time:\u001b[92m 0.40725 \u001b[0m(-0.03413)\n",
            "     | > avg_step_time:\u001b[92m 0.05023 \u001b[0m(-0.00583)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 403/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:43:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 82.80 sec -- GLOBAL_STEP: 433884\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81075\n",
            "     | > avg_G_stft_loss_sc: 0.36209\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74693\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37077\n",
            "     | > avg_G_mse_fake_loss: 0.31457\n",
            "     | > avg_G_loss: 1.93169\n",
            "     | > avg_G_gen_loss: 1.14527\n",
            "     | > avg_G_adv_loss: 0.78642\n",
            "     | > avg_D_mse_gan_loss: 0.44668\n",
            "     | > avg_D_mse_gan_real_loss: 0.13833\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13790\n",
            "     | > avg_D_loss: 0.44668\n",
            "     | > avg_loader_time: 0.90612\n",
            "     | > avg_step_time: 0.68355\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78685 \u001b[0m(-0.00000)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36034 \u001b[0m(-0.00072)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70052 \u001b[0m(-0.00002)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37279 \u001b[0m(-0.00194)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35739 \u001b[0m(+0.00744)\n",
            "     | > avg_G_loss:\u001b[91m 2.00372 \u001b[0m(+0.01725)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11025 \u001b[0m(-0.00134)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.89347 \u001b[0m(+0.01859)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44865 \u001b[0m(+0.00231)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.16130 \u001b[0m(-0.01647)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11312 \u001b[0m(+0.01662)\n",
            "     | > avg_D_loss:\u001b[91m 0.44865 \u001b[0m(+0.00231)\n",
            "     | > avg_loader_time:\u001b[91m 0.43684 \u001b[0m(+0.02959)\n",
            "     | > avg_step_time:\u001b[91m 0.05471 \u001b[0m(+0.00448)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 404/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:46:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 115/120 -- GLOBAL_STEP: 434000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.80399  (0.81041)\n",
            "     | > G_stft_loss_sc: 0.36673  (0.36029)\n",
            "     | > G_subband_stft_loss_mg: 0.73263  (0.74769)\n",
            "     | > G_subband_stft_loss_sc: 0.37549  (0.36864)\n",
            "     | > G_mse_fake_loss: 0.29846  (0.31258)\n",
            "     | > G_loss: 1.88556  (1.92496)\n",
            "     | > G_gen_loss: 1.13942  (1.14351)\n",
            "     | > G_adv_loss: 0.74614  (0.78145)\n",
            "     | > D_mse_gan_loss: 0.44587  (0.44765)\n",
            "     | > D_mse_gan_real_loss: 0.12354  (0.13848)\n",
            "     | > D_mse_gan_fake_loss: 0.15396  (0.13784)\n",
            "     | > D_loss: 0.44587  (0.44765)\n",
            "     | > step_time: 0.49\n",
            "     | > loader_time: 0.0059\n",
            "     | > current_lr_G: 5.554037671616842e-06\n",
            "     | > current_lr_D: 5.554037671616842e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 75.05 sec -- GLOBAL_STEP: 434005\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81054\n",
            "     | > avg_G_stft_loss_sc: 0.36004\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74790\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36834\n",
            "     | > avg_G_mse_fake_loss: 0.31260\n",
            "     | > avg_G_loss: 1.92490\n",
            "     | > avg_G_gen_loss: 1.14341\n",
            "     | > avg_G_adv_loss: 0.78149\n",
            "     | > avg_D_mse_gan_loss: 0.44763\n",
            "     | > avg_D_mse_gan_real_loss: 0.13838\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13801\n",
            "     | > avg_D_loss: 0.44763\n",
            "     | > avg_loader_time: 0.85881\n",
            "     | > avg_step_time: 0.61890\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78650 \u001b[0m(-0.00035)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36507 \u001b[0m(+0.00474)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70011 \u001b[0m(-0.00041)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37633 \u001b[0m(+0.00354)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34227 \u001b[0m(-0.01512)\n",
            "     | > avg_G_loss:\u001b[92m 1.96967 \u001b[0m(-0.03405)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11401 \u001b[0m(+0.00376)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85566 \u001b[0m(-0.03781)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44644 \u001b[0m(-0.00221)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16294 \u001b[0m(+0.00164)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11040 \u001b[0m(-0.00273)\n",
            "     | > avg_D_loss:\u001b[92m 0.44644 \u001b[0m(-0.00221)\n",
            "     | > avg_loader_time:\u001b[92m 0.40251 \u001b[0m(-0.03432)\n",
            "     | > avg_step_time:\u001b[91m 0.05519 \u001b[0m(+0.00047)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 405/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:49:45) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.55 sec -- GLOBAL_STEP: 434126\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80905\n",
            "     | > avg_G_stft_loss_sc: 0.35817\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74292\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36718\n",
            "     | > avg_G_mse_fake_loss: 0.31500\n",
            "     | > avg_G_loss: 1.92617\n",
            "     | > avg_G_gen_loss: 1.13866\n",
            "     | > avg_G_adv_loss: 0.78751\n",
            "     | > avg_D_mse_gan_loss: 0.44725\n",
            "     | > avg_D_mse_gan_real_loss: 0.13791\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13796\n",
            "     | > avg_D_loss: 0.44725\n",
            "     | > avg_loader_time: 0.82642\n",
            "     | > avg_step_time: 0.57418\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79112 \u001b[0m(+0.00461)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.38639 \u001b[0m(+0.02132)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70317 \u001b[0m(+0.00306)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38466 \u001b[0m(+0.00834)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34228 \u001b[0m(+0.00001)\n",
            "     | > avg_G_loss:\u001b[91m 1.98836 \u001b[0m(+0.01869)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13267 \u001b[0m(+0.01866)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85569 \u001b[0m(+0.00003)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44974 \u001b[0m(+0.00330)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16850 \u001b[0m(+0.00556)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10528 \u001b[0m(-0.00512)\n",
            "     | > avg_D_loss:\u001b[91m 0.44974 \u001b[0m(+0.00330)\n",
            "     | > avg_loader_time:\u001b[91m 0.43560 \u001b[0m(+0.03308)\n",
            "     | > avg_step_time:\u001b[92m 0.05047 \u001b[0m(-0.00472)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 406/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:52:44) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.20 sec -- GLOBAL_STEP: 434247\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80907\n",
            "     | > avg_G_stft_loss_sc: 0.36082\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74564\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36907\n",
            "     | > avg_G_mse_fake_loss: 0.31227\n",
            "     | > avg_G_loss: 1.92296\n",
            "     | > avg_G_gen_loss: 1.14230\n",
            "     | > avg_G_adv_loss: 0.78066\n",
            "     | > avg_D_mse_gan_loss: 0.44802\n",
            "     | > avg_D_mse_gan_real_loss: 0.13855\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13771\n",
            "     | > avg_D_loss: 0.44802\n",
            "     | > avg_loader_time: 0.81352\n",
            "     | > avg_step_time: 0.55456\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78624 \u001b[0m(-0.00488)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36534 \u001b[0m(-0.02105)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70103 \u001b[0m(-0.00213)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.38224 \u001b[0m(-0.00242)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32226 \u001b[0m(-0.02002)\n",
            "     | > avg_G_loss:\u001b[92m 1.92308 \u001b[0m(-0.06528)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11743 \u001b[0m(-0.01524)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.80565 \u001b[0m(-0.05004)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44222 \u001b[0m(-0.00753)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14203 \u001b[0m(-0.02647)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12661 \u001b[0m(+0.02133)\n",
            "     | > avg_D_loss:\u001b[92m 0.44222 \u001b[0m(-0.00753)\n",
            "     | > avg_loader_time:\u001b[92m 0.38623 \u001b[0m(-0.04937)\n",
            "     | > avg_step_time:\u001b[91m 0.05213 \u001b[0m(+0.00166)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 407/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:55:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 71.06 sec -- GLOBAL_STEP: 434368\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81846\n",
            "     | > avg_G_stft_loss_sc: 0.35829\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75923\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36713\n",
            "     | > avg_G_mse_fake_loss: 0.31860\n",
            "     | > avg_G_loss: 1.94805\n",
            "     | > avg_G_gen_loss: 1.15156\n",
            "     | > avg_G_adv_loss: 0.79649\n",
            "     | > avg_D_mse_gan_loss: 0.44463\n",
            "     | > avg_D_mse_gan_real_loss: 0.13699\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13674\n",
            "     | > avg_D_loss: 0.44463\n",
            "     | > avg_loader_time: 0.82023\n",
            "     | > avg_step_time: 0.58691\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78615 \u001b[0m(-0.00009)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37347 \u001b[0m(+0.00812)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70070 \u001b[0m(-0.00034)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38896 \u001b[0m(+0.00671)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38651 \u001b[0m(+0.06425)\n",
            "     | > avg_G_loss:\u001b[91m 2.09090 \u001b[0m(+0.16782)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12463 \u001b[0m(+0.00721)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.96627 \u001b[0m(+0.16062)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44747 \u001b[0m(+0.00526)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17604 \u001b[0m(+0.03401)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09741 \u001b[0m(-0.02920)\n",
            "     | > avg_D_loss:\u001b[91m 0.44747 \u001b[0m(+0.00526)\n",
            "     | > avg_loader_time:\u001b[91m 0.43519 \u001b[0m(+0.04896)\n",
            "     | > avg_step_time:\u001b[91m 0.05493 \u001b[0m(+0.00280)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 408/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 22:58:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.50 sec -- GLOBAL_STEP: 434489\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81622\n",
            "     | > avg_G_stft_loss_sc: 0.35738\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75678\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36604\n",
            "     | > avg_G_mse_fake_loss: 0.31562\n",
            "     | > avg_G_loss: 1.93725\n",
            "     | > avg_G_gen_loss: 1.14821\n",
            "     | > avg_G_adv_loss: 0.78904\n",
            "     | > avg_D_mse_gan_loss: 0.44596\n",
            "     | > avg_D_mse_gan_real_loss: 0.13781\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13754\n",
            "     | > avg_D_loss: 0.44596\n",
            "     | > avg_loader_time: 0.80816\n",
            "     | > avg_step_time: 0.56599\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78591 \u001b[0m(-0.00024)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35918 \u001b[0m(-0.01429)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69966 \u001b[0m(-0.00104)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37670 \u001b[0m(-0.01226)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32421 \u001b[0m(-0.06230)\n",
            "     | > avg_G_loss:\u001b[92m 1.92124 \u001b[0m(-0.16966)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11072 \u001b[0m(-0.01391)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81052 \u001b[0m(-0.15575)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44261 \u001b[0m(-0.00486)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15617 \u001b[0m(-0.01987)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11331 \u001b[0m(+0.01590)\n",
            "     | > avg_D_loss:\u001b[92m 0.44261 \u001b[0m(-0.00486)\n",
            "     | > avg_loader_time:\u001b[92m 0.39876 \u001b[0m(-0.03642)\n",
            "     | > avg_step_time:\u001b[92m 0.05100 \u001b[0m(-0.00393)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 409/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:01:34) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.30 sec -- GLOBAL_STEP: 434610\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81162\n",
            "     | > avg_G_stft_loss_sc: 0.35878\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74862\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36739\n",
            "     | > avg_G_mse_fake_loss: 0.31560\n",
            "     | > avg_G_loss: 1.93221\n",
            "     | > avg_G_gen_loss: 1.14320\n",
            "     | > avg_G_adv_loss: 0.78901\n",
            "     | > avg_D_mse_gan_loss: 0.44665\n",
            "     | > avg_D_mse_gan_real_loss: 0.13850\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13831\n",
            "     | > avg_D_loss: 0.44665\n",
            "     | > avg_loader_time: 0.81737\n",
            "     | > avg_step_time: 0.57989\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78651 \u001b[0m(+0.00060)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35780 \u001b[0m(-0.00138)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.69978 \u001b[0m(+0.00013)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37174 \u001b[0m(-0.00496)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34563 \u001b[0m(+0.02143)\n",
            "     | > avg_G_loss:\u001b[91m 1.97200 \u001b[0m(+0.05076)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10791 \u001b[0m(-0.00281)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86409 \u001b[0m(+0.05356)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44285 \u001b[0m(+0.00024)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14660 \u001b[0m(-0.00956)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12240 \u001b[0m(+0.00909)\n",
            "     | > avg_D_loss:\u001b[91m 0.44285 \u001b[0m(+0.00024)\n",
            "     | > avg_loader_time:\u001b[92m 0.38515 \u001b[0m(-0.01361)\n",
            "     | > avg_step_time:\u001b[92m 0.05004 \u001b[0m(-0.00096)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 410/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:04:33) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.20 sec -- GLOBAL_STEP: 434731\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80039\n",
            "     | > avg_G_stft_loss_sc: 0.35623\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72487\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36520\n",
            "     | > avg_G_mse_fake_loss: 0.31613\n",
            "     | > avg_G_loss: 1.91368\n",
            "     | > avg_G_gen_loss: 1.12335\n",
            "     | > avg_G_adv_loss: 0.79033\n",
            "     | > avg_D_mse_gan_loss: 0.44688\n",
            "     | > avg_D_mse_gan_real_loss: 0.13821\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13762\n",
            "     | > avg_D_loss: 0.44688\n",
            "     | > avg_loader_time: 0.80576\n",
            "     | > avg_step_time: 0.56267\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78829 \u001b[0m(+0.00177)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.35793 \u001b[0m(+0.00013)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70062 \u001b[0m(+0.00084)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36954 \u001b[0m(-0.00220)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36658 \u001b[0m(+0.02095)\n",
            "     | > avg_G_loss:\u001b[91m 2.02463 \u001b[0m(+0.05263)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10818 \u001b[0m(+0.00027)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.91645 \u001b[0m(+0.05236)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44016 \u001b[0m(-0.00269)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14545 \u001b[0m(-0.00116)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11306 \u001b[0m(-0.00935)\n",
            "     | > avg_D_loss:\u001b[92m 0.44016 \u001b[0m(-0.00269)\n",
            "     | > avg_loader_time:\u001b[91m 0.38790 \u001b[0m(+0.00275)\n",
            "     | > avg_step_time:\u001b[91m 0.05063 \u001b[0m(+0.00059)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 411/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:07:28) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.62 sec -- GLOBAL_STEP: 434852\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81851\n",
            "     | > avg_G_stft_loss_sc: 0.35828\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75983\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36740\n",
            "     | > avg_G_mse_fake_loss: 0.31972\n",
            "     | > avg_G_loss: 1.95130\n",
            "     | > avg_G_gen_loss: 1.15201\n",
            "     | > avg_G_adv_loss: 0.79930\n",
            "     | > avg_D_mse_gan_loss: 0.44399\n",
            "     | > avg_D_mse_gan_real_loss: 0.13744\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13650\n",
            "     | > avg_D_loss: 0.44399\n",
            "     | > avg_loader_time: 0.81261\n",
            "     | > avg_step_time: 0.56622\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78739 \u001b[0m(-0.00090)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37095 \u001b[0m(+0.01302)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70212 \u001b[0m(+0.00150)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39358 \u001b[0m(+0.02404)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33692 \u001b[0m(-0.02966)\n",
            "     | > avg_G_loss:\u001b[92m 1.96933 \u001b[0m(-0.05530)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12702 \u001b[0m(+0.01884)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84231 \u001b[0m(-0.07414)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.43967 \u001b[0m(-0.00049)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14339 \u001b[0m(-0.00205)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12006 \u001b[0m(+0.00701)\n",
            "     | > avg_D_loss:\u001b[92m 0.43967 \u001b[0m(-0.00049)\n",
            "     | > avg_loader_time:\u001b[91m 0.43594 \u001b[0m(+0.04804)\n",
            "     | > avg_step_time:\u001b[91m 0.05087 \u001b[0m(+0.00024)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 412/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:10:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.08 sec -- GLOBAL_STEP: 434973\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81381\n",
            "     | > avg_G_stft_loss_sc: 0.35805\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75306\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36644\n",
            "     | > avg_G_mse_fake_loss: 0.31482\n",
            "     | > avg_G_loss: 1.93273\n",
            "     | > avg_G_gen_loss: 1.14568\n",
            "     | > avg_G_adv_loss: 0.78705\n",
            "     | > avg_D_mse_gan_loss: 0.44653\n",
            "     | > avg_D_mse_gan_real_loss: 0.13801\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13756\n",
            "     | > avg_D_loss: 0.44653\n",
            "     | > avg_loader_time: 0.80461\n",
            "     | > avg_step_time: 0.57002\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78708 \u001b[0m(-0.00031)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36748 \u001b[0m(-0.00348)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70095 \u001b[0m(-0.00117)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37623 \u001b[0m(-0.01735)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32645 \u001b[0m(-0.01048)\n",
            "     | > avg_G_loss:\u001b[92m 1.93199 \u001b[0m(-0.03734)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11587 \u001b[0m(-0.01115)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81612 \u001b[0m(-0.02619)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44746 \u001b[0m(+0.00779)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14008 \u001b[0m(-0.00331)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13026 \u001b[0m(+0.01020)\n",
            "     | > avg_D_loss:\u001b[91m 0.44746 \u001b[0m(+0.00779)\n",
            "     | > avg_loader_time:\u001b[92m 0.37997 \u001b[0m(-0.05598)\n",
            "     | > avg_step_time:\u001b[92m 0.04620 \u001b[0m(-0.00467)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 413/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:13:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 26/120 -- GLOBAL_STEP: 435000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.78817  (0.80870)\n",
            "     | > G_stft_loss_sc: 0.34768  (0.35984)\n",
            "     | > G_subband_stft_loss_mg: 0.70225  (0.73948)\n",
            "     | > G_subband_stft_loss_sc: 0.36005  (0.36911)\n",
            "     | > G_mse_fake_loss: 0.31085  (0.31931)\n",
            "     | > G_loss: 1.87619  (1.93683)\n",
            "     | > G_gen_loss: 1.09907  (1.13856)\n",
            "     | > G_adv_loss: 0.77712  (0.79826)\n",
            "     | > D_mse_gan_loss: 0.45068  (0.44674)\n",
            "     | > D_mse_gan_real_loss: 0.15232  (0.13965)\n",
            "     | > D_mse_gan_fake_loss: 0.13383  (0.13680)\n",
            "     | > D_loss: 0.45068  (0.44674)\n",
            "     | > step_time: 0.58\n",
            "     | > loader_time: 0.0102\n",
            "     | > current_lr_G: 5.504250812088413e-06\n",
            "     | > current_lr_D: 5.504250812088413e-06\n",
            " > CHECKPOINT : /mydrive/machine-learning/tts/data/jsut_ver1.1_ljspeech_structure/output/multiband-melgan/checkpoint_435000.pth.tar\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.53 sec -- GLOBAL_STEP: 435094\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80648\n",
            "     | > avg_G_stft_loss_sc: 0.35942\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73722\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36858\n",
            "     | > avg_G_mse_fake_loss: 0.31706\n",
            "     | > avg_G_loss: 1.92851\n",
            "     | > avg_G_gen_loss: 1.13585\n",
            "     | > avg_G_adv_loss: 0.79266\n",
            "     | > avg_D_mse_gan_loss: 0.44681\n",
            "     | > avg_D_mse_gan_real_loss: 0.13876\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13777\n",
            "     | > avg_D_loss: 0.44681\n",
            "     | > avg_loader_time: 0.74664\n",
            "     | > avg_step_time: 0.57380\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78480 \u001b[0m(-0.00228)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35848 \u001b[0m(-0.00900)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69919 \u001b[0m(-0.00176)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37393 \u001b[0m(-0.00231)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.36114 \u001b[0m(+0.03469)\n",
            "     | > avg_G_loss:\u001b[91m 2.01105 \u001b[0m(+0.07906)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10820 \u001b[0m(-0.00767)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.90285 \u001b[0m(+0.08673)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44108 \u001b[0m(-0.00637)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15823 \u001b[0m(+0.01815)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10557 \u001b[0m(-0.02469)\n",
            "     | > avg_D_loss:\u001b[92m 0.44108 \u001b[0m(-0.00637)\n",
            "     | > avg_loader_time:\u001b[91m 0.39329 \u001b[0m(+0.01332)\n",
            "     | > avg_step_time:\u001b[92m 0.04594 \u001b[0m(-0.00026)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 414/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:16:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.77 sec -- GLOBAL_STEP: 435215\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81543\n",
            "     | > avg_G_stft_loss_sc: 0.35668\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75609\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36509\n",
            "     | > avg_G_mse_fake_loss: 0.31586\n",
            "     | > avg_G_loss: 1.93631\n",
            "     | > avg_G_gen_loss: 1.14665\n",
            "     | > avg_G_adv_loss: 0.78966\n",
            "     | > avg_D_mse_gan_loss: 0.44557\n",
            "     | > avg_D_mse_gan_real_loss: 0.13776\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13752\n",
            "     | > avg_D_loss: 0.44557\n",
            "     | > avg_loader_time: 0.80089\n",
            "     | > avg_step_time: 0.56726\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78708 \u001b[0m(+0.00228)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36540 \u001b[0m(+0.00692)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70103 \u001b[0m(+0.00183)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38304 \u001b[0m(+0.00911)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35230 \u001b[0m(-0.00884)\n",
            "     | > avg_G_loss:\u001b[92m 1.99903 \u001b[0m(-0.01202)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11827 \u001b[0m(+0.01007)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.88076 \u001b[0m(-0.02209)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44130 \u001b[0m(+0.00022)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15885 \u001b[0m(+0.00061)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10847 \u001b[0m(+0.00289)\n",
            "     | > avg_D_loss:\u001b[91m 0.44130 \u001b[0m(+0.00022)\n",
            "     | > avg_loader_time:\u001b[91m 0.40417 \u001b[0m(+0.01088)\n",
            "     | > avg_step_time:\u001b[91m 0.05047 \u001b[0m(+0.00453)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 415/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:19:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.98 sec -- GLOBAL_STEP: 435336\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81928\n",
            "     | > avg_G_stft_loss_sc: 0.35599\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76011\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36479\n",
            "     | > avg_G_mse_fake_loss: 0.31834\n",
            "     | > avg_G_loss: 1.94593\n",
            "     | > avg_G_gen_loss: 1.15008\n",
            "     | > avg_G_adv_loss: 0.79585\n",
            "     | > avg_D_mse_gan_loss: 0.44480\n",
            "     | > avg_D_mse_gan_real_loss: 0.13772\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13737\n",
            "     | > avg_D_loss: 0.44480\n",
            "     | > avg_loader_time: 0.79810\n",
            "     | > avg_step_time: 0.57764\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78544 \u001b[0m(-0.00164)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35430 \u001b[0m(-0.01110)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69950 \u001b[0m(-0.00152)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36748 \u001b[0m(-0.01556)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.35199 \u001b[0m(-0.00031)\n",
            "     | > avg_G_loss:\u001b[92m 1.98334 \u001b[0m(-0.01569)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10336 \u001b[0m(-0.01491)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.87998 \u001b[0m(-0.00078)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44357 \u001b[0m(+0.00227)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16470 \u001b[0m(+0.00585)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10256 \u001b[0m(-0.00590)\n",
            "     | > avg_D_loss:\u001b[91m 0.44357 \u001b[0m(+0.00227)\n",
            "     | > avg_loader_time:\u001b[91m 0.40560 \u001b[0m(+0.00143)\n",
            "     | > avg_step_time:\u001b[92m 0.04927 \u001b[0m(-0.00120)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 416/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:22:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.50 sec -- GLOBAL_STEP: 435457\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80733\n",
            "     | > avg_G_stft_loss_sc: 0.35586\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73805\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36452\n",
            "     | > avg_G_mse_fake_loss: 0.31513\n",
            "     | > avg_G_loss: 1.92071\n",
            "     | > avg_G_gen_loss: 1.13288\n",
            "     | > avg_G_adv_loss: 0.78783\n",
            "     | > avg_D_mse_gan_loss: 0.44738\n",
            "     | > avg_D_mse_gan_real_loss: 0.13816\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13778\n",
            "     | > avg_D_loss: 0.44738\n",
            "     | > avg_loader_time: 0.80376\n",
            "     | > avg_step_time: 0.57350\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78630 \u001b[0m(+0.00086)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.35657 \u001b[0m(+0.00228)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70205 \u001b[0m(+0.00254)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37261 \u001b[0m(+0.00514)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.34310 \u001b[0m(-0.00889)\n",
            "     | > avg_G_loss:\u001b[92m 1.96652 \u001b[0m(-0.01682)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.10877 \u001b[0m(+0.00541)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.85775 \u001b[0m(-0.02223)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44411 \u001b[0m(+0.00053)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14860 \u001b[0m(-0.01609)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11827 \u001b[0m(+0.01570)\n",
            "     | > avg_D_loss:\u001b[91m 0.44411 \u001b[0m(+0.00053)\n",
            "     | > avg_loader_time:\u001b[92m 0.38824 \u001b[0m(-0.01736)\n",
            "     | > avg_step_time:\u001b[92m 0.04742 \u001b[0m(-0.00185)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 417/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:25:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.97 sec -- GLOBAL_STEP: 435578\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81592\n",
            "     | > avg_G_stft_loss_sc: 0.35622\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75617\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36466\n",
            "     | > avg_G_mse_fake_loss: 0.31402\n",
            "     | > avg_G_loss: 1.93154\n",
            "     | > avg_G_gen_loss: 1.14649\n",
            "     | > avg_G_adv_loss: 0.78505\n",
            "     | > avg_D_mse_gan_loss: 0.44740\n",
            "     | > avg_D_mse_gan_real_loss: 0.13796\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13799\n",
            "     | > avg_D_loss: 0.44740\n",
            "     | > avg_loader_time: 0.82915\n",
            "     | > avg_step_time: 0.56122\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78766 \u001b[0m(+0.00136)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36304 \u001b[0m(+0.00647)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70171 \u001b[0m(-0.00034)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37362 \u001b[0m(+0.00100)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34432 \u001b[0m(+0.00122)\n",
            "     | > avg_G_loss:\u001b[91m 1.97382 \u001b[0m(+0.00730)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11301 \u001b[0m(+0.00424)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86080 \u001b[0m(+0.00305)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44426 \u001b[0m(+0.00016)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16187 \u001b[0m(+0.01326)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10465 \u001b[0m(-0.01361)\n",
            "     | > avg_D_loss:\u001b[91m 0.44426 \u001b[0m(+0.00016)\n",
            "     | > avg_loader_time:\u001b[92m 0.36093 \u001b[0m(-0.02731)\n",
            "     | > avg_step_time:\u001b[92m 0.04598 \u001b[0m(-0.00144)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 418/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:28:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.24 sec -- GLOBAL_STEP: 435699\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81842\n",
            "     | > avg_G_stft_loss_sc: 0.35596\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75810\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36449\n",
            "     | > avg_G_mse_fake_loss: 0.31882\n",
            "     | > avg_G_loss: 1.94553\n",
            "     | > avg_G_gen_loss: 1.14849\n",
            "     | > avg_G_adv_loss: 0.79704\n",
            "     | > avg_D_mse_gan_loss: 0.44416\n",
            "     | > avg_D_mse_gan_real_loss: 0.13681\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13703\n",
            "     | > avg_D_loss: 0.44416\n",
            "     | > avg_loader_time: 0.80828\n",
            "     | > avg_step_time: 0.56346\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78588 \u001b[0m(-0.00178)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35456 \u001b[0m(-0.00847)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69933 \u001b[0m(-0.00238)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36781 \u001b[0m(-0.00580)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.39488 \u001b[0m(+0.05055)\n",
            "     | > avg_G_loss:\u001b[91m 2.09098 \u001b[0m(+0.11717)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10379 \u001b[0m(-0.00922)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.98719 \u001b[0m(+0.12638)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45136 \u001b[0m(+0.00710)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17809 \u001b[0m(+0.01623)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09629 \u001b[0m(-0.00837)\n",
            "     | > avg_D_loss:\u001b[91m 0.45136 \u001b[0m(+0.00710)\n",
            "     | > avg_loader_time:\u001b[91m 0.42941 \u001b[0m(+0.06848)\n",
            "     | > avg_step_time:\u001b[91m 0.04956 \u001b[0m(+0.00358)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 419/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:30:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 66.91 sec -- GLOBAL_STEP: 435820\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81504\n",
            "     | > avg_G_stft_loss_sc: 0.35945\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75479\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36820\n",
            "     | > avg_G_mse_fake_loss: 0.31585\n",
            "     | > avg_G_loss: 1.93838\n",
            "     | > avg_G_gen_loss: 1.14875\n",
            "     | > avg_G_adv_loss: 0.78963\n",
            "     | > avg_D_mse_gan_loss: 0.44652\n",
            "     | > avg_D_mse_gan_real_loss: 0.13827\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13753\n",
            "     | > avg_D_loss: 0.44652\n",
            "     | > avg_loader_time: 0.79178\n",
            "     | > avg_step_time: 0.55278\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78819 \u001b[0m(+0.00231)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36021 \u001b[0m(+0.00564)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70147 \u001b[0m(+0.00213)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37125 \u001b[0m(+0.00344)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33063 \u001b[0m(-0.06425)\n",
            "     | > avg_G_loss:\u001b[92m 1.93713 \u001b[0m(-0.15385)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11056 \u001b[0m(+0.00676)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.82657 \u001b[0m(-0.16062)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44311 \u001b[0m(-0.00825)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15388 \u001b[0m(-0.02421)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10962 \u001b[0m(+0.01333)\n",
            "     | > avg_D_loss:\u001b[92m 0.44311 \u001b[0m(-0.00825)\n",
            "     | > avg_loader_time:\u001b[92m 0.41168 \u001b[0m(-0.01774)\n",
            "     | > avg_step_time:\u001b[91m 0.05389 \u001b[0m(+0.00433)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 420/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:33:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.00 sec -- GLOBAL_STEP: 435941\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80236\n",
            "     | > avg_G_stft_loss_sc: 0.35872\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73043\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36741\n",
            "     | > avg_G_mse_fake_loss: 0.31553\n",
            "     | > avg_G_loss: 1.91827\n",
            "     | > avg_G_gen_loss: 1.12946\n",
            "     | > avg_G_adv_loss: 0.78882\n",
            "     | > avg_D_mse_gan_loss: 0.44662\n",
            "     | > avg_D_mse_gan_real_loss: 0.13768\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13756\n",
            "     | > avg_D_loss: 0.44662\n",
            "     | > avg_loader_time: 0.80877\n",
            "     | > avg_step_time: 0.56942\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78533 \u001b[0m(-0.00286)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35722 \u001b[0m(-0.00298)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70005 \u001b[0m(-0.00142)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37247 \u001b[0m(+0.00122)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35090 \u001b[0m(+0.02027)\n",
            "     | > avg_G_loss:\u001b[91m 1.98478 \u001b[0m(+0.04765)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10754 \u001b[0m(-0.00302)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.87724 \u001b[0m(+0.05067)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44630 \u001b[0m(+0.00318)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.18177 \u001b[0m(+0.02789)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09292 \u001b[0m(-0.01670)\n",
            "     | > avg_D_loss:\u001b[91m 0.44630 \u001b[0m(+0.00318)\n",
            "     | > avg_loader_time:\u001b[92m 0.37655 \u001b[0m(-0.03512)\n",
            "     | > avg_step_time:\u001b[91m 0.05409 \u001b[0m(+0.00020)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 421/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:36:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 58/120 -- GLOBAL_STEP: 436000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.81101  (0.81335)\n",
            "     | > G_stft_loss_sc: 0.36797  (0.36164)\n",
            "     | > G_subband_stft_loss_mg: 0.75280  (0.75211)\n",
            "     | > G_subband_stft_loss_sc: 0.38028  (0.36993)\n",
            "     | > G_mse_fake_loss: 0.30568  (0.31402)\n",
            "     | > G_loss: 1.92024  (1.93357)\n",
            "     | > G_gen_loss: 1.15604  (1.14851)\n",
            "     | > G_adv_loss: 0.76421  (0.78505)\n",
            "     | > D_mse_gan_loss: 0.44790  (0.44767)\n",
            "     | > D_mse_gan_real_loss: 0.13870  (0.13827)\n",
            "     | > D_mse_gan_fake_loss: 0.13968  (0.13808)\n",
            "     | > D_loss: 0.44790  (0.44767)\n",
            "     | > step_time: 0.57\n",
            "     | > loader_time: 0.0138\n",
            "     | > current_lr_G: 5.460370616761387e-06\n",
            "     | > current_lr_D: 5.460370616761387e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 65.89 sec -- GLOBAL_STEP: 436062\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81324\n",
            "     | > avg_G_stft_loss_sc: 0.35979\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75229\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36780\n",
            "     | > avg_G_mse_fake_loss: 0.31413\n",
            "     | > avg_G_loss: 1.93187\n",
            "     | > avg_G_gen_loss: 1.14655\n",
            "     | > avg_G_adv_loss: 0.78532\n",
            "     | > avg_D_mse_gan_loss: 0.44727\n",
            "     | > avg_D_mse_gan_real_loss: 0.13794\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13807\n",
            "     | > avg_D_loss: 0.44727\n",
            "     | > avg_loader_time: 0.81809\n",
            "     | > avg_step_time: 0.54392\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78595 \u001b[0m(+0.00062)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35633 \u001b[0m(-0.00089)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69916 \u001b[0m(-0.00089)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36688 \u001b[0m(-0.00559)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33327 \u001b[0m(-0.01762)\n",
            "     | > avg_G_loss:\u001b[92m 1.93735 \u001b[0m(-0.04743)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10416 \u001b[0m(-0.00338)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.83319 \u001b[0m(-0.04405)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44117 \u001b[0m(-0.00513)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14312 \u001b[0m(-0.03865)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11861 \u001b[0m(+0.02570)\n",
            "     | > avg_D_loss:\u001b[92m 0.44117 \u001b[0m(-0.00513)\n",
            "     | > avg_loader_time:\u001b[91m 0.46487 \u001b[0m(+0.08831)\n",
            "     | > avg_step_time:\u001b[92m 0.05311 \u001b[0m(-0.00099)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 422/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:39:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.03 sec -- GLOBAL_STEP: 436183\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81074\n",
            "     | > avg_G_stft_loss_sc: 0.35640\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74625\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36543\n",
            "     | > avg_G_mse_fake_loss: 0.31483\n",
            "     | > avg_G_loss: 1.92647\n",
            "     | > avg_G_gen_loss: 1.13941\n",
            "     | > avg_G_adv_loss: 0.78707\n",
            "     | > avg_D_mse_gan_loss: 0.44751\n",
            "     | > avg_D_mse_gan_real_loss: 0.13883\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13819\n",
            "     | > avg_D_loss: 0.44751\n",
            "     | > avg_loader_time: 0.81315\n",
            "     | > avg_step_time: 0.56948\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78810 \u001b[0m(+0.00215)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.35852 \u001b[0m(+0.00219)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70149 \u001b[0m(+0.00233)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37559 \u001b[0m(+0.00871)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34356 \u001b[0m(+0.01029)\n",
            "     | > avg_G_loss:\u001b[91m 1.97076 \u001b[0m(+0.03341)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11185 \u001b[0m(+0.00769)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.85891 \u001b[0m(+0.02572)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44769 \u001b[0m(+0.00652)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16089 \u001b[0m(+0.01777)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11039 \u001b[0m(-0.00822)\n",
            "     | > avg_D_loss:\u001b[91m 0.44769 \u001b[0m(+0.00652)\n",
            "     | > avg_loader_time:\u001b[92m 0.37221 \u001b[0m(-0.09265)\n",
            "     | > avg_step_time:\u001b[92m 0.04496 \u001b[0m(-0.00815)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 423/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:42:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 66.32 sec -- GLOBAL_STEP: 436304\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81496\n",
            "     | > avg_G_stft_loss_sc: 0.36043\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75163\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36887\n",
            "     | > avg_G_mse_fake_loss: 0.31453\n",
            "     | > avg_G_loss: 1.93427\n",
            "     | > avg_G_gen_loss: 1.14794\n",
            "     | > avg_G_adv_loss: 0.78633\n",
            "     | > avg_D_mse_gan_loss: 0.44758\n",
            "     | > avg_D_mse_gan_real_loss: 0.13803\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13769\n",
            "     | > avg_D_loss: 0.44758\n",
            "     | > avg_loader_time: 0.80521\n",
            "     | > avg_step_time: 0.54744\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78786 \u001b[0m(-0.00024)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35546 \u001b[0m(-0.00306)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70036 \u001b[0m(-0.00113)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36916 \u001b[0m(-0.00642)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31626 \u001b[0m(-0.02731)\n",
            "     | > avg_G_loss:\u001b[92m 1.89707 \u001b[0m(-0.07369)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10642 \u001b[0m(-0.00543)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.79064 \u001b[0m(-0.06826)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44452 \u001b[0m(-0.00317)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14770 \u001b[0m(-0.01319)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11916 \u001b[0m(+0.00877)\n",
            "     | > avg_D_loss:\u001b[92m 0.44452 \u001b[0m(-0.00317)\n",
            "     | > avg_loader_time:\u001b[91m 0.38692 \u001b[0m(+0.01471)\n",
            "     | > avg_step_time:\u001b[91m 0.05080 \u001b[0m(+0.00585)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 424/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:45:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.22 sec -- GLOBAL_STEP: 436425\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80285\n",
            "     | > avg_G_stft_loss_sc: 0.35755\n",
            "     | > avg_G_subband_stft_loss_mg: 0.72870\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36684\n",
            "     | > avg_G_mse_fake_loss: 0.31881\n",
            "     | > avg_G_loss: 1.92500\n",
            "     | > avg_G_gen_loss: 1.12797\n",
            "     | > avg_G_adv_loss: 0.79703\n",
            "     | > avg_D_mse_gan_loss: 0.44614\n",
            "     | > avg_D_mse_gan_real_loss: 0.13800\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13741\n",
            "     | > avg_D_loss: 0.44614\n",
            "     | > avg_loader_time: 0.80357\n",
            "     | > avg_step_time: 0.57131\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78779 \u001b[0m(-0.00007)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36517 \u001b[0m(+0.00970)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70091 \u001b[0m(+0.00055)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37000 \u001b[0m(+0.00083)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32803 \u001b[0m(+0.01178)\n",
            "     | > avg_G_loss:\u001b[91m 1.93202 \u001b[0m(+0.03495)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11193 \u001b[0m(+0.00551)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.82009 \u001b[0m(+0.02944)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44921 \u001b[0m(+0.00468)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15030 \u001b[0m(+0.00260)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12282 \u001b[0m(+0.00366)\n",
            "     | > avg_D_loss:\u001b[91m 0.44921 \u001b[0m(+0.00468)\n",
            "     | > avg_loader_time:\u001b[91m 0.39536 \u001b[0m(+0.00844)\n",
            "     | > avg_step_time:\u001b[92m 0.04881 \u001b[0m(-0.00199)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 425/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:48:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.43 sec -- GLOBAL_STEP: 436546\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81873\n",
            "     | > avg_G_stft_loss_sc: 0.35724\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75965\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36576\n",
            "     | > avg_G_mse_fake_loss: 0.31789\n",
            "     | > avg_G_loss: 1.94543\n",
            "     | > avg_G_gen_loss: 1.15069\n",
            "     | > avg_G_adv_loss: 0.79473\n",
            "     | > avg_D_mse_gan_loss: 0.44529\n",
            "     | > avg_D_mse_gan_real_loss: 0.13770\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13737\n",
            "     | > avg_D_loss: 0.44529\n",
            "     | > avg_loader_time: 0.80400\n",
            "     | > avg_step_time: 0.56442\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78872 \u001b[0m(+0.00093)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36047 \u001b[0m(-0.00470)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70072 \u001b[0m(-0.00019)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36273 \u001b[0m(-0.00727)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35314 \u001b[0m(+0.02510)\n",
            "     | > avg_G_loss:\u001b[91m 1.98916 \u001b[0m(+0.05714)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10632 \u001b[0m(-0.00561)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88284 \u001b[0m(+0.06275)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44858 \u001b[0m(-0.00063)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.15498 \u001b[0m(+0.00468)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.11523 \u001b[0m(-0.00759)\n",
            "     | > avg_D_loss:\u001b[92m 0.44858 \u001b[0m(-0.00063)\n",
            "     | > avg_loader_time:\u001b[92m 0.35974 \u001b[0m(-0.03563)\n",
            "     | > avg_step_time:\u001b[92m 0.04452 \u001b[0m(-0.00429)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 426/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:51:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.59 sec -- GLOBAL_STEP: 436667\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81707\n",
            "     | > avg_G_stft_loss_sc: 0.35656\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75572\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36543\n",
            "     | > avg_G_mse_fake_loss: 0.31998\n",
            "     | > avg_G_loss: 1.94735\n",
            "     | > avg_G_gen_loss: 1.14739\n",
            "     | > avg_G_adv_loss: 0.79996\n",
            "     | > avg_D_mse_gan_loss: 0.44452\n",
            "     | > avg_D_mse_gan_real_loss: 0.13827\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13761\n",
            "     | > avg_D_loss: 0.44452\n",
            "     | > avg_loader_time: 0.82054\n",
            "     | > avg_step_time: 0.57420\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78783 \u001b[0m(-0.00089)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36428 \u001b[0m(+0.00381)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70203 \u001b[0m(+0.00131)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38452 \u001b[0m(+0.02179)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33756 \u001b[0m(-0.01557)\n",
            "     | > avg_G_loss:\u001b[92m 1.96323 \u001b[0m(-0.02593)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11933 \u001b[0m(+0.01301)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84390 \u001b[0m(-0.03893)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44238 \u001b[0m(-0.00620)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16029 \u001b[0m(+0.00531)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10816 \u001b[0m(-0.00708)\n",
            "     | > avg_D_loss:\u001b[92m 0.44238 \u001b[0m(-0.00620)\n",
            "     | > avg_loader_time:\u001b[91m 0.40210 \u001b[0m(+0.04236)\n",
            "     | > avg_step_time:\u001b[91m 0.04926 \u001b[0m(+0.00474)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 427/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:54:20) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.04 sec -- GLOBAL_STEP: 436788\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81152\n",
            "     | > avg_G_stft_loss_sc: 0.36032\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74744\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36943\n",
            "     | > avg_G_mse_fake_loss: 0.31737\n",
            "     | > avg_G_loss: 1.93778\n",
            "     | > avg_G_gen_loss: 1.14435\n",
            "     | > avg_G_adv_loss: 0.79343\n",
            "     | > avg_D_mse_gan_loss: 0.44650\n",
            "     | > avg_D_mse_gan_real_loss: 0.13815\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13810\n",
            "     | > avg_D_loss: 0.44650\n",
            "     | > avg_loader_time: 0.81290\n",
            "     | > avg_step_time: 0.57015\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79150 \u001b[0m(+0.00367)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37106 \u001b[0m(+0.00677)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70321 \u001b[0m(+0.00118)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37138 \u001b[0m(-0.01314)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.35577 \u001b[0m(+0.01821)\n",
            "     | > avg_G_loss:\u001b[91m 2.00800 \u001b[0m(+0.04476)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11858 \u001b[0m(-0.00076)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.88942 \u001b[0m(+0.04552)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44821 \u001b[0m(+0.00583)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17092 \u001b[0m(+0.01063)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10330 \u001b[0m(-0.00486)\n",
            "     | > avg_D_loss:\u001b[91m 0.44821 \u001b[0m(+0.00583)\n",
            "     | > avg_loader_time:\u001b[92m 0.38211 \u001b[0m(-0.01999)\n",
            "     | > avg_step_time:\u001b[92m 0.04604 \u001b[0m(-0.00321)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 428/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-10 23:57:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.98 sec -- GLOBAL_STEP: 436909\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81971\n",
            "     | > avg_G_stft_loss_sc: 0.35861\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76028\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36728\n",
            "     | > avg_G_mse_fake_loss: 0.31924\n",
            "     | > avg_G_loss: 1.95105\n",
            "     | > avg_G_gen_loss: 1.15294\n",
            "     | > avg_G_adv_loss: 0.79811\n",
            "     | > avg_D_mse_gan_loss: 0.44461\n",
            "     | > avg_D_mse_gan_real_loss: 0.13779\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13758\n",
            "     | > avg_D_loss: 0.44461\n",
            "     | > avg_loader_time: 0.82415\n",
            "     | > avg_step_time: 0.56957\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.79040 \u001b[0m(-0.00110)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.38497 \u001b[0m(+0.01392)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70385 \u001b[0m(+0.00064)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.39245 \u001b[0m(+0.02107)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.33859 \u001b[0m(-0.01718)\n",
            "     | > avg_G_loss:\u001b[92m 1.98231 \u001b[0m(-0.02568)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.13584 \u001b[0m(+0.01726)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.84648 \u001b[0m(-0.04294)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44921 \u001b[0m(+0.00100)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15888 \u001b[0m(-0.01203)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11788 \u001b[0m(+0.01458)\n",
            "     | > avg_D_loss:\u001b[91m 0.44921 \u001b[0m(+0.00100)\n",
            "     | > avg_loader_time:\u001b[92m 0.38207 \u001b[0m(-0.00003)\n",
            "     | > avg_step_time:\u001b[91m 0.04810 \u001b[0m(+0.00205)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 429/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:00:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 90/120 -- GLOBAL_STEP: 437000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.78656  (0.80944)\n",
            "     | > G_stft_loss_sc: 0.34444  (0.36016)\n",
            "     | > G_subband_stft_loss_mg: 0.70824  (0.74201)\n",
            "     | > G_subband_stft_loss_sc: 0.36099  (0.36891)\n",
            "     | > G_mse_fake_loss: 0.30830  (0.31770)\n",
            "     | > G_loss: 1.87086  (1.93450)\n",
            "     | > G_gen_loss: 1.10011  (1.14026)\n",
            "     | > G_adv_loss: 0.77074  (0.79424)\n",
            "     | > D_mse_gan_loss: 0.45387  (0.44541)\n",
            "     | > D_mse_gan_real_loss: 0.13001  (0.13773)\n",
            "     | > D_mse_gan_fake_loss: 0.14821  (0.13748)\n",
            "     | > D_loss: 0.45387  (0.44541)\n",
            "     | > step_time: 0.57\n",
            "     | > loader_time: 1.2531\n",
            "     | > current_lr_G: 5.41684023680573e-06\n",
            "     | > current_lr_D: 5.41684023680573e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.90 sec -- GLOBAL_STEP: 437030\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80906\n",
            "     | > avg_G_stft_loss_sc: 0.35947\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74143\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36801\n",
            "     | > avg_G_mse_fake_loss: 0.31769\n",
            "     | > avg_G_loss: 1.93320\n",
            "     | > avg_G_gen_loss: 1.13898\n",
            "     | > avg_G_adv_loss: 0.79422\n",
            "     | > avg_D_mse_gan_loss: 0.44546\n",
            "     | > avg_D_mse_gan_real_loss: 0.13806\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13715\n",
            "     | > avg_D_loss: 0.44546\n",
            "     | > avg_loader_time: 0.80637\n",
            "     | > avg_step_time: 0.56837\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78828 \u001b[0m(-0.00212)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36050 \u001b[0m(-0.02447)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70112 \u001b[0m(-0.00273)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37128 \u001b[0m(-0.02117)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.29990 \u001b[0m(-0.03869)\n",
            "     | > avg_G_loss:\u001b[92m 1.86034 \u001b[0m(-0.12197)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11059 \u001b[0m(-0.02524)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.74975 \u001b[0m(-0.09673)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44690 \u001b[0m(-0.00231)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13762 \u001b[0m(-0.02126)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13600 \u001b[0m(+0.01812)\n",
            "     | > avg_D_loss:\u001b[92m 0.44690 \u001b[0m(-0.00231)\n",
            "     | > avg_loader_time:\u001b[91m 0.39257 \u001b[0m(+0.01050)\n",
            "     | > avg_step_time:\u001b[91m 0.05144 \u001b[0m(+0.00334)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 430/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:03:11) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.29 sec -- GLOBAL_STEP: 437151\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81737\n",
            "     | > avg_G_stft_loss_sc: 0.35770\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75745\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36639\n",
            "     | > avg_G_mse_fake_loss: 0.31858\n",
            "     | > avg_G_loss: 1.94590\n",
            "     | > avg_G_gen_loss: 1.14946\n",
            "     | > avg_G_adv_loss: 0.79644\n",
            "     | > avg_D_mse_gan_loss: 0.44496\n",
            "     | > avg_D_mse_gan_real_loss: 0.13763\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13768\n",
            "     | > avg_D_loss: 0.44496\n",
            "     | > avg_loader_time: 0.81069\n",
            "     | > avg_step_time: 0.58047\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78591 \u001b[0m(-0.00237)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35579 \u001b[0m(-0.00472)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70070 \u001b[0m(-0.00042)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36853 \u001b[0m(-0.00275)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.38045 \u001b[0m(+0.08055)\n",
            "     | > avg_G_loss:\u001b[91m 2.05658 \u001b[0m(+0.19624)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10546 \u001b[0m(-0.00513)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.95112 \u001b[0m(+0.20137)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44846 \u001b[0m(+0.00156)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17214 \u001b[0m(+0.03451)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10248 \u001b[0m(-0.03352)\n",
            "     | > avg_D_loss:\u001b[91m 0.44846 \u001b[0m(+0.00156)\n",
            "     | > avg_loader_time:\u001b[91m 0.42000 \u001b[0m(+0.02743)\n",
            "     | > avg_step_time:\u001b[91m 0.05419 \u001b[0m(+0.00274)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 431/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:06:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.45 sec -- GLOBAL_STEP: 437272\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80912\n",
            "     | > avg_G_stft_loss_sc: 0.35571\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74274\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36410\n",
            "     | > avg_G_mse_fake_loss: 0.31643\n",
            "     | > avg_G_loss: 1.92692\n",
            "     | > avg_G_gen_loss: 1.13584\n",
            "     | > avg_G_adv_loss: 0.79108\n",
            "     | > avg_D_mse_gan_loss: 0.44623\n",
            "     | > avg_D_mse_gan_real_loss: 0.13838\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13780\n",
            "     | > avg_D_loss: 0.44623\n",
            "     | > avg_loader_time: 0.82121\n",
            "     | > avg_step_time: 0.56508\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78865 \u001b[0m(+0.00274)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36551 \u001b[0m(+0.00972)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70292 \u001b[0m(+0.00222)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38352 \u001b[0m(+0.01499)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.30269 \u001b[0m(-0.07776)\n",
            "     | > avg_G_loss:\u001b[92m 1.87702 \u001b[0m(-0.17956)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12030 \u001b[0m(+0.01484)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.75672 \u001b[0m(-0.19440)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44274 \u001b[0m(-0.00572)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.11862 \u001b[0m(-0.05352)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.14849 \u001b[0m(+0.04601)\n",
            "     | > avg_D_loss:\u001b[92m 0.44274 \u001b[0m(-0.00572)\n",
            "     | > avg_loader_time:\u001b[92m 0.35046 \u001b[0m(-0.06953)\n",
            "     | > avg_step_time:\u001b[92m 0.04738 \u001b[0m(-0.00680)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 432/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:09:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 70.59 sec -- GLOBAL_STEP: 437393\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80873\n",
            "     | > avg_G_stft_loss_sc: 0.35837\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74246\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36717\n",
            "     | > avg_G_mse_fake_loss: 0.31622\n",
            "     | > avg_G_loss: 1.92891\n",
            "     | > avg_G_gen_loss: 1.13836\n",
            "     | > avg_G_adv_loss: 0.79054\n",
            "     | > avg_D_mse_gan_loss: 0.44706\n",
            "     | > avg_D_mse_gan_real_loss: 0.13924\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13783\n",
            "     | > avg_D_loss: 0.44706\n",
            "     | > avg_loader_time: 0.80911\n",
            "     | > avg_step_time: 0.58296\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79068 \u001b[0m(+0.00203)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35631 \u001b[0m(-0.00920)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70272 \u001b[0m(-0.00020)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36605 \u001b[0m(-0.01747)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.33338 \u001b[0m(+0.03070)\n",
            "     | > avg_G_loss:\u001b[91m 1.94134 \u001b[0m(+0.06432)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10788 \u001b[0m(-0.01242)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.83346 \u001b[0m(+0.07674)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44582 \u001b[0m(+0.00308)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.14507 \u001b[0m(+0.02645)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.12931 \u001b[0m(-0.01918)\n",
            "     | > avg_D_loss:\u001b[91m 0.44582 \u001b[0m(+0.00308)\n",
            "     | > avg_loader_time:\u001b[91m 0.41773 \u001b[0m(+0.06726)\n",
            "     | > avg_step_time:\u001b[91m 0.05219 \u001b[0m(+0.00481)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 433/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:12:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 69.79 sec -- GLOBAL_STEP: 437514\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81373\n",
            "     | > avg_G_stft_loss_sc: 0.35688\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75277\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36534\n",
            "     | > avg_G_mse_fake_loss: 0.31511\n",
            "     | > avg_G_loss: 1.93213\n",
            "     | > avg_G_gen_loss: 1.14436\n",
            "     | > avg_G_adv_loss: 0.78777\n",
            "     | > avg_D_mse_gan_loss: 0.44631\n",
            "     | > avg_D_mse_gan_real_loss: 0.13819\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13800\n",
            "     | > avg_D_loss: 0.44631\n",
            "     | > avg_loader_time: 0.81533\n",
            "     | > avg_step_time: 0.57615\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78540 \u001b[0m(-0.00528)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36617 \u001b[0m(+0.00986)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69990 \u001b[0m(-0.00282)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38376 \u001b[0m(+0.01771)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.31116 \u001b[0m(-0.02223)\n",
            "     | > avg_G_loss:\u001b[92m 1.89550 \u001b[0m(-0.04584)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11761 \u001b[0m(+0.00973)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.77789 \u001b[0m(-0.05557)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44392 \u001b[0m(-0.00191)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.13135 \u001b[0m(-0.01372)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.13548 \u001b[0m(+0.00617)\n",
            "     | > avg_D_loss:\u001b[92m 0.44392 \u001b[0m(-0.00191)\n",
            "     | > avg_loader_time:\u001b[92m 0.38647 \u001b[0m(-0.03126)\n",
            "     | > avg_step_time:\u001b[92m 0.04985 \u001b[0m(-0.00234)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 434/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:15:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.30 sec -- GLOBAL_STEP: 437635\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80486\n",
            "     | > avg_G_stft_loss_sc: 0.35900\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73548\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36760\n",
            "     | > avg_G_mse_fake_loss: 0.31474\n",
            "     | > avg_G_loss: 1.92030\n",
            "     | > avg_G_gen_loss: 1.13347\n",
            "     | > avg_G_adv_loss: 0.78684\n",
            "     | > avg_D_mse_gan_loss: 0.44727\n",
            "     | > avg_D_mse_gan_real_loss: 0.13840\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13758\n",
            "     | > avg_D_loss: 0.44727\n",
            "     | > avg_loader_time: 0.81806\n",
            "     | > avg_step_time: 0.56379\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.79117 \u001b[0m(+0.00577)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.36144 \u001b[0m(-0.00473)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70417 \u001b[0m(+0.00427)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.38038 \u001b[0m(-0.00337)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.33660 \u001b[0m(+0.02545)\n",
            "     | > avg_G_loss:\u001b[91m 1.96008 \u001b[0m(+0.06459)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11858 \u001b[0m(+0.00097)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.84151 \u001b[0m(+0.06362)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44407 \u001b[0m(+0.00015)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.16629 \u001b[0m(+0.03494)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10774 \u001b[0m(-0.02774)\n",
            "     | > avg_D_loss:\u001b[91m 0.44407 \u001b[0m(+0.00015)\n",
            "     | > avg_loader_time:\u001b[92m 0.38484 \u001b[0m(-0.00163)\n",
            "     | > avg_step_time:\u001b[92m 0.04708 \u001b[0m(-0.00278)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 435/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:17:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.83 sec -- GLOBAL_STEP: 437756\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81646\n",
            "     | > avg_G_stft_loss_sc: 0.35873\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75682\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36770\n",
            "     | > avg_G_mse_fake_loss: 0.31700\n",
            "     | > avg_G_loss: 1.94236\n",
            "     | > avg_G_gen_loss: 1.14985\n",
            "     | > avg_G_adv_loss: 0.79251\n",
            "     | > avg_D_mse_gan_loss: 0.44559\n",
            "     | > avg_D_mse_gan_real_loss: 0.13742\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13740\n",
            "     | > avg_D_loss: 0.44559\n",
            "     | > avg_loader_time: 0.82017\n",
            "     | > avg_step_time: 0.56812\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78638 \u001b[0m(-0.00479)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35868 \u001b[0m(-0.00276)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69921 \u001b[0m(-0.00496)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36596 \u001b[0m(-0.01442)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.40738 \u001b[0m(+0.07078)\n",
            "     | > avg_G_loss:\u001b[91m 2.12357 \u001b[0m(+0.16349)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10511 \u001b[0m(-0.01347)\n",
            "     | > avg_G_adv_loss:\u001b[91m 1.01846 \u001b[0m(+0.17695)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45220 \u001b[0m(+0.00814)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17840 \u001b[0m(+0.01210)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.09390 \u001b[0m(-0.01384)\n",
            "     | > avg_D_loss:\u001b[91m 0.45220 \u001b[0m(+0.00814)\n",
            "     | > avg_loader_time:\u001b[91m 0.40759 \u001b[0m(+0.02275)\n",
            "     | > avg_step_time:\u001b[91m 0.05426 \u001b[0m(+0.00719)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 436/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:20:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.32 sec -- GLOBAL_STEP: 437877\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.82096\n",
            "     | > avg_G_stft_loss_sc: 0.35734\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76149\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36645\n",
            "     | > avg_G_mse_fake_loss: 0.32011\n",
            "     | > avg_G_loss: 1.95339\n",
            "     | > avg_G_gen_loss: 1.15312\n",
            "     | > avg_G_adv_loss: 0.80027\n",
            "     | > avg_D_mse_gan_loss: 0.44468\n",
            "     | > avg_D_mse_gan_real_loss: 0.13802\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13815\n",
            "     | > avg_D_loss: 0.44468\n",
            "     | > avg_loader_time: 0.80403\n",
            "     | > avg_step_time: 0.55582\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78655 \u001b[0m(+0.00018)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36545 \u001b[0m(+0.00677)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70041 \u001b[0m(+0.00120)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38465 \u001b[0m(+0.01869)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.37710 \u001b[0m(-0.03028)\n",
            "     | > avg_G_loss:\u001b[92m 2.06129 \u001b[0m(-0.06228)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11853 \u001b[0m(+0.01342)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.94276 \u001b[0m(-0.07570)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.45030 \u001b[0m(-0.00190)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.17647 \u001b[0m(-0.00193)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.10134 \u001b[0m(+0.00745)\n",
            "     | > avg_D_loss:\u001b[92m 0.45030 \u001b[0m(-0.00190)\n",
            "     | > avg_loader_time:\u001b[91m 0.44642 \u001b[0m(+0.03883)\n",
            "     | > avg_step_time:\u001b[91m 0.05493 \u001b[0m(+0.00067)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 437/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:23:49) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.77 sec -- GLOBAL_STEP: 437998\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81963\n",
            "     | > avg_G_stft_loss_sc: 0.35890\n",
            "     | > avg_G_subband_stft_loss_mg: 0.76066\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36745\n",
            "     | > avg_G_mse_fake_loss: 0.31951\n",
            "     | > avg_G_loss: 1.95209\n",
            "     | > avg_G_gen_loss: 1.15332\n",
            "     | > avg_G_adv_loss: 0.79877\n",
            "     | > avg_D_mse_gan_loss: 0.44491\n",
            "     | > avg_D_mse_gan_real_loss: 0.13816\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13766\n",
            "     | > avg_D_loss: 0.44491\n",
            "     | > avg_loader_time: 0.81653\n",
            "     | > avg_step_time: 0.56743\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78606 \u001b[0m(-0.00049)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35724 \u001b[0m(-0.00821)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.69972 \u001b[0m(-0.00069)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37361 \u001b[0m(-0.01104)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32010 \u001b[0m(-0.05701)\n",
            "     | > avg_G_loss:\u001b[92m 1.90855 \u001b[0m(-0.15274)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10831 \u001b[0m(-0.01022)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.80024 \u001b[0m(-0.14252)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44361 \u001b[0m(-0.00669)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.15333 \u001b[0m(-0.02314)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.11462 \u001b[0m(+0.01327)\n",
            "     | > avg_D_loss:\u001b[92m 0.44361 \u001b[0m(-0.00669)\n",
            "     | > avg_loader_time:\u001b[92m 0.38783 \u001b[0m(-0.05859)\n",
            "     | > avg_step_time:\u001b[92m 0.04674 \u001b[0m(-0.00819)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 438/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:26:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 1/120 -- GLOBAL_STEP: 438000\u001b[0m\n",
            "     | > G_stft_loss_mg: 0.82177  (0.82177)\n",
            "     | > G_stft_loss_sc: 0.34543  (0.34543)\n",
            "     | > G_subband_stft_loss_mg: 0.76435  (0.76435)\n",
            "     | > G_subband_stft_loss_sc: 0.35697  (0.35697)\n",
            "     | > G_mse_fake_loss: 0.30694  (0.30694)\n",
            "     | > G_loss: 1.91161  (1.91161)\n",
            "     | > G_gen_loss: 1.14426  (1.14426)\n",
            "     | > G_adv_loss: 0.76735  (0.76735)\n",
            "     | > D_mse_gan_loss: 0.44252  (0.44252)\n",
            "     | > D_mse_gan_real_loss: 0.13900  (0.13900)\n",
            "     | > D_mse_gan_fake_loss: 0.13601  (0.13601)\n",
            "     | > D_loss: 0.44252  (0.44252)\n",
            "     | > step_time: 0.51\n",
            "     | > loader_time: 0.0092\n",
            "     | > current_lr_G: 5.368283226590263e-06\n",
            "     | > current_lr_D: 5.368283226590263e-06\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.06 sec -- GLOBAL_STEP: 438119\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81230\n",
            "     | > avg_G_stft_loss_sc: 0.36008\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74937\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36858\n",
            "     | > avg_G_mse_fake_loss: 0.31546\n",
            "     | > avg_G_loss: 1.93381\n",
            "     | > avg_G_gen_loss: 1.14516\n",
            "     | > avg_G_adv_loss: 0.78865\n",
            "     | > avg_D_mse_gan_loss: 0.44559\n",
            "     | > avg_D_mse_gan_real_loss: 0.13786\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13720\n",
            "     | > avg_D_loss: 0.44559\n",
            "     | > avg_loader_time: 0.80534\n",
            "     | > avg_step_time: 0.55310\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78797 \u001b[0m(+0.00190)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36684 \u001b[0m(+0.00960)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70256 \u001b[0m(+0.00284)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.38764 \u001b[0m(+0.01403)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.32147 \u001b[0m(+0.00137)\n",
            "     | > avg_G_loss:\u001b[91m 1.92617 \u001b[0m(+0.01761)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.12250 \u001b[0m(+0.01419)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.80367 \u001b[0m(+0.00343)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44014 \u001b[0m(-0.00347)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14413 \u001b[0m(-0.00920)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12370 \u001b[0m(+0.00909)\n",
            "     | > avg_D_loss:\u001b[92m 0.44014 \u001b[0m(-0.00347)\n",
            "     | > avg_loader_time:\u001b[91m 0.40166 \u001b[0m(+0.01383)\n",
            "     | > avg_step_time:\u001b[91m 0.05418 \u001b[0m(+0.00744)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 439/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:29:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 68.97 sec -- GLOBAL_STEP: 438240\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81295\n",
            "     | > avg_G_stft_loss_sc: 0.35582\n",
            "     | > avg_G_subband_stft_loss_mg: 0.74872\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36486\n",
            "     | > avg_G_mse_fake_loss: 0.31798\n",
            "     | > avg_G_loss: 1.93613\n",
            "     | > avg_G_gen_loss: 1.14118\n",
            "     | > avg_G_adv_loss: 0.79495\n",
            "     | > avg_D_mse_gan_loss: 0.44566\n",
            "     | > avg_D_mse_gan_real_loss: 0.13835\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13739\n",
            "     | > avg_D_loss: 0.44566\n",
            "     | > avg_loader_time: 0.81683\n",
            "     | > avg_step_time: 0.56923\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78776 \u001b[0m(-0.00021)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.36695 \u001b[0m(+0.00012)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70027 \u001b[0m(-0.00229)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.37003 \u001b[0m(-0.01761)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.34644 \u001b[0m(+0.02498)\n",
            "     | > avg_G_loss:\u001b[91m 1.97862 \u001b[0m(+0.05245)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.11251 \u001b[0m(-0.00999)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.86611 \u001b[0m(+0.06244)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.44686 \u001b[0m(+0.00672)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14213 \u001b[0m(-0.00199)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12514 \u001b[0m(+0.00144)\n",
            "     | > avg_D_loss:\u001b[91m 0.44686 \u001b[0m(+0.00672)\n",
            "     | > avg_loader_time:\u001b[91m 0.40740 \u001b[0m(+0.00574)\n",
            "     | > avg_step_time:\u001b[92m 0.04462 \u001b[0m(-0.00956)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 440/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:32:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.23 sec -- GLOBAL_STEP: 438361\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.81924\n",
            "     | > avg_G_stft_loss_sc: 0.35713\n",
            "     | > avg_G_subband_stft_loss_mg: 0.75941\n",
            "     | > avg_G_subband_stft_loss_sc: 0.36591\n",
            "     | > avg_G_mse_fake_loss: 0.31881\n",
            "     | > avg_G_loss: 1.94788\n",
            "     | > avg_G_gen_loss: 1.15084\n",
            "     | > avg_G_adv_loss: 0.79703\n",
            "     | > avg_D_mse_gan_loss: 0.44487\n",
            "     | > avg_D_mse_gan_real_loss: 0.13810\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13788\n",
            "     | > avg_D_loss: 0.44487\n",
            "     | > avg_loader_time: 0.79601\n",
            "     | > avg_step_time: 0.55493\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[91m 0.78873 \u001b[0m(+0.00097)\n",
            "     | > avg_G_stft_loss_sc:\u001b[91m 0.37120 \u001b[0m(+0.00425)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[91m 0.70118 \u001b[0m(+0.00091)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[91m 0.37537 \u001b[0m(+0.00534)\n",
            "     | > avg_G_mse_fake_loss:\u001b[91m 0.39309 \u001b[0m(+0.04665)\n",
            "     | > avg_G_loss:\u001b[91m 2.10096 \u001b[0m(+0.12235)\n",
            "     | > avg_G_gen_loss:\u001b[91m 1.11824 \u001b[0m(+0.00573)\n",
            "     | > avg_G_adv_loss:\u001b[91m 0.98272 \u001b[0m(+0.11662)\n",
            "     | > avg_D_mse_gan_loss:\u001b[91m 0.45350 \u001b[0m(+0.00664)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[91m 0.17503 \u001b[0m(+0.03290)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[92m 0.10068 \u001b[0m(-0.02446)\n",
            "     | > avg_D_loss:\u001b[91m 0.45350 \u001b[0m(+0.00664)\n",
            "     | > avg_loader_time:\u001b[92m 0.36905 \u001b[0m(-0.03835)\n",
            "     | > avg_step_time:\u001b[91m 0.04722 \u001b[0m(+0.00260)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 441/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:35:30) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TRAIN PERFORMACE -- EPOCH TIME: 67.46 sec -- GLOBAL_STEP: 438482\u001b[0m\n",
            "     | > avg_G_stft_loss_mg: 0.80516\n",
            "     | > avg_G_stft_loss_sc: 0.36552\n",
            "     | > avg_G_subband_stft_loss_mg: 0.73898\n",
            "     | > avg_G_subband_stft_loss_sc: 0.37363\n",
            "     | > avg_G_mse_fake_loss: 0.31129\n",
            "     | > avg_G_loss: 1.91987\n",
            "     | > avg_G_gen_loss: 1.14164\n",
            "     | > avg_G_adv_loss: 0.77823\n",
            "     | > avg_D_mse_gan_loss: 0.44859\n",
            "     | > avg_D_mse_gan_real_loss: 0.13930\n",
            "     | > avg_D_mse_gan_fake_loss: 0.13825\n",
            "     | > avg_D_loss: 0.44859\n",
            "     | > avg_loader_time: 0.83776\n",
            "     | > avg_step_time: 0.55731\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_G_stft_loss_mg:\u001b[92m 0.78643 \u001b[0m(-0.00230)\n",
            "     | > avg_G_stft_loss_sc:\u001b[92m 0.35659 \u001b[0m(-0.01461)\n",
            "     | > avg_G_subband_stft_loss_mg:\u001b[92m 0.70043 \u001b[0m(-0.00076)\n",
            "     | > avg_G_subband_stft_loss_sc:\u001b[92m 0.36501 \u001b[0m(-0.01036)\n",
            "     | > avg_G_mse_fake_loss:\u001b[92m 0.32760 \u001b[0m(-0.06549)\n",
            "     | > avg_G_loss:\u001b[92m 1.92324 \u001b[0m(-0.17772)\n",
            "     | > avg_G_gen_loss:\u001b[92m 1.10423 \u001b[0m(-0.01401)\n",
            "     | > avg_G_adv_loss:\u001b[92m 0.81901 \u001b[0m(-0.16371)\n",
            "     | > avg_D_mse_gan_loss:\u001b[92m 0.44039 \u001b[0m(-0.01311)\n",
            "     | > avg_D_mse_gan_real_loss:\u001b[92m 0.14235 \u001b[0m(-0.03268)\n",
            "     | > avg_D_mse_gan_fake_loss:\u001b[91m 0.12135 \u001b[0m(+0.02067)\n",
            "     | > avg_D_loss:\u001b[92m 0.44039 \u001b[0m(-0.01311)\n",
            "     | > avg_loader_time:\u001b[92m 0.36281 \u001b[0m(-0.00625)\n",
            "     | > avg_step_time:\u001b[91m 0.04981 \u001b[0m(+0.00259)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 442/10000\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > TRAINING (2021-05-11 00:38:27) \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEcPFZiYYICO"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"$DATAROOT/jsut_ver1.1_ljspeech_structure/output/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}